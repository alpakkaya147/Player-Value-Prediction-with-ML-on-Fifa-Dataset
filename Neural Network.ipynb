{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-408360ac-1711-4e3d-b922-1e978bdc8408",
    "deepnote_cell_type": "text-cell-h1",
    "tags": []
   },
   "source": [
    "# Application of Arificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-e8cc910c-80f4-4fe6-a8e3-e99dd62fc5f9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 885,
    "execution_start": 1621687828741,
    "source_hash": "c302e583"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "from numpy import absolute\n",
    "from numpy import mean\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from IPython.display import Image\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-5f7adb9b-58dd-4b92-91d4-faab370704fe",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5099,
    "execution_start": 1621687830489,
    "scrolled": true,
    "source_hash": "cc8f0a8e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prettytable in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from prettytable) (0.2.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from prettytable) (49.2.0.post20200714)\n"
     ]
    }
   ],
   "source": [
    "! pip install prettytable\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-95e3656f-576e-40f6-8ee8-692e4f01a0e1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "full_data = pd.read_csv(\"model_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-b1a98375-d205-419f-bf6a-7766a6626c78",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 494,
    "execution_start": 1621687835597,
    "source_hash": "db35f721",
    "tags": []
   },
   "outputs": [],
   "source": [
    "field_df = pd.read_csv(\"field_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-8d837b19-0c2b-4a54-bef4-b43bb24071e6",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "gk_df = pd.read_csv(\"gk_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-f9ef998c-98b8-4347-a0b0-535b68605bfa",
    "deepnote_cell_type": "code",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create goalkeeper dataframe by selecting players with corresponding position index\n",
    "gk_df = full_data[full_data.position_dummy == 1]\n",
    "gk_df = gk_df[[\"long_name\",\"age\", \"height_cm\", \"weight_kg\", \"value_eur\", \"gk_diving\", \"gk_handling\", \"gk_kicking\", \"gk_reflexes\", \"gk_speed\", \"gk_positioning\", \"movement_acceleration\", \"movement_sprint_speed\", \"movement_agility\", \"movement_reactions\", \"movement_balance\", \"power_shot_power\", \"power_jumping\", \"power_stamina\", \"power_strength\", \"power_long_shots\", \"mentality_vision\", \"mentality_penalties\", \"mentality_composure\", \"number_of_traits\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-88987ee1-f396-4e38-b655-bbab96fd6dbc",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "field_df = full_data[full_data.position_dummy != 1]\n",
    "field_df = field_df.drop([\"Unnamed: 0\", \"sofifa_id\", \"gk_diving\", \"gk_handling\", \"gk_kicking\", \"gk_reflexes\", \"gk_speed\", \"gk_positioning\", \"international_reputation\", \"position_dummy\", \"preferred_foot\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-f1290def-1583-4d2b-8f6a-7d57ce3faba0",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#for later processing, create dictionaries containing players name/age and respective index in base dataframe\n",
    "name_gk = list(gk_df.long_name)\n",
    "index_gk = list(gk_df.index)\n",
    "gk_zip_iter = zip(index_gk, name_gk)\n",
    "gk_dict = dict(gk_zip_iter)\n",
    "\n",
    "name_field = list(field_df.long_name)\n",
    "index_field = list(field_df.index)\n",
    "field_zip_iter = zip(index_field, name_field)\n",
    "field_dict = dict(field_zip_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-a96582f9-670a-4ed0-94dd-fd49fb990357",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "age_gk = list(gk_df.age)\n",
    "gk_age_zip_iter = zip(index_gk, age_gk)\n",
    "gk_age_dict = dict(gk_age_zip_iter)\n",
    "gk_df= gk_df.drop([\"long_name\"], axis=1)\n",
    "\n",
    "age_field = list(field_df.age)\n",
    "field_age_zip_iter = zip(index_field, age_field)\n",
    "field_age_dict = dict(field_age_zip_iter)\n",
    "field_df = field_df.drop([\"long_name\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00010-3598dbb8-5777-4e6a-9301-5b4b86bc9956",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "gk_df = gk_df.astype(float)\n",
    "field_df = field_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-fa40f77b-75a1-4f42-8ec0-ba0d7fa36623",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>value_eur</th>\n",
       "      <th>gk_diving</th>\n",
       "      <th>gk_handling</th>\n",
       "      <th>gk_kicking</th>\n",
       "      <th>gk_reflexes</th>\n",
       "      <th>gk_speed</th>\n",
       "      <th>gk_positioning</th>\n",
       "      <th>...</th>\n",
       "      <th>movement_balance</th>\n",
       "      <th>power_shot_power</th>\n",
       "      <th>power_jumping</th>\n",
       "      <th>power_stamina</th>\n",
       "      <th>power_strength</th>\n",
       "      <th>power_long_shots</th>\n",
       "      <th>mentality_vision</th>\n",
       "      <th>mentality_penalties</th>\n",
       "      <th>mentality_composure</th>\n",
       "      <th>number_of_traits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>18.132999</td>\n",
       "      <td>87.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18.056837</td>\n",
       "      <td>88.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>17.950677</td>\n",
       "      <td>86.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>17.840862</td>\n",
       "      <td>84.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>34.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>17.182806</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18654</th>\n",
       "      <td>17.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.819778</td>\n",
       "      <td>49.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18670</th>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.596635</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18675</th>\n",
       "      <td>16.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>10.308953</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18686</th>\n",
       "      <td>22.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10.308953</td>\n",
       "      <td>49.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18688</th>\n",
       "      <td>30.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.903488</td>\n",
       "      <td>51.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2053 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  height_cm  weight_kg  value_eur  gk_diving  gk_handling  \\\n",
       "2      27.0      188.0       87.0  18.132999       87.0         92.0   \n",
       "7      28.0      187.0       85.0  18.056837       88.0         85.0   \n",
       "9      27.0      191.0       91.0  17.950677       86.0         88.0   \n",
       "12     28.0      199.0       96.0  17.840862       84.0         89.0   \n",
       "16     34.0      193.0       92.0  17.182806       87.0         87.0   \n",
       "...     ...        ...        ...        ...        ...          ...   \n",
       "18654  17.0      175.0       70.0  10.819778       49.0         48.0   \n",
       "18670  21.0      185.0       70.0  10.596635       46.0         46.0   \n",
       "18675  16.0      180.0       76.0  10.308953       47.0         46.0   \n",
       "18686  22.0      196.0       85.0  10.308953       49.0         47.0   \n",
       "18688  30.0      196.0       80.0   9.903488       51.0         47.0   \n",
       "\n",
       "       gk_kicking  gk_reflexes  gk_speed  gk_positioning  ...  \\\n",
       "2            78.0         90.0      52.0            90.0  ...   \n",
       "7            88.0         90.0      45.0            88.0  ...   \n",
       "9            85.0         89.0      51.0            91.0  ...   \n",
       "12           74.0         88.0      48.0            85.0  ...   \n",
       "16           91.0         89.0      57.0            86.0  ...   \n",
       "...           ...          ...       ...             ...  ...   \n",
       "18654        47.0         50.0      34.0            47.0  ...   \n",
       "18670        58.0         51.0      30.0            44.0  ...   \n",
       "18675        46.0         50.0      20.0            45.0  ...   \n",
       "18686        45.0         46.0      54.0            44.0  ...   \n",
       "18688        43.0         48.0      34.0            46.0  ...   \n",
       "\n",
       "       movement_balance  power_shot_power  power_jumping  power_stamina  \\\n",
       "2                  49.0              59.0           78.0           41.0   \n",
       "7                  43.0              66.0           79.0           35.0   \n",
       "9                  37.0              64.0           52.0           32.0   \n",
       "12                 45.0              56.0           68.0           38.0   \n",
       "16                 35.0              68.0           77.0           43.0   \n",
       "...                 ...               ...            ...            ...   \n",
       "18654              49.0              35.0           50.0           40.0   \n",
       "18670              48.0              44.0           61.0           18.0   \n",
       "18675              47.0              35.0           64.0           20.0   \n",
       "18686              54.0              34.0           59.0           33.0   \n",
       "18688              40.0              32.0           53.0           27.0   \n",
       "\n",
       "       power_strength  power_long_shots  mentality_vision  \\\n",
       "2                78.0              12.0              65.0   \n",
       "7                78.0              10.0              70.0   \n",
       "9                78.0              14.0              66.0   \n",
       "12               70.0              17.0              44.0   \n",
       "16               80.0              16.0              70.0   \n",
       "...               ...               ...               ...   \n",
       "18654            38.0              10.0              40.0   \n",
       "18670            49.0               7.0              27.0   \n",
       "18675            41.0               7.0              29.0   \n",
       "18686            51.0              13.0              43.0   \n",
       "18688            42.0              13.0              23.0   \n",
       "\n",
       "       mentality_penalties  mentality_composure  number_of_traits  \n",
       "2                     11.0                 68.0               2.0  \n",
       "7                     25.0                 70.0               3.0  \n",
       "9                     23.0                 65.0               2.0  \n",
       "12                    27.0                 66.0               2.0  \n",
       "16                    47.0                 70.0               4.0  \n",
       "...                    ...                  ...               ...  \n",
       "18654                 15.0                 37.0               0.0  \n",
       "18670                 12.0                 27.0               0.0  \n",
       "18675                 17.0                 38.0               0.0  \n",
       "18686                  8.0                 13.0               0.0  \n",
       "18688                 19.0                 27.0               0.0  \n",
       "\n",
       "[2053 rows x 24 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00067-3b183ffe-01bf-4bc7-856e-ffa9e37e6b7f",
    "deepnote_cell_type": "text-cell-h3",
    "tags": []
   },
   "source": [
    "### Applying Neural Network with goalkeepers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00067-acea16b8-1c65-4ef6-9c14-80f95a9ff4b3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1621687890100,
    "source_hash": "2e4f9ef6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load relative libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00069-cd05da81-9e28-4a27-80d6-c0a070815739",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15,
    "execution_start": 1621687890116,
    "source_hash": "1e9276f8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "np.random.seed(37)\n",
    "rn.seed(1254)\n",
    "tf.random.set_seed(89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00069-d4662661-0586-4b19-8f51-f652517dbf39",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Firs, we start applying the model on the goalkeepers dataset. Therefore we divide the columns in features and target variable respectively  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00069-ce87559b-4e67-4030-8021-e08f55a9506f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1621687890136,
    "source_hash": "3007c7f9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = gk_df.drop([\"value_eur\"], axis = 1)   #independent features\n",
    "y = gk_df[\"value_eur\"]                 #dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00070-0b8a0f4b-9fc2-4997-a1f5-0af2238ceb2b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1621687890157,
    "source_hash": "c6a0f106",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00072-9d58c453-42c7-4cf6-85d8-c8e7eaab7027",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 22,
    "execution_start": 1621687890176,
    "source_hash": "a185f9aa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1368, 23)\n",
      "Test set shape: (685, 23)\n",
      "Training label set shape: (1368,)\n",
      "Test label set shape: (685,)\n"
     ]
    }
   ],
   "source": [
    "#checking the shape of our train set and test set\n",
    "\n",
    "print(\"Training set shape: {}\".format(X_train.shape))\n",
    "print(\"Test set shape: {}\".format(X_test.shape))\n",
    "print(\"Training label set shape: {}\".format(y_train.shape))\n",
    "print(\"Test label set shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00073-25830ce0-802e-460a-8aad-e29445527644",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Subsequently, before implementing the neural network, is highly suggested to normalize the data in order to have every features ranging in the same scale. \n",
    "Consequently, the model would be able to efficiently tweak every parameters for every node and to quickly minimize the loss function.\n",
    "\n",
    "For this purpose we decide tio use MinMaxScaler. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00073-ee6a5255-3577-425f-aac0-7e9b14d1d778",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 25,
    "execution_start": 1621687890194,
    "source_hash": "a7bf9899",
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00075-d17363d7-c5ea-46c9-9ad2-ff1989239d5f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Now we are ready to kick off. In order to better undesrtand if our model is generalizing well with the unseen data or if some parameters need to be further tuned, we are going to build a first algorithm as a benchmark.\n",
    "The following model will have:\n",
    "- 4 layers in total:\n",
    "    - the input layers will be provided with 128 neurons\n",
    "    - the two hidden layers will be providedd with 64 and 32 respectively\n",
    "     - the output layer will have only one neuron for the single output variable.\n",
    "\n",
    "-  As a rule of thumb, every layer should have the same activation function. As we are dealing with a regression problem and we want to predict the market value, the output layer will have a linear activation function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00076-1d5a85db-4f16-428e-8b04-c90b6a332f55",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 116,
    "execution_start": 1621687890224,
    "source_hash": "c0807d22",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Since now we are predicting a single continuous value, the output layer will only have 1 node.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim = X.shape[1], activation = \"relu\"))\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(Dense(32, activation = \"relu\"))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1, activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00077-33297c0d-2c93-430b-b19d-c97a2d4802c2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 69,
    "execution_start": 1621687890350,
    "source_hash": "c51f67e2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 128)               3072      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 13,441\n",
      "Trainable params: 13,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"mse\", optimizer = \"adam\", metrics = [\"mse\", \"mae\", \"mape\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00078-fa646751-d768-418d-9fa1-ea4c8c0b2e2e",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "As we can clearly seen from the summary in the previous cell, our model will be provided for a total of 4 dense layers and  more than 13.000 parameters to be adjusted.\n",
    "\n",
    "Whereas in the following cell, we fit the model keeping the default batch'size (however in the following cells it has been questioned which was the best batch's size for the NN ) and with a total amount of 250 epochs. Moreover, to keep track of the algorithm's performances, we decided to use the fucntion validation_split() within the Keras package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00078-951be7f0-e901-4b78-9dd6-d82c8974d823",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 60780,
    "execution_start": 1621687890409,
    "source_hash": "eb5d298",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "35/35 [==============================] - 1s 6ms/step - loss: 149.9090 - mse: 149.9090 - mae: 12.0993 - mape: 92.5916 - val_loss: 21.6677 - val_mse: 21.6677 - val_mae: 4.4713 - val_mape: 34.9451\n",
      "Epoch 2/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 10.1970 - mse: 10.1970 - mae: 2.6564 - mape: 20.5029 - val_loss: 4.5387 - val_mse: 4.5387 - val_mae: 1.7496 - val_mape: 14.0617\n",
      "Epoch 3/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 3.7841 - mse: 3.7841 - mae: 1.6259 - mape: 12.9127 - val_loss: 3.2745 - val_mse: 3.2745 - val_mae: 1.5447 - val_mape: 12.3525\n",
      "Epoch 4/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 3.1007 - mse: 3.1007 - mae: 1.4498 - mape: 11.5973 - val_loss: 2.5281 - val_mse: 2.5281 - val_mae: 1.3585 - val_mape: 10.8216\n",
      "Epoch 5/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 2.1682 - mse: 2.1682 - mae: 1.2089 - mape: 9.6536 - val_loss: 1.8439 - val_mse: 1.8439 - val_mae: 1.1333 - val_mape: 8.9917\n",
      "Epoch 6/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.6669 - mse: 1.6669 - mae: 1.0578 - mape: 8.4537 - val_loss: 1.2016 - val_mse: 1.2016 - val_mae: 0.8929 - val_mape: 7.1188\n",
      "Epoch 7/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.2333 - mse: 1.2333 - mae: 0.8962 - mape: 7.1450 - val_loss: 0.9090 - val_mse: 0.9090 - val_mae: 0.7723 - val_mape: 6.1544\n",
      "Epoch 8/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9841 - mse: 0.9841 - mae: 0.7957 - mape: 6.3064 - val_loss: 0.7334 - val_mse: 0.7334 - val_mae: 0.6889 - val_mape: 5.4495\n",
      "Epoch 9/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7997 - mse: 0.7997 - mae: 0.7119 - mape: 5.5479 - val_loss: 0.6188 - val_mse: 0.6188 - val_mae: 0.6349 - val_mape: 5.0175\n",
      "Epoch 10/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6754 - mse: 0.6754 - mae: 0.6465 - mape: 5.1043 - val_loss: 0.5445 - val_mse: 0.5445 - val_mae: 0.5940 - val_mape: 4.6837\n",
      "Epoch 11/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5547 - mse: 0.5547 - mae: 0.5826 - mape: 4.5621 - val_loss: 0.4891 - val_mse: 0.4891 - val_mae: 0.5611 - val_mape: 4.4382\n",
      "Epoch 12/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5380 - mse: 0.5380 - mae: 0.5850 - mape: 4.6180 - val_loss: 0.4877 - val_mse: 0.4877 - val_mae: 0.5670 - val_mape: 4.4842\n",
      "Epoch 13/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4821 - mse: 0.4821 - mae: 0.5398 - mape: 4.2300 - val_loss: 0.3890 - val_mse: 0.3890 - val_mae: 0.4995 - val_mape: 3.9396\n",
      "Epoch 14/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4036 - mse: 0.4036 - mae: 0.5044 - mape: 3.9565 - val_loss: 0.3534 - val_mse: 0.3534 - val_mae: 0.4764 - val_mape: 3.7517\n",
      "Epoch 15/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3344 - mse: 0.3344 - mae: 0.4633 - mape: 3.6366 - val_loss: 0.3257 - val_mse: 0.3257 - val_mae: 0.4579 - val_mape: 3.6010\n",
      "Epoch 16/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3305 - mse: 0.3305 - mae: 0.4563 - mape: 3.5798 - val_loss: 0.2990 - val_mse: 0.2990 - val_mae: 0.4375 - val_mape: 3.4601\n",
      "Epoch 17/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2647 - mse: 0.2647 - mae: 0.4013 - mape: 3.1564 - val_loss: 0.2712 - val_mse: 0.2712 - val_mae: 0.4156 - val_mape: 3.2676\n",
      "Epoch 18/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2688 - mse: 0.2688 - mae: 0.4050 - mape: 3.1549 - val_loss: 0.2426 - val_mse: 0.2426 - val_mae: 0.3925 - val_mape: 3.0941\n",
      "Epoch 19/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2213 - mse: 0.2213 - mae: 0.3711 - mape: 2.9088 - val_loss: 0.2227 - val_mse: 0.2227 - val_mae: 0.3768 - val_mape: 2.9717\n",
      "Epoch 20/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1991 - mse: 0.1991 - mae: 0.3513 - mape: 2.7488 - val_loss: 0.2048 - val_mse: 0.2048 - val_mae: 0.3592 - val_mape: 2.8287\n",
      "Epoch 21/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1774 - mse: 0.1774 - mae: 0.3351 - mape: 2.6291 - val_loss: 0.1877 - val_mse: 0.1877 - val_mae: 0.3441 - val_mape: 2.7137\n",
      "Epoch 22/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1594 - mse: 0.1594 - mae: 0.3123 - mape: 2.4643 - val_loss: 0.1877 - val_mse: 0.1877 - val_mae: 0.3389 - val_mape: 2.6607\n",
      "Epoch 23/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1598 - mse: 0.1598 - mae: 0.3135 - mape: 2.4551 - val_loss: 0.1626 - val_mse: 0.1626 - val_mae: 0.3278 - val_mape: 2.5919\n",
      "Epoch 24/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1334 - mse: 0.1334 - mae: 0.2879 - mape: 2.2552 - val_loss: 0.1692 - val_mse: 0.1692 - val_mae: 0.3347 - val_mape: 2.6413\n",
      "Epoch 25/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1418 - mse: 0.1418 - mae: 0.2941 - mape: 2.2983 - val_loss: 0.1480 - val_mse: 0.1480 - val_mae: 0.3010 - val_mape: 2.3713\n",
      "Epoch 26/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1139 - mse: 0.1139 - mae: 0.2680 - mape: 2.0848 - val_loss: 0.1435 - val_mse: 0.1435 - val_mae: 0.3076 - val_mape: 2.4295\n",
      "Epoch 27/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1159 - mse: 0.1159 - mae: 0.2680 - mape: 2.1078 - val_loss: 0.1270 - val_mse: 0.1270 - val_mae: 0.2831 - val_mape: 2.2349\n",
      "Epoch 28/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1085 - mse: 0.1085 - mae: 0.2606 - mape: 2.0430 - val_loss: 0.1225 - val_mse: 0.1225 - val_mae: 0.2789 - val_mape: 2.2015\n",
      "Epoch 29/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1230 - mse: 0.1230 - mae: 0.2732 - mape: 2.1290 - val_loss: 0.1192 - val_mse: 0.1192 - val_mae: 0.2759 - val_mape: 2.1784\n",
      "Epoch 30/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1054 - mse: 0.1054 - mae: 0.2521 - mape: 1.9672 - val_loss: 0.1306 - val_mse: 0.1306 - val_mae: 0.2695 - val_mape: 2.1149\n",
      "Epoch 31/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1080 - mse: 0.1080 - mae: 0.2607 - mape: 2.0372 - val_loss: 0.1149 - val_mse: 0.1149 - val_mae: 0.2543 - val_mape: 2.0016\n",
      "Epoch 32/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0961 - mse: 0.0961 - mae: 0.2381 - mape: 1.8812 - val_loss: 0.1070 - val_mse: 0.1070 - val_mae: 0.2559 - val_mape: 2.0200\n",
      "Epoch 33/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0894 - mse: 0.0894 - mae: 0.2361 - mape: 1.8353 - val_loss: 0.1033 - val_mse: 0.1033 - val_mae: 0.2465 - val_mape: 1.9420\n",
      "Epoch 34/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0958 - mse: 0.0958 - mae: 0.2384 - mape: 1.8758 - val_loss: 0.1415 - val_mse: 0.1415 - val_mae: 0.2849 - val_mape: 2.2305\n",
      "Epoch 35/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1118 - mse: 0.1118 - mae: 0.2638 - mape: 2.0670 - val_loss: 0.1346 - val_mse: 0.1346 - val_mae: 0.2988 - val_mape: 2.3372\n",
      "Epoch 36/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1195 - mse: 0.1195 - mae: 0.2707 - mape: 2.1015 - val_loss: 0.1210 - val_mse: 0.1210 - val_mae: 0.2565 - val_mape: 2.0141\n",
      "Epoch 37/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1313 - mse: 0.1313 - mae: 0.2771 - mape: 2.1659 - val_loss: 0.0950 - val_mse: 0.0950 - val_mae: 0.2332 - val_mape: 1.8410\n",
      "Epoch 38/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0941 - mse: 0.0941 - mae: 0.2361 - mape: 1.8431 - val_loss: 0.0980 - val_mse: 0.0980 - val_mae: 0.2449 - val_mape: 1.9295\n",
      "Epoch 39/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0868 - mse: 0.0868 - mae: 0.2275 - mape: 1.7863 - val_loss: 0.0931 - val_mse: 0.0931 - val_mae: 0.2274 - val_mape: 1.7937\n",
      "Epoch 40/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1029 - mse: 0.1029 - mae: 0.2490 - mape: 1.9307 - val_loss: 0.0943 - val_mse: 0.0943 - val_mae: 0.2276 - val_mape: 1.7938\n",
      "Epoch 41/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0844 - mse: 0.0844 - mae: 0.2222 - mape: 1.7456 - val_loss: 0.1006 - val_mse: 0.1006 - val_mae: 0.2351 - val_mape: 1.8487\n",
      "Epoch 42/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0982 - mse: 0.0982 - mae: 0.2421 - mape: 1.8981 - val_loss: 0.0912 - val_mse: 0.0912 - val_mae: 0.2245 - val_mape: 1.7710\n",
      "Epoch 43/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0899 - mse: 0.0899 - mae: 0.2290 - mape: 1.7893 - val_loss: 0.0984 - val_mse: 0.0984 - val_mae: 0.2461 - val_mape: 1.9405\n",
      "Epoch 44/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0957 - mse: 0.0957 - mae: 0.2417 - mape: 1.8829 - val_loss: 0.0889 - val_mse: 0.0889 - val_mae: 0.2283 - val_mape: 1.8025\n",
      "Epoch 45/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0814 - mse: 0.0814 - mae: 0.2167 - mape: 1.6890 - val_loss: 0.0890 - val_mse: 0.0890 - val_mae: 0.2248 - val_mape: 1.7733\n",
      "Epoch 46/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0835 - mse: 0.0835 - mae: 0.2212 - mape: 1.7392 - val_loss: 0.0912 - val_mse: 0.0912 - val_mae: 0.2248 - val_mape: 1.7698\n",
      "Epoch 47/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0849 - mse: 0.0849 - mae: 0.2277 - mape: 1.7752 - val_loss: 0.1084 - val_mse: 0.1084 - val_mae: 0.2450 - val_mape: 1.9256\n",
      "Epoch 48/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1108 - mse: 0.1108 - mae: 0.2565 - mape: 1.9924 - val_loss: 0.0869 - val_mse: 0.0869 - val_mae: 0.2261 - val_mape: 1.7803\n",
      "Epoch 49/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0834 - mse: 0.0834 - mae: 0.2235 - mape: 1.7452 - val_loss: 0.0901 - val_mse: 0.0901 - val_mae: 0.2215 - val_mape: 1.7463\n",
      "Epoch 50/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0916 - mse: 0.0916 - mae: 0.2328 - mape: 1.8135 - val_loss: 0.1210 - val_mse: 0.1210 - val_mae: 0.2841 - val_mape: 2.2178\n",
      "Epoch 51/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0928 - mse: 0.0928 - mae: 0.2375 - mape: 1.8474 - val_loss: 0.0994 - val_mse: 0.0994 - val_mae: 0.2320 - val_mape: 1.8248\n",
      "Epoch 52/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0844 - mse: 0.0844 - mae: 0.2190 - mape: 1.7213 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2215 - val_mape: 1.7472\n",
      "Epoch 53/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0821 - mse: 0.0821 - mae: 0.2191 - mape: 1.7164 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2234 - val_mape: 1.7618\n",
      "Epoch 54/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0807 - mse: 0.0807 - mae: 0.2187 - mape: 1.6910 - val_loss: 0.0848 - val_mse: 0.0848 - val_mae: 0.2251 - val_mape: 1.7725\n",
      "Epoch 55/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0757 - mse: 0.0757 - mae: 0.2132 - mape: 1.6565 - val_loss: 0.1006 - val_mse: 0.1006 - val_mae: 0.2326 - val_mape: 1.8263\n",
      "Epoch 56/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0818 - mse: 0.0818 - mae: 0.2182 - mape: 1.7002 - val_loss: 0.0833 - val_mse: 0.0833 - val_mae: 0.2144 - val_mape: 1.6884\n",
      "Epoch 57/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0758 - mse: 0.0758 - mae: 0.2033 - mape: 1.5811 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2157 - val_mape: 1.6970\n",
      "Epoch 58/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0895 - mse: 0.0895 - mae: 0.2260 - mape: 1.7613 - val_loss: 0.0791 - val_mse: 0.0791 - val_mae: 0.2125 - val_mape: 1.6716\n",
      "Epoch 59/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0785 - mse: 0.0785 - mae: 0.2178 - mape: 1.6880 - val_loss: 0.1001 - val_mse: 0.1001 - val_mae: 0.2530 - val_mape: 1.9772\n",
      "Epoch 60/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0843 - mse: 0.0843 - mae: 0.2229 - mape: 1.7130 - val_loss: 0.0979 - val_mse: 0.0979 - val_mae: 0.2498 - val_mape: 1.9536\n",
      "Epoch 61/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0823 - mse: 0.0823 - mae: 0.2222 - mape: 1.7348 - val_loss: 0.0794 - val_mse: 0.0794 - val_mae: 0.2140 - val_mape: 1.6879\n",
      "Epoch 62/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0794 - mse: 0.0794 - mae: 0.2126 - mape: 1.6535 - val_loss: 0.0785 - val_mse: 0.0785 - val_mae: 0.2071 - val_mape: 1.6289\n",
      "Epoch 63/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0777 - mse: 0.0777 - mae: 0.2113 - mape: 1.6334 - val_loss: 0.0823 - val_mse: 0.0823 - val_mae: 0.2231 - val_mape: 1.7517\n",
      "Epoch 64/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0721 - mse: 0.0721 - mae: 0.2030 - mape: 1.5721 - val_loss: 0.0779 - val_mse: 0.0779 - val_mae: 0.2143 - val_mape: 1.6795\n",
      "Epoch 65/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0732 - mse: 0.0732 - mae: 0.2046 - mape: 1.5756 - val_loss: 0.0833 - val_mse: 0.0833 - val_mae: 0.2269 - val_mape: 1.7786\n",
      "Epoch 66/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0743 - mse: 0.0743 - mae: 0.2112 - mape: 1.6388 - val_loss: 0.0725 - val_mse: 0.0725 - val_mae: 0.2010 - val_mape: 1.5771\n",
      "Epoch 67/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0703 - mse: 0.0703 - mae: 0.1996 - mape: 1.5466 - val_loss: 0.0711 - val_mse: 0.0711 - val_mae: 0.1975 - val_mape: 1.5512\n",
      "Epoch 68/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0666 - mse: 0.0666 - mae: 0.1965 - mape: 1.5250 - val_loss: 0.0740 - val_mse: 0.0740 - val_mae: 0.2092 - val_mape: 1.6400\n",
      "Epoch 69/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0680 - mse: 0.0680 - mae: 0.1987 - mape: 1.5418 - val_loss: 0.0703 - val_mse: 0.0703 - val_mae: 0.2003 - val_mape: 1.5693\n",
      "Epoch 70/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0641 - mse: 0.0641 - mae: 0.1931 - mape: 1.5042 - val_loss: 0.0693 - val_mse: 0.0693 - val_mae: 0.1998 - val_mape: 1.5655\n",
      "Epoch 71/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0690 - mse: 0.0690 - mae: 0.2027 - mape: 1.5477 - val_loss: 0.0693 - val_mse: 0.0693 - val_mae: 0.2010 - val_mape: 1.5717\n",
      "Epoch 72/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0646 - mse: 0.0646 - mae: 0.1942 - mape: 1.5027 - val_loss: 0.0737 - val_mse: 0.0737 - val_mae: 0.2107 - val_mape: 1.6433\n",
      "Epoch 73/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0614 - mse: 0.0614 - mae: 0.1863 - mape: 1.4420 - val_loss: 0.0747 - val_mse: 0.0747 - val_mae: 0.2056 - val_mape: 1.6079\n",
      "Epoch 74/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0634 - mse: 0.0634 - mae: 0.1932 - mape: 1.4887 - val_loss: 0.0658 - val_mse: 0.0658 - val_mae: 0.1943 - val_mape: 1.5213\n",
      "Epoch 75/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0622 - mse: 0.0622 - mae: 0.1870 - mape: 1.4413 - val_loss: 0.0721 - val_mse: 0.0721 - val_mae: 0.1921 - val_mape: 1.5067\n",
      "Epoch 76/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0656 - mse: 0.0656 - mae: 0.1930 - mape: 1.5064 - val_loss: 0.0915 - val_mse: 0.0915 - val_mae: 0.2291 - val_mape: 1.7900\n",
      "Epoch 77/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0731 - mse: 0.0731 - mae: 0.2082 - mape: 1.6152 - val_loss: 0.0610 - val_mse: 0.0610 - val_mae: 0.1830 - val_mape: 1.4328\n",
      "Epoch 78/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0586 - mse: 0.0586 - mae: 0.1819 - mape: 1.4097 - val_loss: 0.0720 - val_mse: 0.0720 - val_mae: 0.2083 - val_mape: 1.6191\n",
      "Epoch 79/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0581 - mse: 0.0581 - mae: 0.1849 - mape: 1.4402 - val_loss: 0.0604 - val_mse: 0.0604 - val_mae: 0.1859 - val_mape: 1.4507\n",
      "Epoch 80/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0566 - mse: 0.0566 - mae: 0.1799 - mape: 1.3905 - val_loss: 0.0740 - val_mse: 0.0740 - val_mae: 0.2121 - val_mape: 1.6471\n",
      "Epoch 81/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0673 - mse: 0.0673 - mae: 0.2003 - mape: 1.5454 - val_loss: 0.0746 - val_mse: 0.0746 - val_mae: 0.2064 - val_mape: 1.6153\n",
      "Epoch 82/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0636 - mse: 0.0636 - mae: 0.1937 - mape: 1.4985 - val_loss: 0.0603 - val_mse: 0.0603 - val_mae: 0.1799 - val_mape: 1.4089\n",
      "Epoch 83/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0572 - mse: 0.0572 - mae: 0.1841 - mape: 1.4240 - val_loss: 0.0722 - val_mse: 0.0722 - val_mae: 0.1986 - val_mape: 1.5533\n",
      "Epoch 84/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1708 - mape: 1.3179 - val_loss: 0.0779 - val_mse: 0.0779 - val_mae: 0.2209 - val_mape: 1.7076\n",
      "Epoch 85/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0889 - mse: 0.0889 - mae: 0.2370 - mape: 1.8234 - val_loss: 0.0560 - val_mse: 0.0560 - val_mae: 0.1780 - val_mape: 1.3908\n",
      "Epoch 86/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0560 - mae: 0.1810 - mape: 1.3994 - val_loss: 0.0560 - val_mse: 0.0560 - val_mae: 0.1769 - val_mape: 1.3789\n",
      "Epoch 87/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1706 - mape: 1.3166 - val_loss: 0.0574 - val_mse: 0.0574 - val_mae: 0.1810 - val_mape: 1.4123\n",
      "Epoch 88/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0520 - mse: 0.0520 - mae: 0.1712 - mape: 1.3348 - val_loss: 0.0751 - val_mse: 0.0751 - val_mae: 0.2063 - val_mape: 1.6093\n",
      "Epoch 89/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0687 - mse: 0.0687 - mae: 0.1968 - mape: 1.5321 - val_loss: 0.0545 - val_mse: 0.0545 - val_mae: 0.1745 - val_mape: 1.3616\n",
      "Epoch 90/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1700 - mape: 1.3101 - val_loss: 0.0730 - val_mse: 0.0730 - val_mae: 0.1903 - val_mape: 1.4918\n",
      "Epoch 91/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0613 - mse: 0.0613 - mae: 0.1894 - mape: 1.4595 - val_loss: 0.0578 - val_mse: 0.0578 - val_mae: 0.1838 - val_mape: 1.4296\n",
      "Epoch 92/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1695 - mape: 1.3144 - val_loss: 0.0654 - val_mse: 0.0654 - val_mae: 0.1983 - val_mape: 1.5337\n",
      "Epoch 93/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1696 - mape: 1.3048 - val_loss: 0.0591 - val_mse: 0.0591 - val_mae: 0.1809 - val_mape: 1.4134\n",
      "Epoch 94/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1708 - mape: 1.3155 - val_loss: 0.0640 - val_mse: 0.0640 - val_mae: 0.1899 - val_mape: 1.4846\n",
      "Epoch 95/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0440 - mse: 0.0440 - mae: 0.1628 - mape: 1.2513 - val_loss: 0.0538 - val_mse: 0.0538 - val_mae: 0.1750 - val_mape: 1.3652\n",
      "Epoch 96/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1664 - mape: 1.2834 - val_loss: 0.0541 - val_mse: 0.0541 - val_mae: 0.1687 - val_mape: 1.3201\n",
      "Epoch 97/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1710 - mape: 1.3187 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1720 - val_mape: 1.3406\n",
      "Epoch 98/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1640 - mape: 1.2685 - val_loss: 0.0616 - val_mse: 0.0616 - val_mae: 0.1913 - val_mape: 1.4843\n",
      "Epoch 99/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1728 - mape: 1.3279 - val_loss: 0.0548 - val_mse: 0.0548 - val_mae: 0.1795 - val_mape: 1.4030\n",
      "Epoch 100/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0416 - mae: 0.1586 - mape: 1.2207 - val_loss: 0.0544 - val_mse: 0.0544 - val_mae: 0.1711 - val_mape: 1.3372\n",
      "Epoch 101/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0439 - mse: 0.0439 - mae: 0.1604 - mape: 1.2221 - val_loss: 0.0509 - val_mse: 0.0509 - val_mae: 0.1696 - val_mape: 1.3239\n",
      "Epoch 102/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0450 - mse: 0.0450 - mae: 0.1614 - mape: 1.2417 - val_loss: 0.0864 - val_mse: 0.0864 - val_mae: 0.2332 - val_mape: 1.7970\n",
      "Epoch 103/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0533 - mse: 0.0533 - mae: 0.1772 - mape: 1.3619 - val_loss: 0.0526 - val_mse: 0.0526 - val_mae: 0.1698 - val_mape: 1.3272\n",
      "Epoch 104/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0438 - mse: 0.0438 - mae: 0.1637 - mape: 1.2678 - val_loss: 0.0547 - val_mse: 0.0547 - val_mae: 0.1807 - val_mape: 1.4045\n",
      "Epoch 105/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0439 - mse: 0.0439 - mae: 0.1653 - mape: 1.2811 - val_loss: 0.0572 - val_mse: 0.0572 - val_mae: 0.1845 - val_mape: 1.4327\n",
      "Epoch 106/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0414 - mae: 0.1590 - mape: 1.2265 - val_loss: 0.0504 - val_mse: 0.0504 - val_mae: 0.1664 - val_mape: 1.2941\n",
      "Epoch 107/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0437 - mse: 0.0437 - mae: 0.1598 - mape: 1.2297 - val_loss: 0.1187 - val_mse: 0.1187 - val_mae: 0.2719 - val_mape: 2.1233\n",
      "Epoch 108/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0653 - mse: 0.0653 - mae: 0.1994 - mape: 1.5245 - val_loss: 0.0710 - val_mse: 0.0710 - val_mae: 0.2096 - val_mape: 1.6181\n",
      "Epoch 109/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0515 - mse: 0.0515 - mae: 0.1781 - mape: 1.3677 - val_loss: 0.0541 - val_mse: 0.0541 - val_mae: 0.1696 - val_mape: 1.3256\n",
      "Epoch 110/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0442 - mse: 0.0442 - mae: 0.1609 - mape: 1.2408 - val_loss: 0.0531 - val_mse: 0.0531 - val_mae: 0.1705 - val_mape: 1.3311\n",
      "Epoch 111/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0394 - mae: 0.1523 - mape: 1.1706 - val_loss: 0.0652 - val_mse: 0.0652 - val_mae: 0.1949 - val_mape: 1.5166\n",
      "Epoch 112/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1695 - mape: 1.3135 - val_loss: 0.0498 - val_mse: 0.0498 - val_mae: 0.1663 - val_mape: 1.2994\n",
      "Epoch 113/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0419 - mae: 0.1584 - mape: 1.2154 - val_loss: 0.0602 - val_mse: 0.0602 - val_mae: 0.1898 - val_mape: 1.4695\n",
      "Epoch 114/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1639 - mape: 1.2655 - val_loss: 0.0489 - val_mse: 0.0489 - val_mae: 0.1649 - val_mape: 1.2880\n",
      "Epoch 115/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0425 - mse: 0.0425 - mae: 0.1583 - mape: 1.2212 - val_loss: 0.0553 - val_mse: 0.0553 - val_mae: 0.1809 - val_mape: 1.4044\n",
      "Epoch 116/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0580 - mse: 0.0580 - mae: 0.1844 - mape: 1.4255 - val_loss: 0.0572 - val_mse: 0.0572 - val_mae: 0.1758 - val_mape: 1.3730\n",
      "Epoch 117/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0528 - mse: 0.0528 - mae: 0.1789 - mape: 1.3874 - val_loss: 0.0509 - val_mse: 0.0509 - val_mae: 0.1673 - val_mape: 1.3066\n",
      "Epoch 118/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0395 - mse: 0.0395 - mae: 0.1567 - mape: 1.2015 - val_loss: 0.0562 - val_mse: 0.0562 - val_mae: 0.1763 - val_mape: 1.3827\n",
      "Epoch 119/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0419 - mae: 0.1591 - mape: 1.2343 - val_loss: 0.0550 - val_mse: 0.0550 - val_mae: 0.1784 - val_mape: 1.3954\n",
      "Epoch 120/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0413 - mae: 0.1558 - mape: 1.2011 - val_loss: 0.0528 - val_mse: 0.0528 - val_mae: 0.1689 - val_mape: 1.3226\n",
      "Epoch 121/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0522 - mse: 0.0522 - mae: 0.1753 - mape: 1.3545 - val_loss: 0.0508 - val_mse: 0.0508 - val_mae: 0.1716 - val_mape: 1.3351\n",
      "Epoch 122/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0411 - mae: 0.1577 - mape: 1.2169 - val_loss: 0.0597 - val_mse: 0.0597 - val_mae: 0.1889 - val_mape: 1.4659\n",
      "Epoch 123/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0426 - mae: 0.1577 - mape: 1.2127 - val_loss: 0.0483 - val_mse: 0.0483 - val_mae: 0.1655 - val_mape: 1.2896\n",
      "Epoch 124/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0441 - mse: 0.0441 - mae: 0.1602 - mape: 1.2346 - val_loss: 0.0491 - val_mse: 0.0491 - val_mae: 0.1645 - val_mape: 1.2824\n",
      "Epoch 125/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0401 - mse: 0.0401 - mae: 0.1559 - mape: 1.2072 - val_loss: 0.0527 - val_mse: 0.0527 - val_mae: 0.1672 - val_mape: 1.3005\n",
      "Epoch 126/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0446 - mse: 0.0446 - mae: 0.1592 - mape: 1.2271 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1698 - val_mape: 1.3282\n",
      "Epoch 127/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0422 - mae: 0.1560 - mape: 1.1956 - val_loss: 0.0573 - val_mse: 0.0573 - val_mae: 0.1807 - val_mape: 1.4084\n",
      "Epoch 128/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0401 - mse: 0.0401 - mae: 0.1565 - mape: 1.2064 - val_loss: 0.0515 - val_mse: 0.0515 - val_mae: 0.1647 - val_mape: 1.2848\n",
      "Epoch 129/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0428 - mse: 0.0428 - mae: 0.1597 - mape: 1.2330 - val_loss: 0.0503 - val_mse: 0.0503 - val_mae: 0.1702 - val_mape: 1.3242\n",
      "Epoch 130/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0392 - mse: 0.0392 - mae: 0.1509 - mape: 1.1641 - val_loss: 0.0903 - val_mse: 0.0903 - val_mae: 0.2390 - val_mape: 1.8643\n",
      "Epoch 131/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0545 - mse: 0.0545 - mae: 0.1861 - mape: 1.4381 - val_loss: 0.0713 - val_mse: 0.0713 - val_mae: 0.2167 - val_mape: 1.6728\n",
      "Epoch 132/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1751 - mape: 1.3507 - val_loss: 0.0780 - val_mse: 0.0780 - val_mae: 0.2242 - val_mape: 1.7291\n",
      "Epoch 133/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0576 - mse: 0.0576 - mae: 0.1944 - mape: 1.4979 - val_loss: 0.0509 - val_mse: 0.0509 - val_mae: 0.1654 - val_mape: 1.2915\n",
      "Epoch 134/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0401 - mse: 0.0401 - mae: 0.1555 - mape: 1.1887 - val_loss: 0.0691 - val_mse: 0.0691 - val_mae: 0.1997 - val_mape: 1.5566\n",
      "Epoch 135/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1707 - mape: 1.2970 - val_loss: 0.0482 - val_mse: 0.0482 - val_mae: 0.1674 - val_mape: 1.3091\n",
      "Epoch 136/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0396 - mae: 0.1530 - mape: 1.1751 - val_loss: 0.0539 - val_mse: 0.0539 - val_mae: 0.1780 - val_mape: 1.3788\n",
      "Epoch 137/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0412 - mae: 0.1576 - mape: 1.2041 - val_loss: 0.0538 - val_mse: 0.0538 - val_mae: 0.1693 - val_mape: 1.3226\n",
      "Epoch 138/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0437 - mse: 0.0437 - mae: 0.1605 - mape: 1.2333 - val_loss: 0.0542 - val_mse: 0.0542 - val_mae: 0.1737 - val_mape: 1.3603\n",
      "Epoch 139/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0405 - mse: 0.0405 - mae: 0.1549 - mape: 1.1947 - val_loss: 0.0597 - val_mse: 0.0597 - val_mae: 0.1836 - val_mape: 1.4380\n",
      "Epoch 140/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0418 - mae: 0.1579 - mape: 1.2090 - val_loss: 0.0524 - val_mse: 0.0524 - val_mae: 0.1749 - val_mape: 1.3513\n",
      "Epoch 141/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0405 - mse: 0.0405 - mae: 0.1559 - mape: 1.2048 - val_loss: 0.0474 - val_mse: 0.0474 - val_mae: 0.1648 - val_mape: 1.2855\n",
      "Epoch 142/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0431 - mae: 0.1630 - mape: 1.2578 - val_loss: 0.0467 - val_mse: 0.0467 - val_mae: 0.1647 - val_mape: 1.2874\n",
      "Epoch 143/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0402 - mse: 0.0402 - mae: 0.1572 - mape: 1.2097 - val_loss: 0.0490 - val_mse: 0.0490 - val_mae: 0.1663 - val_mape: 1.2949\n",
      "Epoch 144/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0362 - mae: 0.1482 - mape: 1.1350 - val_loss: 0.0558 - val_mse: 0.0558 - val_mae: 0.1803 - val_mape: 1.4021\n",
      "Epoch 145/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0404 - mse: 0.0404 - mae: 0.1546 - mape: 1.1845 - val_loss: 0.0494 - val_mse: 0.0494 - val_mae: 0.1626 - val_mape: 1.2698\n",
      "Epoch 146/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0376 - mse: 0.0376 - mae: 0.1501 - mape: 1.1584 - val_loss: 0.0482 - val_mse: 0.0482 - val_mae: 0.1638 - val_mape: 1.2759\n",
      "Epoch 147/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0426 - mae: 0.1612 - mape: 1.2315 - val_loss: 0.0487 - val_mse: 0.0487 - val_mae: 0.1669 - val_mape: 1.3036\n",
      "Epoch 148/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0366 - mse: 0.0366 - mae: 0.1488 - mape: 1.1456 - val_loss: 0.0559 - val_mse: 0.0559 - val_mae: 0.1811 - val_mape: 1.4201\n",
      "Epoch 149/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0460 - mse: 0.0460 - mae: 0.1675 - mape: 1.2929 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1792 - val_mape: 1.3874\n",
      "Epoch 150/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0399 - mse: 0.0399 - mae: 0.1517 - mape: 1.1601 - val_loss: 0.0530 - val_mse: 0.0530 - val_mae: 0.1700 - val_mape: 1.3311\n",
      "Epoch 151/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0394 - mae: 0.1527 - mape: 1.1704 - val_loss: 0.0655 - val_mse: 0.0655 - val_mae: 0.2016 - val_mape: 1.5607\n",
      "Epoch 152/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0458 - mse: 0.0458 - mae: 0.1605 - mape: 1.2361 - val_loss: 0.0479 - val_mse: 0.0479 - val_mae: 0.1631 - val_mape: 1.2722\n",
      "Epoch 153/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1652 - mape: 1.2636 - val_loss: 0.0456 - val_mse: 0.0456 - val_mae: 0.1589 - val_mape: 1.2424\n",
      "Epoch 154/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0362 - mse: 0.0362 - mae: 0.1479 - mape: 1.1299 - val_loss: 0.0512 - val_mse: 0.0512 - val_mae: 0.1727 - val_mape: 1.3411\n",
      "Epoch 155/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0359 - mse: 0.0359 - mae: 0.1479 - mape: 1.1157 - val_loss: 0.0573 - val_mse: 0.0573 - val_mae: 0.1822 - val_mape: 1.4168\n",
      "Epoch 156/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0400 - mse: 0.0400 - mae: 0.1571 - mape: 1.2056 - val_loss: 0.0531 - val_mse: 0.0531 - val_mae: 0.1748 - val_mape: 1.3534\n",
      "Epoch 157/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0369 - mse: 0.0369 - mae: 0.1516 - mape: 1.1639 - val_loss: 0.0541 - val_mse: 0.0541 - val_mae: 0.1793 - val_mape: 1.3881\n",
      "Epoch 158/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0407 - mse: 0.0407 - mae: 0.1569 - mape: 1.2099 - val_loss: 0.0499 - val_mse: 0.0499 - val_mae: 0.1654 - val_mape: 1.2937\n",
      "Epoch 159/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0363 - mse: 0.0363 - mae: 0.1487 - mape: 1.1541 - val_loss: 0.0564 - val_mse: 0.0564 - val_mae: 0.1751 - val_mape: 1.3751\n",
      "Epoch 160/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0385 - mae: 0.1500 - mape: 1.1552 - val_loss: 0.0836 - val_mse: 0.0836 - val_mae: 0.2375 - val_mape: 1.8297\n",
      "Epoch 161/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1602 - mape: 1.2286 - val_loss: 0.0485 - val_mse: 0.0485 - val_mae: 0.1619 - val_mape: 1.2675\n",
      "Epoch 162/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0394 - mae: 0.1511 - mape: 1.1565 - val_loss: 0.0625 - val_mse: 0.0625 - val_mae: 0.1943 - val_mape: 1.5011\n",
      "Epoch 163/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1628 - mape: 1.2506 - val_loss: 0.0505 - val_mse: 0.0505 - val_mae: 0.1659 - val_mape: 1.2954\n",
      "Epoch 164/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0384 - mse: 0.0384 - mae: 0.1524 - mape: 1.1669 - val_loss: 0.0575 - val_mse: 0.0575 - val_mae: 0.1763 - val_mape: 1.3851\n",
      "Epoch 165/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0394 - mae: 0.1557 - mape: 1.1971 - val_loss: 0.0475 - val_mse: 0.0475 - val_mae: 0.1655 - val_mape: 1.2939\n",
      "Epoch 166/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0346 - mse: 0.0346 - mae: 0.1435 - mape: 1.1067 - val_loss: 0.0545 - val_mse: 0.0545 - val_mae: 0.1738 - val_mape: 1.3509\n",
      "Epoch 167/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0365 - mse: 0.0365 - mae: 0.1469 - mape: 1.1254 - val_loss: 0.0809 - val_mse: 0.0809 - val_mae: 0.2200 - val_mape: 1.7307\n",
      "Epoch 168/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0404 - mse: 0.0404 - mae: 0.1561 - mape: 1.2109 - val_loss: 0.0694 - val_mse: 0.0694 - val_mae: 0.1992 - val_mape: 1.5501\n",
      "Epoch 169/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0389 - mse: 0.0389 - mae: 0.1541 - mape: 1.1831 - val_loss: 0.0889 - val_mse: 0.0889 - val_mae: 0.2327 - val_mape: 1.8095\n",
      "Epoch 170/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0432 - mse: 0.0432 - mae: 0.1600 - mape: 1.2285 - val_loss: 0.0767 - val_mse: 0.0767 - val_mae: 0.2253 - val_mape: 1.7385\n",
      "Epoch 171/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0719 - mse: 0.0719 - mae: 0.2183 - mape: 1.6596 - val_loss: 0.0514 - val_mse: 0.0514 - val_mae: 0.1632 - val_mape: 1.2759\n",
      "Epoch 172/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0340 - mse: 0.0340 - mae: 0.1421 - mape: 1.0890 - val_loss: 0.0527 - val_mse: 0.0527 - val_mae: 0.1667 - val_mape: 1.3097\n",
      "Epoch 173/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0355 - mse: 0.0355 - mae: 0.1463 - mape: 1.1218 - val_loss: 0.0481 - val_mse: 0.0481 - val_mae: 0.1601 - val_mape: 1.2559\n",
      "Epoch 174/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0347 - mse: 0.0347 - mae: 0.1449 - mape: 1.1244 - val_loss: 0.0569 - val_mse: 0.0569 - val_mae: 0.1805 - val_mape: 1.4040\n",
      "Epoch 175/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.1826 - mape: 1.3871 - val_loss: 0.0501 - val_mse: 0.0501 - val_mae: 0.1679 - val_mape: 1.3147\n",
      "Epoch 176/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0352 - mse: 0.0352 - mae: 0.1455 - mape: 1.1293 - val_loss: 0.0545 - val_mse: 0.0545 - val_mae: 0.1687 - val_mape: 1.3210\n",
      "Epoch 177/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0448 - mse: 0.0448 - mae: 0.1680 - mape: 1.2894 - val_loss: 0.0465 - val_mse: 0.0465 - val_mae: 0.1571 - val_mape: 1.2299\n",
      "Epoch 178/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0353 - mse: 0.0353 - mae: 0.1455 - mape: 1.1166 - val_loss: 0.0494 - val_mse: 0.0494 - val_mae: 0.1660 - val_mape: 1.2979\n",
      "Epoch 179/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0357 - mae: 0.1503 - mape: 1.1516 - val_loss: 0.0509 - val_mse: 0.0509 - val_mae: 0.1674 - val_mape: 1.3081\n",
      "Epoch 180/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0330 - mse: 0.0330 - mae: 0.1422 - mape: 1.0938 - val_loss: 0.0595 - val_mse: 0.0595 - val_mae: 0.1834 - val_mape: 1.4263\n",
      "Epoch 181/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0369 - mse: 0.0369 - mae: 0.1489 - mape: 1.1379 - val_loss: 0.0547 - val_mse: 0.0547 - val_mae: 0.1780 - val_mape: 1.3821\n",
      "Epoch 182/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0396 - mae: 0.1554 - mape: 1.1884 - val_loss: 0.0587 - val_mse: 0.0587 - val_mae: 0.1749 - val_mape: 1.3681\n",
      "Epoch 183/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0367 - mse: 0.0367 - mae: 0.1492 - mape: 1.1432 - val_loss: 0.0567 - val_mse: 0.0567 - val_mae: 0.1841 - val_mape: 1.4319\n",
      "Epoch 184/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0422 - mae: 0.1599 - mape: 1.2188 - val_loss: 0.0473 - val_mse: 0.0473 - val_mae: 0.1596 - val_mape: 1.2504\n",
      "Epoch 185/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0377 - mse: 0.0377 - mae: 0.1488 - mape: 1.1387 - val_loss: 0.0677 - val_mse: 0.0677 - val_mae: 0.2009 - val_mape: 1.5526\n",
      "Epoch 186/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0560 - mae: 0.1846 - mape: 1.4164 - val_loss: 0.0498 - val_mse: 0.0498 - val_mae: 0.1626 - val_mape: 1.2753\n",
      "Epoch 187/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0366 - mse: 0.0366 - mae: 0.1486 - mape: 1.1335 - val_loss: 0.0608 - val_mse: 0.0608 - val_mae: 0.1887 - val_mape: 1.4511\n",
      "Epoch 188/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0325 - mae: 0.1404 - mape: 1.0758 - val_loss: 0.0553 - val_mse: 0.0553 - val_mae: 0.1710 - val_mape: 1.3449\n",
      "Epoch 189/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0439 - mse: 0.0439 - mae: 0.1653 - mape: 1.2758 - val_loss: 0.0752 - val_mse: 0.0752 - val_mae: 0.2072 - val_mape: 1.6206\n",
      "Epoch 190/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0568 - mse: 0.0568 - mae: 0.1841 - mape: 1.4076 - val_loss: 0.0461 - val_mse: 0.0461 - val_mae: 0.1559 - val_mape: 1.2174\n",
      "Epoch 191/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - mae: 0.1447 - mape: 1.1113 - val_loss: 0.0646 - val_mse: 0.0646 - val_mae: 0.1973 - val_mape: 1.5254\n",
      "Epoch 192/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0355 - mse: 0.0355 - mae: 0.1457 - mape: 1.1119 - val_loss: 0.0551 - val_mse: 0.0551 - val_mae: 0.1663 - val_mape: 1.3066\n",
      "Epoch 193/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0345 - mse: 0.0345 - mae: 0.1439 - mape: 1.1063 - val_loss: 0.0586 - val_mse: 0.0586 - val_mae: 0.1749 - val_mape: 1.3711\n",
      "Epoch 194/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0438 - mse: 0.0438 - mae: 0.1617 - mape: 1.2466 - val_loss: 0.0501 - val_mse: 0.0501 - val_mae: 0.1692 - val_mape: 1.3210\n",
      "Epoch 195/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1740 - mape: 1.3385 - val_loss: 0.0524 - val_mse: 0.0524 - val_mae: 0.1697 - val_mape: 1.3256\n",
      "Epoch 196/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.1386 - mape: 1.0601 - val_loss: 0.0879 - val_mse: 0.0879 - val_mae: 0.2434 - val_mape: 1.8804\n",
      "Epoch 197/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0406 - mse: 0.0406 - mae: 0.1599 - mape: 1.2316 - val_loss: 0.0618 - val_mse: 0.0618 - val_mae: 0.1859 - val_mape: 1.4523\n",
      "Epoch 198/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0366 - mse: 0.0366 - mae: 0.1492 - mape: 1.1558 - val_loss: 0.0565 - val_mse: 0.0565 - val_mae: 0.1679 - val_mape: 1.3137\n",
      "Epoch 199/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0308 - mse: 0.0308 - mae: 0.1362 - mape: 1.0433 - val_loss: 0.0500 - val_mse: 0.0500 - val_mae: 0.1650 - val_mape: 1.2922\n",
      "Epoch 200/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0335 - mse: 0.0335 - mae: 0.1427 - mape: 1.0997 - val_loss: 0.0540 - val_mse: 0.0540 - val_mae: 0.1662 - val_mape: 1.3048\n",
      "Epoch 201/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0351 - mse: 0.0351 - mae: 0.1455 - mape: 1.1160 - val_loss: 0.0503 - val_mse: 0.0503 - val_mae: 0.1598 - val_mape: 1.2532\n",
      "Epoch 202/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0328 - mse: 0.0328 - mae: 0.1428 - mape: 1.0943 - val_loss: 0.0481 - val_mse: 0.0481 - val_mae: 0.1573 - val_mape: 1.2322\n",
      "Epoch 203/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0387 - mse: 0.0387 - mae: 0.1518 - mape: 1.1613 - val_loss: 0.0614 - val_mse: 0.0614 - val_mae: 0.1904 - val_mape: 1.4699\n",
      "Epoch 204/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0339 - mse: 0.0339 - mae: 0.1450 - mape: 1.1170 - val_loss: 0.0527 - val_mse: 0.0527 - val_mae: 0.1654 - val_mape: 1.2929\n",
      "Epoch 205/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0321 - mse: 0.0321 - mae: 0.1409 - mape: 1.0798 - val_loss: 0.0512 - val_mse: 0.0512 - val_mae: 0.1723 - val_mape: 1.3406\n",
      "Epoch 206/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0356 - mae: 0.1472 - mape: 1.1275 - val_loss: 0.0521 - val_mse: 0.0521 - val_mae: 0.1633 - val_mape: 1.2768\n",
      "Epoch 207/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0356 - mae: 0.1468 - mape: 1.1266 - val_loss: 0.0891 - val_mse: 0.0891 - val_mae: 0.2474 - val_mape: 1.9106\n",
      "Epoch 208/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0451 - mse: 0.0451 - mae: 0.1698 - mape: 1.2964 - val_loss: 0.0475 - val_mse: 0.0475 - val_mae: 0.1573 - val_mape: 1.2334\n",
      "Epoch 209/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0294 - mse: 0.0294 - mae: 0.1343 - mape: 1.0312 - val_loss: 0.0646 - val_mse: 0.0646 - val_mae: 0.1835 - val_mape: 1.4409\n",
      "Epoch 210/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0371 - mse: 0.0371 - mae: 0.1487 - mape: 1.1389 - val_loss: 0.0654 - val_mse: 0.0654 - val_mae: 0.1993 - val_mape: 1.5515\n",
      "Epoch 211/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0379 - mae: 0.1544 - mape: 1.1867 - val_loss: 0.0460 - val_mse: 0.0460 - val_mae: 0.1584 - val_mape: 1.2393\n",
      "Epoch 212/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0297 - mse: 0.0297 - mae: 0.1338 - mape: 1.0351 - val_loss: 0.0495 - val_mse: 0.0495 - val_mae: 0.1599 - val_mape: 1.2511\n",
      "Epoch 213/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0301 - mse: 0.0301 - mae: 0.1347 - mape: 1.0343 - val_loss: 0.0528 - val_mse: 0.0528 - val_mae: 0.1727 - val_mape: 1.3448\n",
      "Epoch 214/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.1413 - mape: 1.0809 - val_loss: 0.0653 - val_mse: 0.0653 - val_mae: 0.1833 - val_mape: 1.4380\n",
      "Epoch 215/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0296 - mse: 0.0296 - mae: 0.1334 - mape: 1.0302 - val_loss: 0.0557 - val_mse: 0.0557 - val_mae: 0.1792 - val_mape: 1.3869\n",
      "Epoch 216/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0326 - mse: 0.0326 - mae: 0.1404 - mape: 1.0771 - val_loss: 0.0491 - val_mse: 0.0491 - val_mae: 0.1628 - val_mape: 1.2770\n",
      "Epoch 217/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0316 - mae: 0.1393 - mape: 1.0667 - val_loss: 0.0939 - val_mse: 0.0939 - val_mae: 0.2498 - val_mape: 1.9220\n",
      "Epoch 218/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0520 - mse: 0.0520 - mae: 0.1808 - mape: 1.3938 - val_loss: 0.0461 - val_mse: 0.0461 - val_mae: 0.1548 - val_mape: 1.2107\n",
      "Epoch 219/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0304 - mse: 0.0304 - mae: 0.1354 - mape: 1.0406 - val_loss: 0.0535 - val_mse: 0.0535 - val_mae: 0.1684 - val_mape: 1.3113\n",
      "Epoch 220/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0342 - mse: 0.0342 - mae: 0.1451 - mape: 1.1074 - val_loss: 0.0489 - val_mse: 0.0489 - val_mae: 0.1578 - val_mape: 1.2366\n",
      "Epoch 221/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0334 - mse: 0.0334 - mae: 0.1429 - mape: 1.0930 - val_loss: 0.0473 - val_mse: 0.0473 - val_mae: 0.1558 - val_mape: 1.2221\n",
      "Epoch 222/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0292 - mse: 0.0292 - mae: 0.1337 - mape: 1.0269 - val_loss: 0.0507 - val_mse: 0.0507 - val_mae: 0.1614 - val_mape: 1.2644\n",
      "Epoch 223/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0338 - mse: 0.0338 - mae: 0.1397 - mape: 1.0735 - val_loss: 0.0491 - val_mse: 0.0491 - val_mae: 0.1568 - val_mape: 1.2342\n",
      "Epoch 224/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0308 - mse: 0.0308 - mae: 0.1379 - mape: 1.0583 - val_loss: 0.0524 - val_mse: 0.0524 - val_mae: 0.1695 - val_mape: 1.3183\n",
      "Epoch 225/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0327 - mse: 0.0327 - mae: 0.1406 - mape: 1.0835 - val_loss: 0.0779 - val_mse: 0.0779 - val_mae: 0.2082 - val_mape: 1.6333\n",
      "Epoch 226/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0398 - mse: 0.0398 - mae: 0.1571 - mape: 1.2008 - val_loss: 0.0613 - val_mse: 0.0613 - val_mae: 0.1820 - val_mape: 1.4324\n",
      "Epoch 227/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0314 - mse: 0.0314 - mae: 0.1349 - mape: 1.0340 - val_loss: 0.0670 - val_mse: 0.0670 - val_mae: 0.1913 - val_mape: 1.5004\n",
      "Epoch 228/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0352 - mse: 0.0352 - mae: 0.1461 - mape: 1.1313 - val_loss: 0.0517 - val_mse: 0.0517 - val_mae: 0.1650 - val_mape: 1.2974\n",
      "Epoch 229/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0357 - mae: 0.1483 - mape: 1.1367 - val_loss: 0.0623 - val_mse: 0.0623 - val_mae: 0.1823 - val_mape: 1.4306\n",
      "Epoch 230/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0405 - mse: 0.0405 - mae: 0.1573 - mape: 1.2037 - val_loss: 0.0520 - val_mse: 0.0520 - val_mae: 0.1676 - val_mape: 1.3137\n",
      "Epoch 231/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0309 - mse: 0.0309 - mae: 0.1357 - mape: 1.0562 - val_loss: 0.0504 - val_mse: 0.0504 - val_mae: 0.1606 - val_mape: 1.2577\n",
      "Epoch 232/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0271 - mse: 0.0271 - mae: 0.1290 - mape: 0.9866 - val_loss: 0.0522 - val_mse: 0.0522 - val_mae: 0.1691 - val_mape: 1.3222\n",
      "Epoch 233/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0314 - mse: 0.0314 - mae: 0.1397 - mape: 1.0669 - val_loss: 0.0719 - val_mse: 0.0719 - val_mae: 0.2088 - val_mape: 1.6146\n",
      "Epoch 234/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0360 - mse: 0.0360 - mae: 0.1490 - mape: 1.1431 - val_loss: 0.0571 - val_mse: 0.0571 - val_mae: 0.1699 - val_mape: 1.3331\n",
      "Epoch 235/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0351 - mse: 0.0351 - mae: 0.1437 - mape: 1.1068 - val_loss: 0.0695 - val_mse: 0.0695 - val_mae: 0.1898 - val_mape: 1.4915\n",
      "Epoch 236/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0417 - mae: 0.1592 - mape: 1.2293 - val_loss: 0.0672 - val_mse: 0.0672 - val_mae: 0.1929 - val_mape: 1.5061\n",
      "Epoch 237/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0344 - mse: 0.0344 - mae: 0.1439 - mape: 1.1122 - val_loss: 0.0491 - val_mse: 0.0491 - val_mae: 0.1620 - val_mape: 1.2659\n",
      "Epoch 238/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0297 - mse: 0.0297 - mae: 0.1346 - mape: 1.0300 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2211 - val_mape: 1.7285\n",
      "Epoch 239/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0377 - mse: 0.0377 - mae: 0.1547 - mape: 1.1919 - val_loss: 0.0651 - val_mse: 0.0651 - val_mae: 0.1965 - val_mape: 1.5203\n",
      "Epoch 240/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0336 - mse: 0.0336 - mae: 0.1446 - mape: 1.1054 - val_loss: 0.0484 - val_mse: 0.0484 - val_mae: 0.1615 - val_mape: 1.2658\n",
      "Epoch 241/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0310 - mse: 0.0310 - mae: 0.1326 - mape: 1.0183 - val_loss: 0.0538 - val_mse: 0.0538 - val_mae: 0.1617 - val_mape: 1.2684\n",
      "Epoch 242/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0299 - mse: 0.0299 - mae: 0.1357 - mape: 1.0374 - val_loss: 0.0531 - val_mse: 0.0531 - val_mae: 0.1679 - val_mape: 1.3140\n",
      "Epoch 243/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0292 - mse: 0.0292 - mae: 0.1316 - mape: 1.0060 - val_loss: 0.0465 - val_mse: 0.0465 - val_mae: 0.1556 - val_mape: 1.2206\n",
      "Epoch 244/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0270 - mse: 0.0270 - mae: 0.1263 - mape: 0.9736 - val_loss: 0.0516 - val_mse: 0.0516 - val_mae: 0.1623 - val_mape: 1.2741\n",
      "Epoch 245/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0332 - mse: 0.0332 - mae: 0.1423 - mape: 1.0825 - val_loss: 0.0516 - val_mse: 0.0516 - val_mae: 0.1628 - val_mape: 1.2749\n",
      "Epoch 246/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0306 - mse: 0.0306 - mae: 0.1343 - mape: 1.0329 - val_loss: 0.0528 - val_mse: 0.0528 - val_mae: 0.1688 - val_mape: 1.3212\n",
      "Epoch 247/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0288 - mse: 0.0288 - mae: 0.1332 - mape: 1.0232 - val_loss: 0.0589 - val_mse: 0.0589 - val_mae: 0.1747 - val_mape: 1.3742\n",
      "Epoch 248/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.1411 - mape: 1.0939 - val_loss: 0.0535 - val_mse: 0.0535 - val_mae: 0.1609 - val_mape: 1.2665\n",
      "Epoch 249/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0319 - mse: 0.0319 - mae: 0.1387 - mape: 1.0747 - val_loss: 0.0523 - val_mse: 0.0523 - val_mae: 0.1683 - val_mape: 1.3133\n",
      "Epoch 250/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0298 - mae: 0.1358 - mape: 1.0356 - val_loss: 0.0641 - val_mse: 0.0641 - val_mae: 0.1931 - val_mape: 1.4933\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs = 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00080-549e427e-5233-4053-93e7-980d790e0878",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Subsequently, after all the epochs, we decided to plot the loss function for the training and the test set respectively as the graph is capable of giving useful insight in terms of overfitting or underfitting. \n",
    "\n",
    "Hence, as it can be see from the following line graph, it seems that model learns quikly how to correctly adjust all the parameters suggesting that 250 epochs would be to much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00080-ae0cf6b4-b10e-4029-ae78-4c641647eaf4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 851,
    "execution_start": 1621687951187,
    "scrolled": true,
    "source_hash": "791495d5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.044, Test: 0.066\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 264,
       "width": 375
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_mse = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse[0], test_mse[0]))\n",
    "# plot loss during training\n",
    "plt.title('Loss / Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00028-82e205f7-429f-4cc6-b775-c2cb70155ed3",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 250\n"
     ]
    }
   ],
   "source": [
    "epochs = len(history.history[\"loss\"])\n",
    "print(\"Epochs\", epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00082-2976e404-5a5a-4c43-9fe2-1b17e8b8c9e3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Let's predict the market values of the goalkeepers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00083-d57e9f48-0455-44e2-81ef-f392ba4ba513",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 418,
    "execution_start": 1621687952094,
    "scrolled": true,
    "source_hash": "f2a72b24",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squarred error: 0.06571800114811646\n",
      "Root mean squarred error: 0.2563552245383668\n",
      "Mean Absolute Error: 0.203209886859501\n",
      "MAPE: 0.015740379014569924\n",
      "R squared: 0.9695732949674287\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mse_gk = metrics.mean_squared_error(y_pred, y_test)\n",
    "rmse_gk = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "mae_gk = mean_absolute_error(y_test,y_pred)\n",
    "mape_gk = mean_absolute_percentage_error(y_test,y_pred)\n",
    "r2_score_gk = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean squarred error: {}\".format(mse_gk))\n",
    "print(\"Root mean squarred error: {}\".format(rmse_gk))\n",
    "print(\"Mean Absolute Error: {}\".format(mae_gk))\n",
    "print(\"MAPE: {}\".format(mape_gk))\n",
    "print(\"R squared: {}\".format(r2_score_gk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00084-fbeb436e-1c1f-47bf-8ebb-cca2ad0428a3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "It's clear that our model has achieved good results. The mse and rmse are pretty low, indicating that the results are really similar to the actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-aba6b528-8277-4f83-9b22-6a35c9c63096",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Hyperparameter optimization with RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00085-6ff7dc3a-e8ba-40ee-a8ba-6a377f26b9fb",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "However, we still do not know if the choosen model would be the best one. Hence we decide to pursue our analysis by performing hyperparameter optimization.\n",
    "The following model has been furtherly tuned using RandomSearch() in keras tuner. \n",
    "Although there are several hyperparameters which can be investigated and given the good performencases obtained in the previous model, the scope of this step has been sfifted to the optimizations of the following factors:\n",
    "- number of neurons in the input layer\n",
    "- learning rate: [1e-2, 1e-3, 1e-4]\n",
    "- number of hidden layers: 1 to 7\n",
    "- number of neurons in each hidden layer: 5 to 128\n",
    "\n",
    "The loss and actibation function are the same mentioned above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00034-bfc2d01c-c6d0-403c-9a0f-5cbeae2dc25d",
    "deepnote_cell_type": "code",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: keras-tuner in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (1.0.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied, skipping upgrade: colorama in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from keras-tuner) (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: future in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from keras-tuner) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from keras-tuner) (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from keras-tuner) (4.47.0)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from keras-tuner) (0.8.9)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from keras-tuner) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from keras-tuner) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from keras-tuner) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from keras-tuner) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: terminaltables in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from keras-tuner) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from scikit-learn->keras-tuner) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from scikit-learn->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from packaging->keras-tuner) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in c:\\users\\mazzi\\anaconda3\\lib\\site-packages (from packaging->keras-tuner) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00085-b43c533d-8bac-448d-bfc1-f2c12ef80455",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7553,
    "execution_start": 1621687952549,
    "source_hash": "646af89c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "import kerastuner\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00093-0a26adf9-bc81-4156-89d8-8e8a736ff81a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 14,
    "execution_start": 1621687960107,
    "source_hash": "df5af9b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_new_model(hp):\n",
    "    first_layers_neuron = hp.Choice(\"Number of neurons Input layer\", [128, 100, 80, 60, 40, 30, 10])\n",
    "    model = Sequential()\n",
    "    model.add(Dense(first_layers_neuron, input_dim = X.shape[1], activation = \"relu\"))\n",
    "    for i in range(hp.Int('num_layers', 1, 7)):                      #number of hidden layers\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=5,       #min number of neurons\n",
    "                                            max_value=128,     #max number of neurons\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [0.01, 1e-3, 1e-4])),  #what should be the learning rate\n",
    "        loss='mse',\n",
    "        metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00095-ad371ebc-bb4b-495d-a708-231bb8e632f0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 510,
    "execution_start": 1621687960125,
    "source_hash": "20fac9e1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project temp_second\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from temp_second\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner2 = RandomSearch(\n",
    "    build_new_model,\n",
    "    objective='val_mse',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='temp_second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00096-aa6c9ca8-2978-41f6-b03b-94bc26fdb7de",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1041403,
    "execution_start": 1621687960640,
    "source_hash": "4548092a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner2.search(X_train, y_train, epochs = 250, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00091-45eef42e-98e4-401e-b668-136af65a3fac",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Next we want to get the best parameters which will be consequently implemented in our model in oorder to get the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00096-316c064d-0d3e-4636-864f-715ae67dd5ca",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1621689010655,
    "source_hash": "280332c0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of neurons Input layer': 128,\n",
       " 'num_layers': 5,\n",
       " 'units_0': 5,\n",
       " 'learning_rate': 0.001,\n",
       " 'units_1': 101,\n",
       " 'units_2': 37,\n",
       " 'units_3': 69,\n",
       " 'units_4': 37,\n",
       " 'units_5': 37,\n",
       " 'units_6': 101}"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner2.get_best_hyperparameters()[0].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00093-ac0b36cf-e6a3-42c8-bfb3-c706ea86bcd6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Therefore our model will be built with the following parameters:\n",
    "- Input layer with 128 neurons\n",
    "- 5 hidden layers with 5, 101, 37, 69, 37 neurons respectively\n",
    "- learning rate of 0.001 and Adam as our optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00097-9af9d3aa-4524-4cd2-9a11-f49ce67e196e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 147,
    "execution_start": 1621689016245,
    "scrolled": false,
    "source_hash": "471621c8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               3072      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               606       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 37)                3774      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 69)                2622      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 37)                2590      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 38        \n",
      "=================================================================\n",
      "Total params: 13,347\n",
      "Trainable params: 13,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "tuner2.get_best_models()[0].summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00043-0d8e5240-9bfb-4f12-bb66-3dbba5c51d61",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### NN without Earlystopping (goalkeepers dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00044-84d1e8f3-0492-4185-b67d-68d7a7733ff9",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim = X.shape[1], activation = \"relu\"))\n",
    "model.add(Dense(5, activation = \"relu\"))\n",
    "model.add(Dense(101, activation = \"relu\"))\n",
    "model.add(Dense(37, activation = \"relu\"))\n",
    "model.add(Dense(69, activation = \"relu\"))\n",
    "model.add(Dense(37, activation = \"relu\"))\n",
    "\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1, activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00045-9d35844f-a3bd-4335-8bdb-e92d9546ff5f",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 146.7340 - mse: 146.7340 - mae: 11.8556 - mape: 90.7250 - val_loss: 13.1888 - val_mse: 13.1888 - val_mae: 2.9063 - val_mape: 22.1842\n",
      "Epoch 2/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 10.2965 - mse: 10.2965 - mae: 2.5209 - mape: 19.3265 - val_loss: 3.9160 - val_mse: 3.9160 - val_mae: 1.7073 - val_mape: 13.4468\n",
      "Epoch 3/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3.4908 - mse: 3.4908 - mae: 1.5471 - mape: 12.2717 - val_loss: 2.7998 - val_mse: 2.7998 - val_mae: 1.4353 - val_mape: 11.4330\n",
      "Epoch 4/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 2.7445 - mse: 2.7445 - mae: 1.3578 - mape: 10.8834 - val_loss: 2.1230 - val_mse: 2.1230 - val_mae: 1.2441 - val_mape: 9.8761\n",
      "Epoch 5/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.8466 - mse: 1.8466 - mae: 1.1055 - mape: 8.8174 - val_loss: 1.5791 - val_mse: 1.5791 - val_mae: 1.0487 - val_mape: 8.2896\n",
      "Epoch 6/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.4034 - mse: 1.4034 - mae: 0.9633 - mape: 7.6767 - val_loss: 1.0754 - val_mse: 1.0754 - val_mae: 0.8463 - val_mape: 6.6947\n",
      "Epoch 7/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.0967 - mse: 1.0967 - mae: 0.8364 - mape: 6.6201 - val_loss: 0.7773 - val_mse: 0.7773 - val_mae: 0.7105 - val_mape: 5.6388\n",
      "Epoch 8/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9400 - mse: 0.9400 - mae: 0.7633 - mape: 6.0345 - val_loss: 0.6664 - val_mse: 0.6664 - val_mae: 0.6471 - val_mape: 5.1038\n",
      "Epoch 9/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.7530 - mse: 0.7530 - mae: 0.6848 - mape: 5.3262 - val_loss: 0.5597 - val_mse: 0.5597 - val_mae: 0.5913 - val_mape: 4.6602\n",
      "Epoch 10/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6308 - mse: 0.6308 - mae: 0.6171 - mape: 4.8616 - val_loss: 0.4658 - val_mse: 0.4658 - val_mae: 0.5418 - val_mape: 4.2698\n",
      "Epoch 11/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5121 - mse: 0.5121 - mae: 0.5534 - mape: 4.3320 - val_loss: 0.4053 - val_mse: 0.4053 - val_mae: 0.5075 - val_mape: 4.0017\n",
      "Epoch 12/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5221 - mse: 0.5221 - mae: 0.5635 - mape: 4.4420 - val_loss: 0.3882 - val_mse: 0.3882 - val_mae: 0.4999 - val_mape: 3.9492\n",
      "Epoch 13/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4505 - mse: 0.4505 - mae: 0.5172 - mape: 4.0445 - val_loss: 0.3227 - val_mse: 0.3227 - val_mae: 0.4540 - val_mape: 3.5761\n",
      "Epoch 14/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3938 - mse: 0.3938 - mae: 0.4875 - mape: 3.8140 - val_loss: 0.2982 - val_mse: 0.2982 - val_mae: 0.4371 - val_mape: 3.4313\n",
      "Epoch 15/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3355 - mse: 0.3355 - mae: 0.4569 - mape: 3.5745 - val_loss: 0.2640 - val_mse: 0.2640 - val_mae: 0.4127 - val_mape: 3.2443\n",
      "Epoch 16/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3233 - mse: 0.3233 - mae: 0.4407 - mape: 3.4333 - val_loss: 0.2391 - val_mse: 0.2391 - val_mae: 0.3919 - val_mape: 3.0925\n",
      "Epoch 17/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2542 - mse: 0.2542 - mae: 0.3898 - mape: 3.0606 - val_loss: 0.2169 - val_mse: 0.2169 - val_mae: 0.3727 - val_mape: 2.9313\n",
      "Epoch 18/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2539 - mse: 0.2539 - mae: 0.3891 - mape: 3.0249 - val_loss: 0.2010 - val_mse: 0.2010 - val_mae: 0.3554 - val_mape: 2.7937\n",
      "Epoch 19/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2160 - mse: 0.2160 - mae: 0.3574 - mape: 2.7961 - val_loss: 0.1987 - val_mse: 0.1987 - val_mae: 0.3512 - val_mape: 2.7542\n",
      "Epoch 20/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2091 - mse: 0.2091 - mae: 0.3576 - mape: 2.7887 - val_loss: 0.1921 - val_mse: 0.1921 - val_mae: 0.3443 - val_mape: 2.6945\n",
      "Epoch 21/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1819 - mse: 0.1819 - mae: 0.3344 - mape: 2.6122 - val_loss: 0.1589 - val_mse: 0.1589 - val_mae: 0.3118 - val_mape: 2.4536\n",
      "Epoch 22/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1566 - mse: 0.1566 - mae: 0.3054 - mape: 2.4090 - val_loss: 0.1570 - val_mse: 0.1570 - val_mae: 0.3084 - val_mape: 2.4211\n",
      "Epoch 23/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1562 - mse: 0.1562 - mae: 0.3146 - mape: 2.4529 - val_loss: 0.1489 - val_mse: 0.1489 - val_mae: 0.3099 - val_mape: 2.4466\n",
      "Epoch 24/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1313 - mse: 0.1313 - mae: 0.2830 - mape: 2.2058 - val_loss: 0.1412 - val_mse: 0.1412 - val_mae: 0.3016 - val_mape: 2.3801\n",
      "Epoch 25/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1290 - mse: 0.1290 - mae: 0.2782 - mape: 2.1744 - val_loss: 0.1271 - val_mse: 0.1271 - val_mae: 0.2770 - val_mape: 2.1807\n",
      "Epoch 26/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1181 - mse: 0.1181 - mae: 0.2703 - mape: 2.0969 - val_loss: 0.1202 - val_mse: 0.1202 - val_mae: 0.2745 - val_mape: 2.1678\n",
      "Epoch 27/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1152 - mse: 0.1152 - mae: 0.2644 - mape: 2.0776 - val_loss: 0.1140 - val_mse: 0.1140 - val_mae: 0.2601 - val_mape: 2.0476\n",
      "Epoch 28/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1065 - mse: 0.1065 - mae: 0.2574 - mape: 2.0117 - val_loss: 0.1233 - val_mse: 0.1233 - val_mae: 0.2808 - val_mape: 2.2124\n",
      "Epoch 29/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1241 - mse: 0.1241 - mae: 0.2703 - mape: 2.1070 - val_loss: 0.1142 - val_mse: 0.1142 - val_mae: 0.2565 - val_mape: 2.0125\n",
      "Epoch 30/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1007 - mse: 0.1007 - mae: 0.2470 - mape: 1.9269 - val_loss: 0.1054 - val_mse: 0.1054 - val_mae: 0.2469 - val_mape: 1.9383\n",
      "Epoch 31/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1017 - mse: 0.1017 - mae: 0.2508 - mape: 1.9575 - val_loss: 0.1042 - val_mse: 0.1042 - val_mae: 0.2429 - val_mape: 1.9067\n",
      "Epoch 32/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0949 - mse: 0.0949 - mae: 0.2344 - mape: 1.8493 - val_loss: 0.0935 - val_mse: 0.0935 - val_mae: 0.2335 - val_mape: 1.8385\n",
      "Epoch 33/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0844 - mse: 0.0844 - mae: 0.2295 - mape: 1.7865 - val_loss: 0.1005 - val_mse: 0.1005 - val_mae: 0.2391 - val_mape: 1.8756\n",
      "Epoch 34/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0923 - mse: 0.0923 - mae: 0.2331 - mape: 1.8386 - val_loss: 0.1117 - val_mse: 0.1117 - val_mae: 0.2537 - val_mape: 1.9888\n",
      "Epoch 35/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0992 - mse: 0.0992 - mae: 0.2468 - mape: 1.9363 - val_loss: 0.1131 - val_mse: 0.1131 - val_mae: 0.2706 - val_mape: 2.1242\n",
      "Epoch 36/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1048 - mse: 0.1048 - mae: 0.2532 - mape: 1.9757 - val_loss: 0.1422 - val_mse: 0.1422 - val_mae: 0.2900 - val_mape: 2.2648\n",
      "Epoch 37/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1176 - mse: 0.1176 - mae: 0.2654 - mape: 2.0804 - val_loss: 0.0873 - val_mse: 0.0873 - val_mae: 0.2251 - val_mape: 1.7696\n",
      "Epoch 38/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0903 - mse: 0.0903 - mae: 0.2282 - mape: 1.7837 - val_loss: 0.0947 - val_mse: 0.0947 - val_mae: 0.2296 - val_mape: 1.8041\n",
      "Epoch 39/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0883 - mse: 0.0883 - mae: 0.2292 - mape: 1.8077 - val_loss: 0.0892 - val_mse: 0.0892 - val_mae: 0.2223 - val_mape: 1.7475\n",
      "Epoch 40/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1015 - mse: 0.1015 - mae: 0.2445 - mape: 1.8946 - val_loss: 0.0890 - val_mse: 0.0890 - val_mae: 0.2223 - val_mape: 1.7459\n",
      "Epoch 41/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0870 - mse: 0.0870 - mae: 0.2297 - mape: 1.7956 - val_loss: 0.1070 - val_mse: 0.1070 - val_mae: 0.2464 - val_mape: 1.9316\n",
      "Epoch 42/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0970 - mse: 0.0970 - mae: 0.2396 - mape: 1.8794 - val_loss: 0.0891 - val_mse: 0.0891 - val_mae: 0.2230 - val_mape: 1.7534\n",
      "Epoch 43/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0891 - mse: 0.0891 - mae: 0.2286 - mape: 1.7808 - val_loss: 0.0895 - val_mse: 0.0895 - val_mae: 0.2322 - val_mape: 1.8304\n",
      "Epoch 44/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0935 - mse: 0.0935 - mae: 0.2365 - mape: 1.8486 - val_loss: 0.0959 - val_mse: 0.0959 - val_mae: 0.2435 - val_mape: 1.9147\n",
      "Epoch 45/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0825 - mse: 0.0825 - mae: 0.2183 - mape: 1.6995 - val_loss: 0.0836 - val_mse: 0.0836 - val_mae: 0.2192 - val_mape: 1.7248\n",
      "Epoch 46/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0842 - mse: 0.0842 - mae: 0.2193 - mape: 1.7174 - val_loss: 0.0815 - val_mse: 0.0815 - val_mae: 0.2177 - val_mape: 1.7092\n",
      "Epoch 47/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0845 - mse: 0.0845 - mae: 0.2227 - mape: 1.7263 - val_loss: 0.1181 - val_mse: 0.1181 - val_mae: 0.2627 - val_mape: 2.0634\n",
      "Epoch 48/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1053 - mse: 0.1053 - mae: 0.2531 - mape: 1.9687 - val_loss: 0.0938 - val_mse: 0.0938 - val_mae: 0.2277 - val_mape: 1.7869\n",
      "Epoch 49/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0800 - mse: 0.0800 - mae: 0.2173 - mape: 1.7004 - val_loss: 0.0835 - val_mse: 0.0835 - val_mae: 0.2144 - val_mape: 1.6869\n",
      "Epoch 50/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0914 - mse: 0.0914 - mae: 0.2278 - mape: 1.7733 - val_loss: 0.0837 - val_mse: 0.0837 - val_mae: 0.2232 - val_mape: 1.7546\n",
      "Epoch 51/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0857 - mse: 0.0857 - mae: 0.2232 - mape: 1.7415 - val_loss: 0.0824 - val_mse: 0.0824 - val_mae: 0.2125 - val_mape: 1.6725\n",
      "Epoch 52/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0801 - mse: 0.0801 - mae: 0.2126 - mape: 1.6652 - val_loss: 0.0854 - val_mse: 0.0854 - val_mae: 0.2159 - val_mape: 1.6967\n",
      "Epoch 53/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2219 - mape: 1.7385 - val_loss: 0.1065 - val_mse: 0.1065 - val_mae: 0.2646 - val_mape: 2.0763\n",
      "Epoch 54/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0860 - mse: 0.0860 - mae: 0.2228 - mape: 1.7220 - val_loss: 0.0926 - val_mse: 0.0926 - val_mae: 0.2402 - val_mape: 1.8857\n",
      "Epoch 55/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0839 - mse: 0.0839 - mae: 0.2239 - mape: 1.7380 - val_loss: 0.1126 - val_mse: 0.1126 - val_mae: 0.2515 - val_mape: 1.9645\n",
      "Epoch 56/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0778 - mse: 0.0778 - mae: 0.2156 - mape: 1.6727 - val_loss: 0.0814 - val_mse: 0.0814 - val_mae: 0.2165 - val_mape: 1.7044\n",
      "Epoch 57/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0936 - mse: 0.0936 - mae: 0.2346 - mape: 1.8149 - val_loss: 0.0838 - val_mse: 0.0838 - val_mae: 0.2141 - val_mape: 1.6840\n",
      "Epoch 58/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1138 - mse: 0.1138 - mae: 0.2584 - mape: 2.0176 - val_loss: 0.1149 - val_mse: 0.1149 - val_mae: 0.2757 - val_mape: 2.1494\n",
      "Epoch 59/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1001 - mse: 0.1001 - mae: 0.2520 - mape: 1.9505 - val_loss: 0.1183 - val_mse: 0.1183 - val_mae: 0.2820 - val_mape: 2.1971\n",
      "Epoch 60/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1032 - mse: 0.1032 - mae: 0.2475 - mape: 1.9038 - val_loss: 0.1013 - val_mse: 0.1013 - val_mae: 0.2561 - val_mape: 2.0060\n",
      "Epoch 61/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0847 - mse: 0.0847 - mae: 0.2224 - mape: 1.7445 - val_loss: 0.0826 - val_mse: 0.0826 - val_mae: 0.2157 - val_mape: 1.7009\n",
      "Epoch 62/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0836 - mse: 0.0836 - mae: 0.2233 - mape: 1.7400 - val_loss: 0.0845 - val_mse: 0.0845 - val_mae: 0.2236 - val_mape: 1.7621\n",
      "Epoch 63/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0919 - mse: 0.0919 - mae: 0.2362 - mape: 1.8284 - val_loss: 0.0988 - val_mse: 0.0988 - val_mae: 0.2310 - val_mape: 1.8093\n",
      "Epoch 64/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0761 - mse: 0.0761 - mae: 0.2116 - mape: 1.6410 - val_loss: 0.0799 - val_mse: 0.0799 - val_mae: 0.2131 - val_mape: 1.6779\n",
      "Epoch 65/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0835 - mse: 0.0835 - mae: 0.2187 - mape: 1.6934 - val_loss: 0.1084 - val_mse: 0.1084 - val_mae: 0.2685 - val_mape: 2.1039\n",
      "Epoch 66/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0930 - mse: 0.0930 - mae: 0.2331 - mape: 1.8091 - val_loss: 0.0821 - val_mse: 0.0821 - val_mae: 0.2186 - val_mape: 1.7215\n",
      "Epoch 67/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0849 - mse: 0.0849 - mae: 0.2237 - mape: 1.7278 - val_loss: 0.0792 - val_mse: 0.0792 - val_mae: 0.2093 - val_mape: 1.6479\n",
      "Epoch 68/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0783 - mse: 0.0783 - mae: 0.2158 - mape: 1.6799 - val_loss: 0.0894 - val_mse: 0.0894 - val_mae: 0.2351 - val_mape: 1.8424\n",
      "Epoch 69/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0817 - mse: 0.0817 - mae: 0.2188 - mape: 1.6970 - val_loss: 0.1049 - val_mse: 0.1049 - val_mae: 0.2418 - val_mape: 1.9013\n",
      "Epoch 70/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0925 - mse: 0.0925 - mae: 0.2356 - mape: 1.8329 - val_loss: 0.0789 - val_mse: 0.0789 - val_mae: 0.2088 - val_mape: 1.6453\n",
      "Epoch 71/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0757 - mse: 0.0757 - mae: 0.2093 - mape: 1.6062 - val_loss: 0.1198 - val_mse: 0.1198 - val_mae: 0.2889 - val_mape: 2.2613\n",
      "Epoch 72/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0935 - mse: 0.0935 - mae: 0.2390 - mape: 1.8394 - val_loss: 0.0774 - val_mse: 0.0774 - val_mae: 0.2054 - val_mape: 1.6149\n",
      "Epoch 73/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0701 - mse: 0.0701 - mae: 0.2043 - mape: 1.5804 - val_loss: 0.0771 - val_mse: 0.0771 - val_mae: 0.2062 - val_mape: 1.6206\n",
      "Epoch 74/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0775 - mse: 0.0775 - mae: 0.2114 - mape: 1.6311 - val_loss: 0.0810 - val_mse: 0.0810 - val_mae: 0.2102 - val_mape: 1.6487\n",
      "Epoch 75/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0828 - mse: 0.0828 - mae: 0.2177 - mape: 1.6755 - val_loss: 0.0807 - val_mse: 0.0807 - val_mae: 0.2077 - val_mape: 1.6326\n",
      "Epoch 76/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0714 - mse: 0.0714 - mae: 0.2015 - mape: 1.5718 - val_loss: 0.0806 - val_mse: 0.0806 - val_mae: 0.2088 - val_mape: 1.6436\n",
      "Epoch 77/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0757 - mse: 0.0757 - mae: 0.2156 - mape: 1.6708 - val_loss: 0.0798 - val_mse: 0.0798 - val_mae: 0.2163 - val_mape: 1.7012\n",
      "Epoch 78/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0717 - mse: 0.0717 - mae: 0.1960 - mape: 1.5197 - val_loss: 0.0950 - val_mse: 0.0950 - val_mae: 0.2482 - val_mape: 1.9352\n",
      "Epoch 79/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0779 - mse: 0.0779 - mae: 0.2098 - mape: 1.6367 - val_loss: 0.0710 - val_mse: 0.0710 - val_mae: 0.1950 - val_mape: 1.5341\n",
      "Epoch 80/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0705 - mse: 0.0705 - mae: 0.1992 - mape: 1.5477 - val_loss: 0.0773 - val_mse: 0.0773 - val_mae: 0.2130 - val_mape: 1.6688\n",
      "Epoch 81/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0842 - mse: 0.0842 - mae: 0.2254 - mape: 1.7410 - val_loss: 0.0892 - val_mse: 0.0892 - val_mae: 0.2202 - val_mape: 1.7297\n",
      "Epoch 82/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0954 - mse: 0.0954 - mae: 0.2397 - mape: 1.8551 - val_loss: 0.0697 - val_mse: 0.0697 - val_mae: 0.1956 - val_mape: 1.5381\n",
      "Epoch 83/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0766 - mse: 0.0766 - mae: 0.2117 - mape: 1.6395 - val_loss: 0.0699 - val_mse: 0.0699 - val_mae: 0.1928 - val_mape: 1.5137\n",
      "Epoch 84/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0561 - mse: 0.0561 - mae: 0.1786 - mape: 1.3785 - val_loss: 0.1133 - val_mse: 0.1133 - val_mae: 0.2805 - val_mape: 2.1820\n",
      "Epoch 85/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1258 - mse: 0.1258 - mae: 0.2838 - mape: 2.1895 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2292 - val_mape: 1.7883\n",
      "Epoch 86/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0689 - mse: 0.0689 - mae: 0.2024 - mape: 1.5568 - val_loss: 0.0715 - val_mse: 0.0715 - val_mae: 0.2038 - val_mape: 1.6001\n",
      "Epoch 87/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0656 - mse: 0.0656 - mae: 0.1991 - mape: 1.5343 - val_loss: 0.0676 - val_mse: 0.0676 - val_mae: 0.1903 - val_mape: 1.4902\n",
      "Epoch 88/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0574 - mae: 0.1771 - mape: 1.3745 - val_loss: 0.0967 - val_mse: 0.0967 - val_mae: 0.2377 - val_mape: 1.8506\n",
      "Epoch 89/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0856 - mse: 0.0856 - mae: 0.2206 - mape: 1.7118 - val_loss: 0.0640 - val_mse: 0.0640 - val_mae: 0.1860 - val_mape: 1.4571\n",
      "Epoch 90/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0640 - mse: 0.0640 - mae: 0.1935 - mape: 1.4856 - val_loss: 0.0744 - val_mse: 0.0744 - val_mae: 0.1943 - val_mape: 1.5228\n",
      "Epoch 91/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0666 - mse: 0.0666 - mae: 0.1970 - mape: 1.5175 - val_loss: 0.0832 - val_mse: 0.0832 - val_mae: 0.2104 - val_mape: 1.6503\n",
      "Epoch 92/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0610 - mse: 0.0610 - mae: 0.1861 - mape: 1.4326 - val_loss: 0.0782 - val_mse: 0.0782 - val_mae: 0.2215 - val_mape: 1.7198\n",
      "Epoch 93/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0604 - mse: 0.0604 - mae: 0.1909 - mape: 1.4632 - val_loss: 0.0829 - val_mse: 0.0829 - val_mae: 0.2169 - val_mape: 1.6939\n",
      "Epoch 94/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0620 - mse: 0.0620 - mae: 0.1883 - mape: 1.4489 - val_loss: 0.0612 - val_mse: 0.0612 - val_mae: 0.1813 - val_mape: 1.4205\n",
      "Epoch 95/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0651 - mse: 0.0651 - mae: 0.1997 - mape: 1.5304 - val_loss: 0.0595 - val_mse: 0.0595 - val_mae: 0.1763 - val_mape: 1.3834\n",
      "Epoch 96/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1672 - mape: 1.2888 - val_loss: 0.0591 - val_mse: 0.0591 - val_mae: 0.1798 - val_mape: 1.4134\n",
      "Epoch 97/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0558 - mse: 0.0558 - mae: 0.1831 - mape: 1.4087 - val_loss: 0.0680 - val_mse: 0.0680 - val_mae: 0.1901 - val_mape: 1.4866\n",
      "Epoch 98/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0544 - mse: 0.0544 - mae: 0.1742 - mape: 1.3407 - val_loss: 0.0673 - val_mse: 0.0673 - val_mae: 0.1986 - val_mape: 1.5527\n",
      "Epoch 99/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1732 - mape: 1.3295 - val_loss: 0.0569 - val_mse: 0.0569 - val_mae: 0.1764 - val_mape: 1.3860\n",
      "Epoch 100/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1653 - mape: 1.2743 - val_loss: 0.0625 - val_mse: 0.0625 - val_mae: 0.1841 - val_mape: 1.4486\n",
      "Epoch 101/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1724 - mape: 1.3145 - val_loss: 0.0578 - val_mse: 0.0578 - val_mae: 0.1798 - val_mape: 1.4099\n",
      "Epoch 102/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1659 - mape: 1.2759 - val_loss: 0.0814 - val_mse: 0.0814 - val_mae: 0.2264 - val_mape: 1.7589\n",
      "Epoch 103/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0720 - mse: 0.0720 - mae: 0.2103 - mape: 1.6136 - val_loss: 0.0551 - val_mse: 0.0551 - val_mae: 0.1765 - val_mape: 1.3828\n",
      "Epoch 104/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1687 - mape: 1.2983 - val_loss: 0.0546 - val_mse: 0.0546 - val_mae: 0.1756 - val_mape: 1.3754\n",
      "Epoch 105/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1678 - mape: 1.2983 - val_loss: 0.0809 - val_mse: 0.0809 - val_mae: 0.2254 - val_mape: 1.7559\n",
      "Epoch 106/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1731 - mape: 1.3333 - val_loss: 0.0568 - val_mse: 0.0568 - val_mae: 0.1767 - val_mape: 1.3860\n",
      "Epoch 107/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0460 - mse: 0.0460 - mae: 0.1639 - mape: 1.2599 - val_loss: 0.0534 - val_mse: 0.0534 - val_mae: 0.1702 - val_mape: 1.3382\n",
      "Epoch 108/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0553 - mse: 0.0553 - mae: 0.1818 - mape: 1.3889 - val_loss: 0.0577 - val_mse: 0.0577 - val_mae: 0.1828 - val_mape: 1.4262\n",
      "Epoch 109/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0513 - mse: 0.0513 - mae: 0.1744 - mape: 1.3341 - val_loss: 0.0587 - val_mse: 0.0587 - val_mae: 0.1809 - val_mape: 1.4178\n",
      "Epoch 110/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0510 - mse: 0.0510 - mae: 0.1753 - mape: 1.3498 - val_loss: 0.0565 - val_mse: 0.0565 - val_mae: 0.1794 - val_mape: 1.4044\n",
      "Epoch 111/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1730 - mape: 1.3235 - val_loss: 0.0541 - val_mse: 0.0541 - val_mae: 0.1763 - val_mape: 1.3826\n",
      "Epoch 112/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0422 - mae: 0.1575 - mape: 1.2103 - val_loss: 0.0547 - val_mse: 0.0547 - val_mae: 0.1732 - val_mape: 1.3593\n",
      "Epoch 113/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1639 - mape: 1.2543 - val_loss: 0.0656 - val_mse: 0.0656 - val_mae: 0.1999 - val_mape: 1.5633\n",
      "Epoch 114/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0574 - mse: 0.0574 - mae: 0.1848 - mape: 1.4201 - val_loss: 0.0634 - val_mse: 0.0634 - val_mae: 0.1948 - val_mape: 1.5148\n",
      "Epoch 115/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0430 - mse: 0.0430 - mae: 0.1601 - mape: 1.2345 - val_loss: 0.0921 - val_mse: 0.0921 - val_mae: 0.2442 - val_mape: 1.8864\n",
      "Epoch 116/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0826 - mse: 0.0826 - mae: 0.2313 - mape: 1.7865 - val_loss: 0.0632 - val_mse: 0.0632 - val_mae: 0.1872 - val_mape: 1.4685\n",
      "Epoch 117/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.1740 - mape: 1.3410 - val_loss: 0.0573 - val_mse: 0.0573 - val_mae: 0.1833 - val_mape: 1.4382\n",
      "Epoch 118/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0419 - mae: 0.1581 - mape: 1.2076 - val_loss: 0.0691 - val_mse: 0.0691 - val_mae: 0.2034 - val_mape: 1.5994\n",
      "Epoch 119/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1707 - mape: 1.3234 - val_loss: 0.0520 - val_mse: 0.0520 - val_mae: 0.1739 - val_mape: 1.3643\n",
      "Epoch 120/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0449 - mse: 0.0449 - mae: 0.1621 - mape: 1.2398 - val_loss: 0.0533 - val_mse: 0.0533 - val_mae: 0.1767 - val_mape: 1.3879\n",
      "Epoch 121/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0593 - mse: 0.0593 - mae: 0.1892 - mape: 1.4589 - val_loss: 0.0524 - val_mse: 0.0524 - val_mae: 0.1724 - val_mape: 1.3545\n",
      "Epoch 122/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0460 - mse: 0.0460 - mae: 0.1635 - mape: 1.2587 - val_loss: 0.0614 - val_mse: 0.0614 - val_mae: 0.1927 - val_mape: 1.5028\n",
      "Epoch 123/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0437 - mse: 0.0437 - mae: 0.1594 - mape: 1.2252 - val_loss: 0.0717 - val_mse: 0.0717 - val_mae: 0.2137 - val_mape: 1.6612\n",
      "Epoch 124/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0595 - mse: 0.0595 - mae: 0.1935 - mape: 1.4847 - val_loss: 0.0589 - val_mse: 0.0589 - val_mae: 0.1851 - val_mape: 1.4483\n",
      "Epoch 125/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0435 - mse: 0.0435 - mae: 0.1638 - mape: 1.2686 - val_loss: 0.0562 - val_mse: 0.0562 - val_mae: 0.1714 - val_mape: 1.3454\n",
      "Epoch 126/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1621 - mape: 1.2429 - val_loss: 0.0580 - val_mse: 0.0580 - val_mae: 0.1809 - val_mape: 1.4176\n",
      "Epoch 127/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0623 - mse: 0.0623 - mae: 0.1946 - mape: 1.4886 - val_loss: 0.0812 - val_mse: 0.0812 - val_mae: 0.2278 - val_mape: 1.7703\n",
      "Epoch 128/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0540 - mse: 0.0540 - mae: 0.1820 - mape: 1.4019 - val_loss: 0.0599 - val_mse: 0.0599 - val_mae: 0.1849 - val_mape: 1.4485\n",
      "Epoch 129/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1738 - mape: 1.3340 - val_loss: 0.0559 - val_mse: 0.0559 - val_mae: 0.1807 - val_mape: 1.4107\n",
      "Epoch 130/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0418 - mae: 0.1561 - mape: 1.2050 - val_loss: 0.0649 - val_mse: 0.0649 - val_mae: 0.1980 - val_mape: 1.5510\n",
      "Epoch 131/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0416 - mse: 0.0416 - mae: 0.1581 - mape: 1.2235 - val_loss: 0.0660 - val_mse: 0.0660 - val_mae: 0.2010 - val_mape: 1.5651\n",
      "Epoch 132/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0455 - mse: 0.0455 - mae: 0.1687 - mape: 1.3032 - val_loss: 0.1335 - val_mse: 0.1335 - val_mae: 0.3166 - val_mape: 2.4531\n",
      "Epoch 133/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0676 - mse: 0.0676 - mae: 0.2083 - mape: 1.6060 - val_loss: 0.0522 - val_mse: 0.0522 - val_mae: 0.1687 - val_mape: 1.3260\n",
      "Epoch 134/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.1800 - mape: 1.3722 - val_loss: 0.0520 - val_mse: 0.0520 - val_mae: 0.1740 - val_mape: 1.3657\n",
      "Epoch 135/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1652 - mape: 1.2501 - val_loss: 0.0574 - val_mse: 0.0574 - val_mae: 0.1897 - val_mape: 1.4860\n",
      "Epoch 136/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0430 - mse: 0.0430 - mae: 0.1620 - mape: 1.2413 - val_loss: 0.0497 - val_mse: 0.0497 - val_mae: 0.1709 - val_mape: 1.3399\n",
      "Epoch 137/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0438 - mse: 0.0438 - mae: 0.1674 - mape: 1.2865 - val_loss: 0.0558 - val_mse: 0.0558 - val_mae: 0.1801 - val_mape: 1.4099\n",
      "Epoch 138/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1676 - mape: 1.2855 - val_loss: 0.0483 - val_mse: 0.0483 - val_mae: 0.1668 - val_mape: 1.3084\n",
      "Epoch 139/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0391 - mse: 0.0391 - mae: 0.1512 - mape: 1.1651 - val_loss: 0.0768 - val_mse: 0.0768 - val_mae: 0.2198 - val_mape: 1.7187\n",
      "Epoch 140/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1576 - mape: 1.2020 - val_loss: 0.0507 - val_mse: 0.0507 - val_mae: 0.1678 - val_mape: 1.3140\n",
      "Epoch 141/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0376 - mse: 0.0376 - mae: 0.1494 - mape: 1.1519 - val_loss: 0.0800 - val_mse: 0.0800 - val_mae: 0.2250 - val_mape: 1.7537\n",
      "Epoch 142/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1713 - mape: 1.3214 - val_loss: 0.0768 - val_mse: 0.0768 - val_mae: 0.2190 - val_mape: 1.6990\n",
      "Epoch 143/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0455 - mse: 0.0455 - mae: 0.1655 - mape: 1.2602 - val_loss: 0.0541 - val_mse: 0.0541 - val_mae: 0.1774 - val_mape: 1.3853\n",
      "Epoch 144/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1587 - mape: 1.2130 - val_loss: 0.0493 - val_mse: 0.0493 - val_mae: 0.1686 - val_mape: 1.3250\n",
      "Epoch 145/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0372 - mse: 0.0372 - mae: 0.1460 - mape: 1.1160 - val_loss: 0.0561 - val_mse: 0.0561 - val_mae: 0.1796 - val_mape: 1.4111\n",
      "Epoch 146/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - mae: 0.1515 - mape: 1.1683 - val_loss: 0.0534 - val_mse: 0.0534 - val_mae: 0.1757 - val_mape: 1.3754\n",
      "Epoch 147/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0565 - mse: 0.0565 - mae: 0.1880 - mape: 1.4360 - val_loss: 0.0541 - val_mse: 0.0541 - val_mae: 0.1796 - val_mape: 1.4067\n",
      "Epoch 148/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0414 - mae: 0.1614 - mape: 1.2395 - val_loss: 0.0512 - val_mse: 0.0512 - val_mae: 0.1740 - val_mape: 1.3669\n",
      "Epoch 149/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0419 - mae: 0.1587 - mape: 1.2250 - val_loss: 0.0536 - val_mse: 0.0536 - val_mae: 0.1785 - val_mape: 1.4026\n",
      "Epoch 150/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1754 - mape: 1.3425 - val_loss: 0.0516 - val_mse: 0.0516 - val_mae: 0.1686 - val_mape: 1.3250\n",
      "Epoch 151/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0450 - mse: 0.0450 - mae: 0.1619 - mape: 1.2329 - val_loss: 0.0642 - val_mse: 0.0642 - val_mae: 0.1975 - val_mape: 1.5359\n",
      "Epoch 152/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0438 - mse: 0.0438 - mae: 0.1582 - mape: 1.2157 - val_loss: 0.0505 - val_mse: 0.0505 - val_mae: 0.1670 - val_mape: 1.3137\n",
      "Epoch 153/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0425 - mse: 0.0425 - mae: 0.1582 - mape: 1.2169 - val_loss: 0.0570 - val_mse: 0.0570 - val_mae: 0.1761 - val_mape: 1.3788\n",
      "Epoch 154/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0377 - mse: 0.0377 - mae: 0.1499 - mape: 1.1505 - val_loss: 0.0485 - val_mse: 0.0485 - val_mae: 0.1670 - val_mape: 1.3105\n",
      "Epoch 155/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0426 - mse: 0.0426 - mae: 0.1604 - mape: 1.2125 - val_loss: 0.0520 - val_mse: 0.0520 - val_mae: 0.1703 - val_mape: 1.3352\n",
      "Epoch 156/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0422 - mae: 0.1601 - mape: 1.2316 - val_loss: 0.0519 - val_mse: 0.0519 - val_mae: 0.1686 - val_mape: 1.3216\n",
      "Epoch 157/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0403 - mse: 0.0403 - mae: 0.1582 - mape: 1.2128 - val_loss: 0.0710 - val_mse: 0.0710 - val_mae: 0.2117 - val_mape: 1.6396\n",
      "Epoch 158/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0422 - mae: 0.1629 - mape: 1.2524 - val_loss: 0.0799 - val_mse: 0.0799 - val_mae: 0.2214 - val_mape: 1.7293\n",
      "Epoch 159/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0435 - mse: 0.0435 - mae: 0.1609 - mape: 1.2437 - val_loss: 0.0705 - val_mse: 0.0705 - val_mae: 0.2080 - val_mape: 1.6295\n",
      "Epoch 160/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0413 - mae: 0.1553 - mape: 1.1988 - val_loss: 0.0566 - val_mse: 0.0566 - val_mae: 0.1833 - val_mape: 1.4262\n",
      "Epoch 161/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - mae: 0.1507 - mape: 1.1559 - val_loss: 0.0499 - val_mse: 0.0499 - val_mae: 0.1662 - val_mape: 1.3039\n",
      "Epoch 162/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.1775 - mape: 1.3575 - val_loss: 0.0509 - val_mse: 0.0509 - val_mae: 0.1689 - val_mape: 1.3189\n",
      "Epoch 163/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0367 - mse: 0.0367 - mae: 0.1472 - mape: 1.1202 - val_loss: 0.0514 - val_mse: 0.0514 - val_mae: 0.1692 - val_mape: 1.3243\n",
      "Epoch 164/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0401 - mse: 0.0401 - mae: 0.1549 - mape: 1.1817 - val_loss: 0.0529 - val_mse: 0.0529 - val_mae: 0.1766 - val_mape: 1.3891\n",
      "Epoch 165/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0352 - mse: 0.0352 - mae: 0.1440 - mape: 1.1066 - val_loss: 0.0489 - val_mse: 0.0489 - val_mae: 0.1664 - val_mape: 1.3070\n",
      "Epoch 166/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0364 - mae: 0.1478 - mape: 1.1361 - val_loss: 0.0574 - val_mse: 0.0574 - val_mae: 0.1731 - val_mape: 1.3583\n",
      "Epoch 167/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0383 - mse: 0.0383 - mae: 0.1515 - mape: 1.1630 - val_loss: 0.0480 - val_mse: 0.0480 - val_mae: 0.1654 - val_mape: 1.2999\n",
      "Epoch 168/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0344 - mse: 0.0344 - mae: 0.1452 - mape: 1.1180 - val_loss: 0.0561 - val_mse: 0.0561 - val_mae: 0.1795 - val_mape: 1.4129\n",
      "Epoch 169/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0431 - mae: 0.1655 - mape: 1.2651 - val_loss: 0.0715 - val_mse: 0.0715 - val_mae: 0.2137 - val_mape: 1.6593\n",
      "Epoch 170/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0402 - mse: 0.0402 - mae: 0.1561 - mape: 1.1963 - val_loss: 0.0677 - val_mse: 0.0677 - val_mae: 0.2076 - val_mape: 1.6157\n",
      "Epoch 171/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0539 - mse: 0.0539 - mae: 0.1869 - mape: 1.4229 - val_loss: 0.0627 - val_mse: 0.0627 - val_mae: 0.1958 - val_mape: 1.5321\n",
      "Epoch 172/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0374 - mse: 0.0374 - mae: 0.1524 - mape: 1.1731 - val_loss: 0.0502 - val_mse: 0.0502 - val_mae: 0.1669 - val_mape: 1.3023\n",
      "Epoch 173/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0382 - mae: 0.1521 - mape: 1.1581 - val_loss: 0.0475 - val_mse: 0.0475 - val_mae: 0.1631 - val_mape: 1.2816\n",
      "Epoch 174/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0542 - mse: 0.0542 - mae: 0.1861 - mape: 1.4380 - val_loss: 0.1919 - val_mse: 0.1919 - val_mae: 0.3970 - val_mape: 3.0782\n",
      "Epoch 175/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1130 - mse: 0.1130 - mae: 0.2797 - mape: 2.1358 - val_loss: 0.0629 - val_mse: 0.0629 - val_mae: 0.1957 - val_mape: 1.5140\n",
      "Epoch 176/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0385 - mse: 0.0385 - mae: 0.1539 - mape: 1.1918 - val_loss: 0.0457 - val_mse: 0.0457 - val_mae: 0.1586 - val_mape: 1.2445\n",
      "Epoch 177/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0479 - mse: 0.0479 - mae: 0.1722 - mape: 1.3154 - val_loss: 0.0459 - val_mse: 0.0459 - val_mae: 0.1594 - val_mape: 1.2489\n",
      "Epoch 178/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0372 - mse: 0.0372 - mae: 0.1468 - mape: 1.1248 - val_loss: 0.0571 - val_mse: 0.0571 - val_mae: 0.1786 - val_mape: 1.3985\n",
      "Epoch 179/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0447 - mse: 0.0447 - mae: 0.1676 - mape: 1.2824 - val_loss: 0.0453 - val_mse: 0.0453 - val_mae: 0.1634 - val_mape: 1.2814\n",
      "Epoch 180/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0338 - mse: 0.0338 - mae: 0.1441 - mape: 1.1046 - val_loss: 0.0631 - val_mse: 0.0631 - val_mae: 0.1989 - val_mape: 1.5460\n",
      "Epoch 181/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0437 - mse: 0.0437 - mae: 0.1641 - mape: 1.2523 - val_loss: 0.0468 - val_mse: 0.0468 - val_mae: 0.1640 - val_mape: 1.2824\n",
      "Epoch 182/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1738 - mape: 1.3316 - val_loss: 0.0538 - val_mse: 0.0538 - val_mae: 0.1783 - val_mape: 1.3875\n",
      "Epoch 183/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0395 - mse: 0.0395 - mae: 0.1559 - mape: 1.1866 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1813 - val_mape: 1.4072\n",
      "Epoch 184/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1797 - mape: 1.3726 - val_loss: 0.0545 - val_mse: 0.0545 - val_mae: 0.1773 - val_mape: 1.3760\n",
      "Epoch 185/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1725 - mape: 1.3202 - val_loss: 0.0451 - val_mse: 0.0451 - val_mae: 0.1617 - val_mape: 1.2677\n",
      "Epoch 186/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0432 - mse: 0.0432 - mae: 0.1604 - mape: 1.2266 - val_loss: 0.0504 - val_mse: 0.0504 - val_mae: 0.1714 - val_mape: 1.3342\n",
      "Epoch 187/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0407 - mse: 0.0407 - mae: 0.1576 - mape: 1.2038 - val_loss: 0.0465 - val_mse: 0.0465 - val_mae: 0.1625 - val_mape: 1.2744\n",
      "Epoch 188/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0325 - mae: 0.1418 - mape: 1.0835 - val_loss: 0.0535 - val_mse: 0.0535 - val_mae: 0.1760 - val_mape: 1.3821\n",
      "Epoch 189/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0410 - mse: 0.0410 - mae: 0.1616 - mape: 1.2427 - val_loss: 0.0586 - val_mse: 0.0586 - val_mae: 0.1874 - val_mape: 1.4684\n",
      "Epoch 190/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0386 - mse: 0.0386 - mae: 0.1503 - mape: 1.1493 - val_loss: 0.0475 - val_mse: 0.0475 - val_mae: 0.1621 - val_mape: 1.2696\n",
      "Epoch 191/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0336 - mse: 0.0336 - mae: 0.1405 - mape: 1.0716 - val_loss: 0.0467 - val_mse: 0.0467 - val_mae: 0.1633 - val_mape: 1.2772\n",
      "Epoch 192/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.1415 - mape: 1.0805 - val_loss: 0.0562 - val_mse: 0.0562 - val_mae: 0.1733 - val_mape: 1.3645\n",
      "Epoch 193/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0417 - mae: 0.1628 - mape: 1.2477 - val_loss: 0.0457 - val_mse: 0.0457 - val_mae: 0.1620 - val_mape: 1.2637\n",
      "Epoch 194/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0404 - mse: 0.0404 - mae: 0.1549 - mape: 1.1912 - val_loss: 0.0563 - val_mse: 0.0563 - val_mae: 0.1865 - val_mape: 1.4643\n",
      "Epoch 195/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0331 - mse: 0.0331 - mae: 0.1445 - mape: 1.1056 - val_loss: 0.0439 - val_mse: 0.0439 - val_mae: 0.1572 - val_mape: 1.2323\n",
      "Epoch 196/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0336 - mse: 0.0336 - mae: 0.1426 - mape: 1.0844 - val_loss: 0.0545 - val_mse: 0.0545 - val_mae: 0.1783 - val_mape: 1.3895\n",
      "Epoch 197/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0343 - mse: 0.0343 - mae: 0.1466 - mape: 1.1339 - val_loss: 0.0578 - val_mse: 0.0578 - val_mae: 0.1865 - val_mape: 1.4570\n",
      "Epoch 198/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0366 - mse: 0.0366 - mae: 0.1519 - mape: 1.1764 - val_loss: 0.0535 - val_mse: 0.0535 - val_mae: 0.1707 - val_mape: 1.3382\n",
      "Epoch 199/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0379 - mse: 0.0379 - mae: 0.1522 - mape: 1.1666 - val_loss: 0.0469 - val_mse: 0.0469 - val_mae: 0.1630 - val_mape: 1.2800\n",
      "Epoch 200/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0323 - mse: 0.0323 - mae: 0.1392 - mape: 1.0721 - val_loss: 0.0540 - val_mse: 0.0540 - val_mae: 0.1795 - val_mape: 1.3929\n",
      "Epoch 201/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0357 - mse: 0.0357 - mae: 0.1501 - mape: 1.1470 - val_loss: 0.0641 - val_mse: 0.0641 - val_mae: 0.1929 - val_mape: 1.5059\n",
      "Epoch 202/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0451 - mse: 0.0451 - mae: 0.1670 - mape: 1.2762 - val_loss: 0.0488 - val_mse: 0.0488 - val_mae: 0.1644 - val_mape: 1.2898\n",
      "Epoch 203/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0388 - mse: 0.0388 - mae: 0.1516 - mape: 1.1557 - val_loss: 0.0682 - val_mse: 0.0682 - val_mae: 0.2010 - val_mape: 1.5585\n",
      "Epoch 204/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0375 - mse: 0.0375 - mae: 0.1540 - mape: 1.1854 - val_loss: 0.0471 - val_mse: 0.0471 - val_mae: 0.1583 - val_mape: 1.2407\n",
      "Epoch 205/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0303 - mse: 0.0303 - mae: 0.1366 - mape: 1.0378 - val_loss: 0.0539 - val_mse: 0.0539 - val_mae: 0.1802 - val_mape: 1.4075\n",
      "Epoch 206/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0341 - mse: 0.0341 - mae: 0.1452 - mape: 1.1028 - val_loss: 0.0515 - val_mse: 0.0515 - val_mae: 0.1718 - val_mape: 1.3431\n",
      "Epoch 207/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0419 - mse: 0.0419 - mae: 0.1619 - mape: 1.2396 - val_loss: 0.0480 - val_mse: 0.0480 - val_mae: 0.1664 - val_mape: 1.3011\n",
      "Epoch 208/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0321 - mse: 0.0321 - mae: 0.1398 - mape: 1.0669 - val_loss: 0.0560 - val_mse: 0.0560 - val_mae: 0.1781 - val_mape: 1.3884\n",
      "Epoch 209/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0432 - mse: 0.0432 - mae: 0.1664 - mape: 1.2807 - val_loss: 0.0575 - val_mse: 0.0575 - val_mae: 0.1810 - val_mape: 1.4179\n",
      "Epoch 210/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0344 - mse: 0.0344 - mae: 0.1456 - mape: 1.1125 - val_loss: 0.0607 - val_mse: 0.0607 - val_mae: 0.1920 - val_mape: 1.4976\n",
      "Epoch 211/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0452 - mse: 0.0452 - mae: 0.1665 - mape: 1.2754 - val_loss: 0.0691 - val_mse: 0.0691 - val_mae: 0.2057 - val_mape: 1.6135\n",
      "Epoch 212/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0368 - mse: 0.0368 - mae: 0.1531 - mape: 1.1787 - val_loss: 0.0536 - val_mse: 0.0536 - val_mae: 0.1782 - val_mape: 1.3799\n",
      "Epoch 213/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0373 - mse: 0.0373 - mae: 0.1520 - mape: 1.1635 - val_loss: 0.0588 - val_mse: 0.0588 - val_mae: 0.1893 - val_mape: 1.4688\n",
      "Epoch 214/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0366 - mse: 0.0366 - mae: 0.1479 - mape: 1.1218 - val_loss: 0.0512 - val_mse: 0.0512 - val_mae: 0.1651 - val_mape: 1.2995\n",
      "Epoch 215/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0315 - mse: 0.0315 - mae: 0.1392 - mape: 1.0720 - val_loss: 0.1090 - val_mse: 0.1090 - val_mae: 0.2736 - val_mape: 2.1049\n",
      "Epoch 216/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1751 - mape: 1.3455 - val_loss: 0.0753 - val_mse: 0.0753 - val_mae: 0.2163 - val_mape: 1.6898\n",
      "Epoch 217/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0443 - mse: 0.0443 - mae: 0.1664 - mape: 1.2655 - val_loss: 0.1645 - val_mse: 0.1645 - val_mae: 0.3607 - val_mape: 2.7808\n",
      "Epoch 218/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0752 - mse: 0.0752 - mae: 0.2224 - mape: 1.7128 - val_loss: 0.0464 - val_mse: 0.0464 - val_mae: 0.1638 - val_mape: 1.2739\n",
      "Epoch 219/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0273 - mse: 0.0273 - mae: 0.1299 - mape: 1.0020 - val_loss: 0.0500 - val_mse: 0.0500 - val_mae: 0.1659 - val_mape: 1.2919\n",
      "Epoch 220/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0309 - mse: 0.0309 - mae: 0.1385 - mape: 1.0583 - val_loss: 0.0432 - val_mse: 0.0432 - val_mae: 0.1534 - val_mape: 1.2027\n",
      "Epoch 221/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0317 - mae: 0.1406 - mape: 1.0710 - val_loss: 0.0487 - val_mse: 0.0487 - val_mae: 0.1688 - val_mape: 1.3250\n",
      "Epoch 222/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0295 - mse: 0.0295 - mae: 0.1352 - mape: 1.0352 - val_loss: 0.0470 - val_mse: 0.0470 - val_mae: 0.1595 - val_mape: 1.2530\n",
      "Epoch 223/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0378 - mse: 0.0378 - mae: 0.1508 - mape: 1.1580 - val_loss: 0.0474 - val_mse: 0.0474 - val_mae: 0.1646 - val_mape: 1.2851\n",
      "Epoch 224/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0313 - mse: 0.0313 - mae: 0.1392 - mape: 1.0651 - val_loss: 0.0480 - val_mse: 0.0480 - val_mae: 0.1680 - val_mape: 1.3198\n",
      "Epoch 225/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0364 - mse: 0.0364 - mae: 0.1516 - mape: 1.1673 - val_loss: 0.0877 - val_mse: 0.0877 - val_mae: 0.2335 - val_mape: 1.8214\n",
      "Epoch 226/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0439 - mse: 0.0439 - mae: 0.1665 - mape: 1.2700 - val_loss: 0.0603 - val_mse: 0.0603 - val_mae: 0.1918 - val_mape: 1.4835\n",
      "Epoch 227/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0377 - mse: 0.0377 - mae: 0.1484 - mape: 1.1212 - val_loss: 0.0628 - val_mse: 0.0628 - val_mae: 0.1952 - val_mape: 1.5302\n",
      "Epoch 228/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0342 - mse: 0.0342 - mae: 0.1453 - mape: 1.1242 - val_loss: 0.0436 - val_mse: 0.0436 - val_mae: 0.1595 - val_mape: 1.2521\n",
      "Epoch 229/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0305 - mse: 0.0305 - mae: 0.1388 - mape: 1.0623 - val_loss: 0.0510 - val_mse: 0.0510 - val_mae: 0.1611 - val_mape: 1.2651\n",
      "Epoch 230/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.1422 - mape: 1.0874 - val_loss: 0.0501 - val_mse: 0.0501 - val_mae: 0.1696 - val_mape: 1.3329\n",
      "Epoch 231/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0273 - mse: 0.0273 - mae: 0.1293 - mape: 1.0039 - val_loss: 0.0458 - val_mse: 0.0458 - val_mae: 0.1620 - val_mape: 1.2704\n",
      "Epoch 232/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0290 - mse: 0.0290 - mae: 0.1343 - mape: 1.0266 - val_loss: 0.0518 - val_mse: 0.0518 - val_mae: 0.1776 - val_mape: 1.3938\n",
      "Epoch 233/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0317 - mae: 0.1388 - mape: 1.0459 - val_loss: 0.0471 - val_mse: 0.0471 - val_mae: 0.1642 - val_mape: 1.2823\n",
      "Epoch 234/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0317 - mse: 0.0317 - mae: 0.1396 - mape: 1.0652 - val_loss: 0.0895 - val_mse: 0.0895 - val_mae: 0.2361 - val_mape: 1.8447\n",
      "Epoch 235/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0545 - mse: 0.0545 - mae: 0.1898 - mape: 1.4581 - val_loss: 0.0452 - val_mse: 0.0452 - val_mae: 0.1589 - val_mape: 1.2460\n",
      "Epoch 236/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0417 - mae: 0.1632 - mape: 1.2562 - val_loss: 0.0492 - val_mse: 0.0492 - val_mae: 0.1663 - val_mape: 1.3025\n",
      "Epoch 237/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0316 - mae: 0.1382 - mape: 1.0583 - val_loss: 0.0448 - val_mse: 0.0448 - val_mae: 0.1542 - val_mape: 1.2097\n",
      "Epoch 238/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0291 - mse: 0.0291 - mae: 0.1331 - mape: 1.0144 - val_loss: 0.0631 - val_mse: 0.0631 - val_mae: 0.1955 - val_mape: 1.5310\n",
      "Epoch 239/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0316 - mae: 0.1409 - mape: 1.0858 - val_loss: 0.0494 - val_mse: 0.0494 - val_mae: 0.1698 - val_mape: 1.3235\n",
      "Epoch 240/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0276 - mse: 0.0276 - mae: 0.1292 - mape: 0.9835 - val_loss: 0.0530 - val_mse: 0.0530 - val_mae: 0.1739 - val_mape: 1.3656\n",
      "Epoch 241/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0296 - mse: 0.0296 - mae: 0.1359 - mape: 1.0367 - val_loss: 0.0463 - val_mse: 0.0463 - val_mae: 0.1569 - val_mape: 1.2322\n",
      "Epoch 242/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0307 - mse: 0.0307 - mae: 0.1379 - mape: 1.0526 - val_loss: 0.0936 - val_mse: 0.0936 - val_mae: 0.2525 - val_mape: 1.9476\n",
      "Epoch 243/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0383 - mse: 0.0383 - mae: 0.1524 - mape: 1.1682 - val_loss: 0.0703 - val_mse: 0.0703 - val_mae: 0.2049 - val_mape: 1.5983\n",
      "Epoch 244/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0353 - mse: 0.0353 - mae: 0.1474 - mape: 1.1323 - val_loss: 0.0527 - val_mse: 0.0527 - val_mae: 0.1745 - val_mape: 1.3585\n",
      "Epoch 245/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0350 - mse: 0.0350 - mae: 0.1456 - mape: 1.1067 - val_loss: 0.0438 - val_mse: 0.0438 - val_mae: 0.1584 - val_mape: 1.2440\n",
      "Epoch 246/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0288 - mse: 0.0288 - mae: 0.1336 - mape: 1.0256 - val_loss: 0.0487 - val_mse: 0.0487 - val_mae: 0.1646 - val_mape: 1.2898\n",
      "Epoch 247/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0298 - mse: 0.0298 - mae: 0.1366 - mape: 1.0481 - val_loss: 0.0489 - val_mse: 0.0489 - val_mae: 0.1704 - val_mape: 1.3380\n",
      "Epoch 248/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0281 - mse: 0.0281 - mae: 0.1315 - mape: 1.0155 - val_loss: 0.0462 - val_mse: 0.0462 - val_mae: 0.1560 - val_mape: 1.2258\n",
      "Epoch 249/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0307 - mse: 0.0307 - mae: 0.1369 - mape: 1.0526 - val_loss: 0.0469 - val_mse: 0.0469 - val_mae: 0.1629 - val_mape: 1.2799\n",
      "Epoch 250/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0316 - mse: 0.0316 - mae: 0.1366 - mape: 1.0337 - val_loss: 0.0530 - val_mse: 0.0530 - val_mae: 0.1730 - val_mape: 1.3439\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss = \"mse\", optimizer = opt, metrics = [\"mse\", \"mae\", \"mape\"])\n",
    "\n",
    "history_1 = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00046-19890a59-6ff1-4cb8-8345-736935205c42",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squarred error (no early stopping): 0.0558779335688955\n",
      "Root mean squarred error (no early stopping): 0.23638513821493834\n",
      "Mean Absolute Error (no early stopping): 0.18535790070119243\n",
      "MAPE (no early stopping): 0.014311512538106598\n",
      "R squared (no early stopping):0.9741291370274867\n"
     ]
    }
   ],
   "source": [
    "y_pred_no_earlystop = model.predict(X_test)\n",
    "mse_gk_tuned_no_earlystop = metrics.mean_squared_error(y_test, y_pred_no_earlystop)\n",
    "rmse_gk_tuned_no_earlystop = np.sqrt(mean_squared_error(y_test, y_pred_no_earlystop))\n",
    "mae_gk_tuned_no_earlystop = mean_absolute_error(y_test,y_pred_no_earlystop)\n",
    "mape_gk_tuned_no_earlystop = mean_absolute_percentage_error(y_test,y_pred_no_earlystop)\n",
    "r2_score_gk_tuned_no_earlystop = r2_score(y_test, y_pred_no_earlystop)\n",
    "\n",
    "print(\"Mean squarred error (no early stopping): {}\".format(mse_gk_tuned_no_earlystop))\n",
    "print(\"Root mean squarred error (no early stopping): {}\".format(rmse_gk_tuned_no_earlystop))\n",
    "print(\"Mean Absolute Error (no early stopping): {}\".format(mae_gk_tuned_no_earlystop))\n",
    "print(\"MAPE (no early stopping): {}\".format(mape_gk_tuned_no_earlystop))\n",
    "print(\"R squared (no early stopping):{}\".format(r2_score_gk_tuned_no_earlystop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00047-7f1da7c0-22af-4182-9d1f-c1303ecdbbd2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### NN with Earlystopping (goalkeepers dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00098-fffa8869-0f74-4dbd-aecd-34edc68a1f51",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 117,
    "execution_start": 1621689025831,
    "source_hash": "badb7f10",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=40, min_delta = 0.01)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim = X.shape[1], activation = \"relu\"))\n",
    "model.add(Dense(5, activation = \"relu\"))\n",
    "model.add(Dense(101, activation = \"relu\"))\n",
    "model.add(Dense(37, activation = \"relu\"))\n",
    "model.add(Dense(69, activation = \"relu\"))\n",
    "model.add(Dense(37, activation = \"relu\"))\n",
    "\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1, activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00099-b95b1346-42e4-4251-83c5-766177b0b426",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 63801,
    "execution_start": 1621689027645,
    "source_hash": "a6d364c6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "35/35 [==============================] - 1s 7ms/step - loss: 161.1934 - mse: 161.1934 - mae: 12.5722 - mape: 96.1875 - val_loss: 16.2050 - val_mse: 16.2050 - val_mae: 3.7922 - val_mape: 29.5945\n",
      "Epoch 2/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 10.0606 - mse: 10.0606 - mae: 2.5988 - mape: 19.9230 - val_loss: 4.4053 - val_mse: 4.4053 - val_mae: 1.7662 - val_mape: 13.8310\n",
      "Epoch 3/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 3.9218 - mse: 3.9218 - mae: 1.6469 - mape: 12.9733 - val_loss: 2.8925 - val_mse: 2.8925 - val_mae: 1.4633 - val_mape: 11.6551\n",
      "Epoch 4/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 2.8838 - mse: 2.8838 - mae: 1.3936 - mape: 11.1562 - val_loss: 2.2749 - val_mse: 2.2749 - val_mae: 1.2827 - val_mape: 10.2070\n",
      "Epoch 5/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.9863 - mse: 1.9863 - mae: 1.1501 - mape: 9.1668 - val_loss: 1.7091 - val_mse: 1.7091 - val_mae: 1.0921 - val_mape: 8.6617\n",
      "Epoch 6/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.5326 - mse: 1.5326 - mae: 1.0052 - mape: 8.0106 - val_loss: 1.1939 - val_mse: 1.1939 - val_mae: 0.8930 - val_mape: 7.0887\n",
      "Epoch 7/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 1.2063 - mse: 1.2063 - mae: 0.8805 - mape: 6.9832 - val_loss: 0.8886 - val_mse: 0.8886 - val_mae: 0.7659 - val_mape: 6.0772\n",
      "Epoch 8/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.9900 - mse: 0.9900 - mae: 0.7880 - mape: 6.2200 - val_loss: 0.7707 - val_mse: 0.7707 - val_mae: 0.6916 - val_mape: 5.4643\n",
      "Epoch 9/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.8358 - mse: 0.8358 - mae: 0.7149 - mape: 5.5573 - val_loss: 0.6455 - val_mse: 0.6455 - val_mae: 0.6320 - val_mape: 4.9876\n",
      "Epoch 10/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.6887 - mse: 0.6887 - mae: 0.6486 - mape: 5.1101 - val_loss: 0.5272 - val_mse: 0.5272 - val_mae: 0.5824 - val_mape: 4.5959\n",
      "Epoch 11/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5560 - mse: 0.5560 - mae: 0.5807 - mape: 4.5480 - val_loss: 0.4569 - val_mse: 0.4569 - val_mae: 0.5475 - val_mape: 4.3205\n",
      "Epoch 12/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.5340 - mse: 0.5340 - mae: 0.5766 - mape: 4.5476 - val_loss: 0.4346 - val_mse: 0.4346 - val_mae: 0.5383 - val_mape: 4.2486\n",
      "Epoch 13/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4711 - mse: 0.4711 - mae: 0.5304 - mape: 4.1577 - val_loss: 0.3629 - val_mse: 0.3629 - val_mae: 0.4849 - val_mape: 3.8234\n",
      "Epoch 14/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3933 - mse: 0.3933 - mae: 0.4949 - mape: 3.8791 - val_loss: 0.3364 - val_mse: 0.3364 - val_mae: 0.4674 - val_mape: 3.6713\n",
      "Epoch 15/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3370 - mse: 0.3370 - mae: 0.4579 - mape: 3.5895 - val_loss: 0.3005 - val_mse: 0.3005 - val_mae: 0.4398 - val_mape: 3.4600\n",
      "Epoch 16/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3290 - mse: 0.3290 - mae: 0.4549 - mape: 3.5526 - val_loss: 0.2755 - val_mse: 0.2755 - val_mae: 0.4214 - val_mape: 3.3244\n",
      "Epoch 17/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2625 - mse: 0.2625 - mae: 0.4011 - mape: 3.1512 - val_loss: 0.2483 - val_mse: 0.2483 - val_mae: 0.3999 - val_mape: 3.1472\n",
      "Epoch 18/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2637 - mse: 0.2637 - mae: 0.3992 - mape: 3.1054 - val_loss: 0.2502 - val_mse: 0.2502 - val_mae: 0.4030 - val_mape: 3.1502\n",
      "Epoch 19/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2379 - mse: 0.2379 - mae: 0.3813 - mape: 2.9764 - val_loss: 0.2348 - val_mse: 0.2348 - val_mae: 0.3904 - val_mape: 3.0531\n",
      "Epoch 20/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.2144 - mse: 0.2144 - mae: 0.3671 - mape: 2.8594 - val_loss: 0.2088 - val_mse: 0.2088 - val_mae: 0.3681 - val_mape: 2.8824\n",
      "Epoch 21/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1775 - mse: 0.1775 - mae: 0.3343 - mape: 2.6146 - val_loss: 0.1786 - val_mse: 0.1786 - val_mae: 0.3401 - val_mape: 2.6786\n",
      "Epoch 22/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1510 - mse: 0.1510 - mae: 0.3042 - mape: 2.3946 - val_loss: 0.1739 - val_mse: 0.1739 - val_mae: 0.3365 - val_mape: 2.6437\n",
      "Epoch 23/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1535 - mse: 0.1535 - mae: 0.3113 - mape: 2.4244 - val_loss: 0.1631 - val_mse: 0.1631 - val_mae: 0.3275 - val_mape: 2.5867\n",
      "Epoch 24/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1280 - mse: 0.1280 - mae: 0.2822 - mape: 2.2001 - val_loss: 0.1502 - val_mse: 0.1502 - val_mae: 0.3146 - val_mape: 2.4845\n",
      "Epoch 25/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1271 - mse: 0.1271 - mae: 0.2788 - mape: 2.1764 - val_loss: 0.1378 - val_mse: 0.1378 - val_mae: 0.2962 - val_mape: 2.3336\n",
      "Epoch 26/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1154 - mse: 0.1154 - mae: 0.2701 - mape: 2.0953 - val_loss: 0.1300 - val_mse: 0.1300 - val_mae: 0.2919 - val_mape: 2.3069\n",
      "Epoch 27/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1131 - mse: 0.1131 - mae: 0.2631 - mape: 2.0641 - val_loss: 0.1200 - val_mse: 0.1200 - val_mae: 0.2753 - val_mape: 2.1719\n",
      "Epoch 28/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1024 - mse: 0.1024 - mae: 0.2537 - mape: 1.9867 - val_loss: 0.1307 - val_mse: 0.1307 - val_mae: 0.2914 - val_mape: 2.2987\n",
      "Epoch 29/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1179 - mse: 0.1179 - mae: 0.2679 - mape: 2.0856 - val_loss: 0.1172 - val_mse: 0.1172 - val_mae: 0.2645 - val_mape: 2.0812\n",
      "Epoch 30/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0995 - mse: 0.0995 - mae: 0.2459 - mape: 1.9193 - val_loss: 0.1095 - val_mse: 0.1095 - val_mae: 0.2552 - val_mape: 2.0130\n",
      "Epoch 31/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0982 - mse: 0.0982 - mae: 0.2482 - mape: 1.9381 - val_loss: 0.1097 - val_mse: 0.1097 - val_mae: 0.2529 - val_mape: 1.9911\n",
      "Epoch 32/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0927 - mse: 0.0927 - mae: 0.2352 - mape: 1.8618 - val_loss: 0.0996 - val_mse: 0.0996 - val_mae: 0.2446 - val_mape: 1.9331\n",
      "Epoch 33/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0801 - mse: 0.0801 - mae: 0.2251 - mape: 1.7477 - val_loss: 0.1003 - val_mse: 0.1003 - val_mae: 0.2426 - val_mape: 1.9087\n",
      "Epoch 34/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0880 - mse: 0.0880 - mae: 0.2300 - mape: 1.8081 - val_loss: 0.1082 - val_mse: 0.1082 - val_mae: 0.2516 - val_mape: 1.9773\n",
      "Epoch 35/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0923 - mse: 0.0923 - mae: 0.2368 - mape: 1.8570 - val_loss: 0.1056 - val_mse: 0.1056 - val_mae: 0.2576 - val_mape: 2.0246\n",
      "Epoch 36/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0936 - mse: 0.0936 - mae: 0.2411 - mape: 1.8782 - val_loss: 0.1386 - val_mse: 0.1386 - val_mae: 0.2855 - val_mape: 2.2343\n",
      "Epoch 37/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1104 - mse: 0.1104 - mae: 0.2594 - mape: 2.0324 - val_loss: 0.0899 - val_mse: 0.0899 - val_mae: 0.2264 - val_mape: 1.7859\n",
      "Epoch 38/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0847 - mse: 0.0847 - mae: 0.2218 - mape: 1.7303 - val_loss: 0.0975 - val_mse: 0.0975 - val_mae: 0.2330 - val_mape: 1.8420\n",
      "Epoch 39/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0830 - mse: 0.0830 - mae: 0.2244 - mape: 1.7663 - val_loss: 0.0904 - val_mse: 0.0904 - val_mae: 0.2255 - val_mape: 1.7799\n",
      "Epoch 40/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0952 - mse: 0.0952 - mae: 0.2366 - mape: 1.8356 - val_loss: 0.0873 - val_mse: 0.0873 - val_mae: 0.2232 - val_mape: 1.7571\n",
      "Epoch 41/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0833 - mse: 0.0833 - mae: 0.2243 - mape: 1.7518 - val_loss: 0.1087 - val_mse: 0.1087 - val_mae: 0.2504 - val_mape: 1.9660\n",
      "Epoch 42/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0915 - mse: 0.0915 - mae: 0.2338 - mape: 1.8283 - val_loss: 0.0900 - val_mse: 0.0900 - val_mae: 0.2257 - val_mape: 1.7788\n",
      "Epoch 43/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0850 - mse: 0.0850 - mae: 0.2257 - mape: 1.7588 - val_loss: 0.0882 - val_mse: 0.0882 - val_mae: 0.2270 - val_mape: 1.7939\n",
      "Epoch 44/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0864 - mse: 0.0864 - mae: 0.2297 - mape: 1.7906 - val_loss: 0.0954 - val_mse: 0.0954 - val_mae: 0.2434 - val_mape: 1.9120\n",
      "Epoch 45/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0737 - mse: 0.0737 - mae: 0.2081 - mape: 1.6131 - val_loss: 0.0821 - val_mse: 0.0821 - val_mae: 0.2152 - val_mape: 1.7003\n",
      "Epoch 46/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0815 - mse: 0.0815 - mae: 0.2184 - mape: 1.7130 - val_loss: 0.0796 - val_mse: 0.0796 - val_mae: 0.2152 - val_mape: 1.6937\n",
      "Epoch 47/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0767 - mse: 0.0767 - mae: 0.2113 - mape: 1.6391 - val_loss: 0.1094 - val_mse: 0.1094 - val_mae: 0.2525 - val_mape: 1.9811\n",
      "Epoch 48/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0979 - mse: 0.0979 - mae: 0.2463 - mape: 1.9155 - val_loss: 0.0946 - val_mse: 0.0946 - val_mae: 0.2316 - val_mape: 1.8224\n",
      "Epoch 49/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0726 - mse: 0.0726 - mae: 0.2086 - mape: 1.6309 - val_loss: 0.0799 - val_mse: 0.0799 - val_mae: 0.2069 - val_mape: 1.6371\n",
      "Epoch 50/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0801 - mse: 0.0801 - mae: 0.2152 - mape: 1.6746 - val_loss: 0.0760 - val_mse: 0.0760 - val_mae: 0.2091 - val_mape: 1.6479\n",
      "Epoch 51/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0810 - mse: 0.0810 - mae: 0.2191 - mape: 1.7005 - val_loss: 0.0783 - val_mse: 0.0783 - val_mae: 0.2051 - val_mape: 1.6217\n",
      "Epoch 52/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0714 - mse: 0.0714 - mae: 0.2012 - mape: 1.5783 - val_loss: 0.0838 - val_mse: 0.0838 - val_mae: 0.2105 - val_mape: 1.6641\n",
      "Epoch 53/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0788 - mse: 0.0788 - mae: 0.2109 - mape: 1.6494 - val_loss: 0.1079 - val_mse: 0.1079 - val_mae: 0.2691 - val_mape: 2.1077\n",
      "Epoch 54/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0802 - mse: 0.0802 - mae: 0.2145 - mape: 1.6560 - val_loss: 0.0858 - val_mse: 0.0858 - val_mae: 0.2265 - val_mape: 1.7780\n",
      "Epoch 55/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0737 - mse: 0.0737 - mae: 0.2072 - mape: 1.6046 - val_loss: 0.0862 - val_mse: 0.0862 - val_mae: 0.2190 - val_mape: 1.7223\n",
      "Epoch 56/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0669 - mse: 0.0669 - mae: 0.1988 - mape: 1.5465 - val_loss: 0.0727 - val_mse: 0.0727 - val_mae: 0.2010 - val_mape: 1.5857\n",
      "Epoch 57/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0813 - mse: 0.0813 - mae: 0.2194 - mape: 1.6950 - val_loss: 0.0893 - val_mse: 0.0893 - val_mae: 0.2239 - val_mape: 1.7592\n",
      "Epoch 58/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.1200 - mse: 0.1200 - mae: 0.2684 - mape: 2.0906 - val_loss: 0.1030 - val_mse: 0.1030 - val_mae: 0.2593 - val_mape: 2.0191\n",
      "Epoch 59/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0851 - mse: 0.0851 - mae: 0.2301 - mape: 1.7765 - val_loss: 0.0992 - val_mse: 0.0992 - val_mae: 0.2529 - val_mape: 1.9761\n",
      "Epoch 60/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0900 - mse: 0.0900 - mae: 0.2306 - mape: 1.7721 - val_loss: 0.0790 - val_mse: 0.0790 - val_mae: 0.2156 - val_mape: 1.6918\n",
      "Epoch 61/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0705 - mse: 0.0705 - mae: 0.2032 - mape: 1.5923 - val_loss: 0.0737 - val_mse: 0.0737 - val_mae: 0.1971 - val_mape: 1.5601\n",
      "Epoch 62/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0709 - mse: 0.0709 - mae: 0.2057 - mape: 1.6033 - val_loss: 0.0786 - val_mse: 0.0786 - val_mae: 0.2159 - val_mape: 1.6930\n",
      "Epoch 63/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0789 - mse: 0.0789 - mae: 0.2197 - mape: 1.6947 - val_loss: 0.0830 - val_mse: 0.0830 - val_mae: 0.2137 - val_mape: 1.6807\n",
      "Epoch 64/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0661 - mse: 0.0661 - mae: 0.1985 - mape: 1.5341 - val_loss: 0.0684 - val_mse: 0.0684 - val_mae: 0.1929 - val_mape: 1.5221\n",
      "Epoch 65/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0660 - mse: 0.0660 - mae: 0.1939 - mape: 1.4936 - val_loss: 0.0810 - val_mse: 0.0810 - val_mae: 0.2213 - val_mape: 1.7374\n",
      "Epoch 66/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0715 - mse: 0.0715 - mae: 0.2028 - mape: 1.5747 - val_loss: 0.0681 - val_mse: 0.0681 - val_mae: 0.1931 - val_mape: 1.5229\n",
      "Epoch 67/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0637 - mse: 0.0637 - mae: 0.1916 - mape: 1.4773 - val_loss: 0.0663 - val_mse: 0.0663 - val_mae: 0.1926 - val_mape: 1.5190\n",
      "Epoch 68/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0619 - mse: 0.0619 - mae: 0.1924 - mape: 1.4923 - val_loss: 0.0740 - val_mse: 0.0740 - val_mae: 0.2075 - val_mape: 1.6275\n",
      "Epoch 69/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0617 - mse: 0.0617 - mae: 0.1917 - mape: 1.4835 - val_loss: 0.1059 - val_mse: 0.1059 - val_mae: 0.2501 - val_mape: 1.9576\n",
      "Epoch 70/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0795 - mse: 0.0795 - mae: 0.2239 - mape: 1.7363 - val_loss: 0.0653 - val_mse: 0.0653 - val_mae: 0.1892 - val_mape: 1.4922\n",
      "Epoch 71/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0589 - mse: 0.0589 - mae: 0.1863 - mape: 1.4276 - val_loss: 0.1139 - val_mse: 0.1139 - val_mae: 0.2832 - val_mape: 2.1965\n",
      "Epoch 72/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0743 - mse: 0.0743 - mae: 0.2099 - mape: 1.6102 - val_loss: 0.0636 - val_mse: 0.0636 - val_mae: 0.1905 - val_mape: 1.4984\n",
      "Epoch 73/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0564 - mae: 0.1813 - mape: 1.4018 - val_loss: 0.0630 - val_mse: 0.0630 - val_mae: 0.1887 - val_mape: 1.4839\n",
      "Epoch 74/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0563 - mse: 0.0563 - mae: 0.1798 - mape: 1.3887 - val_loss: 0.0709 - val_mse: 0.0709 - val_mae: 0.2003 - val_mape: 1.5706\n",
      "Epoch 75/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0620 - mse: 0.0620 - mae: 0.1872 - mape: 1.4409 - val_loss: 0.0788 - val_mse: 0.0788 - val_mae: 0.2057 - val_mape: 1.6137\n",
      "Epoch 76/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0598 - mse: 0.0598 - mae: 0.1867 - mape: 1.4566 - val_loss: 0.0728 - val_mse: 0.0728 - val_mae: 0.2033 - val_mape: 1.5949\n",
      "Epoch 77/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0584 - mse: 0.0584 - mae: 0.1889 - mape: 1.4587 - val_loss: 0.0615 - val_mse: 0.0615 - val_mae: 0.1903 - val_mape: 1.4849\n",
      "Epoch 78/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.1741 - mape: 1.3435 - val_loss: 0.1281 - val_mse: 0.1281 - val_mae: 0.3012 - val_mape: 2.3319\n",
      "Epoch 79/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0824 - mse: 0.0824 - mae: 0.2254 - mape: 1.7439 - val_loss: 0.0571 - val_mse: 0.0571 - val_mae: 0.1817 - val_mape: 1.4298\n",
      "Epoch 80/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0547 - mse: 0.0547 - mae: 0.1772 - mape: 1.3774 - val_loss: 0.0650 - val_mse: 0.0650 - val_mae: 0.1946 - val_mape: 1.5183\n",
      "Epoch 81/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0658 - mse: 0.0658 - mae: 0.2004 - mape: 1.5415 - val_loss: 0.0739 - val_mse: 0.0739 - val_mae: 0.1989 - val_mape: 1.5595\n",
      "Epoch 82/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2270 - mape: 1.7529 - val_loss: 0.0577 - val_mse: 0.0577 - val_mae: 0.1802 - val_mape: 1.4166\n",
      "Epoch 83/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0554 - mse: 0.0554 - mae: 0.1834 - mape: 1.4169 - val_loss: 0.0625 - val_mse: 0.0625 - val_mae: 0.1831 - val_mape: 1.4389\n",
      "Epoch 84/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1661 - mape: 1.2814 - val_loss: 0.0900 - val_mse: 0.0900 - val_mae: 0.2447 - val_mape: 1.8996\n",
      "Epoch 85/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0939 - mse: 0.0939 - mae: 0.2452 - mape: 1.8859 - val_loss: 0.0613 - val_mse: 0.0613 - val_mae: 0.1881 - val_mape: 1.4721\n",
      "Epoch 86/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.1794 - mape: 1.3824 - val_loss: 0.0574 - val_mse: 0.0574 - val_mae: 0.1767 - val_mape: 1.3898\n",
      "Epoch 87/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0662 - mse: 0.0662 - mae: 0.2008 - mape: 1.5405 - val_loss: 0.0570 - val_mse: 0.0570 - val_mae: 0.1806 - val_mape: 1.4156\n",
      "Epoch 88/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1668 - mape: 1.2932 - val_loss: 0.1141 - val_mse: 0.1141 - val_mae: 0.2644 - val_mape: 2.0542\n",
      "Epoch 89/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0861 - mse: 0.0861 - mae: 0.2321 - mape: 1.8019 - val_loss: 0.0554 - val_mse: 0.0554 - val_mae: 0.1792 - val_mape: 1.4038\n",
      "Epoch 90/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0504 - mse: 0.0504 - mae: 0.1733 - mape: 1.3315 - val_loss: 0.0814 - val_mse: 0.0814 - val_mae: 0.2106 - val_mape: 1.6443\n",
      "Epoch 91/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0627 - mse: 0.0627 - mae: 0.1948 - mape: 1.4999 - val_loss: 0.0657 - val_mse: 0.0657 - val_mae: 0.1874 - val_mape: 1.4703\n",
      "Epoch 92/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1680 - mape: 1.2926 - val_loss: 0.0699 - val_mse: 0.0699 - val_mae: 0.2084 - val_mape: 1.6198\n",
      "Epoch 93/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0574 - mse: 0.0574 - mae: 0.1891 - mape: 1.4526 - val_loss: 0.0640 - val_mse: 0.0640 - val_mae: 0.1884 - val_mape: 1.4771\n",
      "Epoch 94/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1736 - mape: 1.3332 - val_loss: 0.0558 - val_mse: 0.0558 - val_mae: 0.1817 - val_mape: 1.4242\n",
      "Epoch 95/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1692 - mape: 1.2983 - val_loss: 0.0536 - val_mse: 0.0536 - val_mae: 0.1766 - val_mape: 1.3885\n",
      "Epoch 96/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0459 - mse: 0.0459 - mae: 0.1658 - mape: 1.2826 - val_loss: 0.0558 - val_mse: 0.0558 - val_mae: 0.1760 - val_mape: 1.3787\n",
      "Epoch 97/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1675 - mape: 1.2857 - val_loss: 0.0639 - val_mse: 0.0639 - val_mae: 0.1847 - val_mape: 1.4494\n",
      "Epoch 98/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1640 - mape: 1.2660 - val_loss: 0.0600 - val_mse: 0.0600 - val_mae: 0.1879 - val_mape: 1.4673\n",
      "Epoch 99/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1732 - mape: 1.3281 - val_loss: 0.0532 - val_mse: 0.0532 - val_mae: 0.1769 - val_mape: 1.3895\n",
      "Epoch 100/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0421 - mae: 0.1591 - mape: 1.2222 - val_loss: 0.0694 - val_mse: 0.0694 - val_mae: 0.1992 - val_mape: 1.5599\n",
      "Epoch 101/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1713 - mape: 1.3057 - val_loss: 0.0521 - val_mse: 0.0521 - val_mae: 0.1726 - val_mape: 1.3543\n",
      "Epoch 102/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0424 - mse: 0.0424 - mae: 0.1588 - mape: 1.2197 - val_loss: 0.0862 - val_mse: 0.0862 - val_mae: 0.2376 - val_mape: 1.8454\n",
      "Epoch 103/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0663 - mse: 0.0663 - mae: 0.2028 - mape: 1.5528 - val_loss: 0.0511 - val_mse: 0.0511 - val_mae: 0.1726 - val_mape: 1.3503\n",
      "Epoch 104/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0431 - mae: 0.1637 - mape: 1.2660 - val_loss: 0.0509 - val_mse: 0.0509 - val_mae: 0.1738 - val_mape: 1.3642\n",
      "Epoch 105/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0409 - mse: 0.0409 - mae: 0.1587 - mape: 1.2269 - val_loss: 0.0616 - val_mse: 0.0616 - val_mae: 0.1943 - val_mape: 1.5123\n",
      "Epoch 106/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0414 - mse: 0.0414 - mae: 0.1610 - mape: 1.2421 - val_loss: 0.0516 - val_mse: 0.0516 - val_mae: 0.1710 - val_mape: 1.3406\n",
      "Epoch 107/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0411 - mse: 0.0411 - mae: 0.1582 - mape: 1.2129 - val_loss: 0.0509 - val_mse: 0.0509 - val_mae: 0.1696 - val_mape: 1.3332\n",
      "Epoch 108/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1763 - mape: 1.3485 - val_loss: 0.0670 - val_mse: 0.0670 - val_mae: 0.2059 - val_mape: 1.5965\n",
      "Epoch 109/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0513 - mse: 0.0513 - mae: 0.1738 - mape: 1.3348 - val_loss: 0.0495 - val_mse: 0.0495 - val_mae: 0.1688 - val_mape: 1.3247\n",
      "Epoch 110/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0401 - mse: 0.0401 - mae: 0.1534 - mape: 1.1769 - val_loss: 0.0568 - val_mse: 0.0568 - val_mae: 0.1844 - val_mape: 1.4415\n",
      "Epoch 111/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1694 - mape: 1.2933 - val_loss: 0.0503 - val_mse: 0.0503 - val_mae: 0.1712 - val_mape: 1.3435\n",
      "Epoch 112/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0382 - mse: 0.0382 - mae: 0.1557 - mape: 1.1944 - val_loss: 0.0514 - val_mse: 0.0514 - val_mae: 0.1714 - val_mape: 1.3448\n",
      "Epoch 113/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0400 - mse: 0.0400 - mae: 0.1541 - mape: 1.1795 - val_loss: 0.0704 - val_mse: 0.0704 - val_mae: 0.2049 - val_mape: 1.5970\n",
      "Epoch 114/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0459 - mse: 0.0459 - mae: 0.1663 - mape: 1.2779 - val_loss: 0.0568 - val_mse: 0.0568 - val_mae: 0.1850 - val_mape: 1.4404\n",
      "Epoch 115/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0395 - mse: 0.0395 - mae: 0.1562 - mape: 1.2061 - val_loss: 0.0705 - val_mse: 0.0705 - val_mae: 0.2108 - val_mape: 1.6403\n",
      "Epoch 116/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0650 - mse: 0.0650 - mae: 0.2008 - mape: 1.5558 - val_loss: 0.0812 - val_mse: 0.0812 - val_mae: 0.2188 - val_mape: 1.7053\n",
      "Epoch 117/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0533 - mse: 0.0533 - mae: 0.1795 - mape: 1.3864 - val_loss: 0.0585 - val_mse: 0.0585 - val_mae: 0.1865 - val_mape: 1.4601\n",
      "Epoch 118/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0399 - mse: 0.0399 - mae: 0.1589 - mape: 1.2140 - val_loss: 0.0709 - val_mse: 0.0709 - val_mae: 0.2061 - val_mape: 1.6145\n",
      "Epoch 119/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1731 - mape: 1.3408 - val_loss: 0.0489 - val_mse: 0.0489 - val_mae: 0.1712 - val_mape: 1.3386\n",
      "Epoch 120/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0408 - mse: 0.0408 - mae: 0.1577 - mape: 1.2101 - val_loss: 0.0504 - val_mse: 0.0504 - val_mae: 0.1726 - val_mape: 1.3546\n",
      "Epoch 121/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0601 - mae: 0.1926 - mape: 1.4885 - val_loss: 0.0485 - val_mse: 0.0485 - val_mae: 0.1674 - val_mape: 1.3145\n",
      "Epoch 122/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0421 - mae: 0.1595 - mape: 1.2301 - val_loss: 0.0517 - val_mse: 0.0517 - val_mae: 0.1780 - val_mape: 1.3868\n",
      "Epoch 123/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0437 - mse: 0.0437 - mae: 0.1594 - mape: 1.2279 - val_loss: 0.0695 - val_mse: 0.0695 - val_mae: 0.2129 - val_mape: 1.6519\n",
      "Epoch 124/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0445 - mse: 0.0445 - mae: 0.1687 - mape: 1.2968 - val_loss: 0.0464 - val_mse: 0.0464 - val_mae: 0.1653 - val_mape: 1.2977\n",
      "Epoch 125/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1609 - mape: 1.2447 - val_loss: 0.0496 - val_mse: 0.0496 - val_mae: 0.1677 - val_mape: 1.3128\n",
      "Epoch 126/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0433 - mse: 0.0433 - mae: 0.1608 - mape: 1.2328 - val_loss: 0.0590 - val_mse: 0.0590 - val_mae: 0.1826 - val_mape: 1.4290\n",
      "Epoch 127/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0636 - mse: 0.0636 - mae: 0.1980 - mape: 1.5158 - val_loss: 0.0827 - val_mse: 0.0827 - val_mae: 0.2287 - val_mape: 1.7822\n",
      "Epoch 128/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1790 - mape: 1.3766 - val_loss: 0.0521 - val_mse: 0.0521 - val_mae: 0.1721 - val_mape: 1.3472\n",
      "Epoch 129/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0451 - mse: 0.0451 - mae: 0.1683 - mape: 1.2912 - val_loss: 0.0545 - val_mse: 0.0545 - val_mae: 0.1820 - val_mape: 1.4138\n",
      "Epoch 130/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0397 - mse: 0.0397 - mae: 0.1549 - mape: 1.1975 - val_loss: 0.0637 - val_mse: 0.0637 - val_mae: 0.1943 - val_mape: 1.5193\n",
      "Epoch 131/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0371 - mse: 0.0371 - mae: 0.1515 - mape: 1.1752 - val_loss: 0.0471 - val_mse: 0.0471 - val_mae: 0.1656 - val_mape: 1.2947\n",
      "Epoch 132/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0431 - mse: 0.0431 - mae: 0.1628 - mape: 1.2604 - val_loss: 0.1135 - val_mse: 0.1135 - val_mae: 0.2924 - val_mape: 2.2555\n",
      "Epoch 133/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0601 - mse: 0.0601 - mae: 0.1975 - mape: 1.5179 - val_loss: 0.0459 - val_mse: 0.0459 - val_mae: 0.1642 - val_mape: 1.2880\n",
      "Epoch 134/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0437 - mse: 0.0437 - mae: 0.1627 - mape: 1.2443 - val_loss: 0.0483 - val_mse: 0.0483 - val_mae: 0.1665 - val_mape: 1.3052\n",
      "Epoch 135/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0389 - mse: 0.0389 - mae: 0.1541 - mape: 1.1679 - val_loss: 0.0483 - val_mse: 0.0483 - val_mae: 0.1686 - val_mape: 1.3235\n",
      "Epoch 136/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0395 - mse: 0.0395 - mae: 0.1546 - mape: 1.1865 - val_loss: 0.0512 - val_mse: 0.0512 - val_mae: 0.1721 - val_mape: 1.3486\n",
      "Epoch 137/250\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.0391 - mse: 0.0391 - mae: 0.1550 - mape: 1.1914 - val_loss: 0.0512 - val_mse: 0.0512 - val_mae: 0.1745 - val_mape: 1.3614\n",
      "Epoch 138/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0433 - mse: 0.0433 - mae: 0.1637 - mape: 1.2555 - val_loss: 0.0449 - val_mse: 0.0449 - val_mae: 0.1635 - val_mape: 1.2792\n",
      "Epoch 139/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0343 - mse: 0.0343 - mae: 0.1448 - mape: 1.1179 - val_loss: 0.0731 - val_mse: 0.0731 - val_mae: 0.2059 - val_mape: 1.6069\n",
      "Epoch 140/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0383 - mse: 0.0383 - mae: 0.1536 - mape: 1.1693 - val_loss: 0.0464 - val_mse: 0.0464 - val_mae: 0.1637 - val_mape: 1.2818\n",
      "Epoch 141/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0353 - mse: 0.0353 - mae: 0.1491 - mape: 1.1504 - val_loss: 0.0793 - val_mse: 0.0793 - val_mae: 0.2248 - val_mape: 1.7486\n",
      "Epoch 142/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0417 - mse: 0.0417 - mae: 0.1627 - mape: 1.2574 - val_loss: 0.0545 - val_mse: 0.0545 - val_mae: 0.1831 - val_mape: 1.4209\n",
      "Epoch 143/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0396 - mae: 0.1543 - mape: 1.1793 - val_loss: 0.0462 - val_mse: 0.0462 - val_mae: 0.1651 - val_mape: 1.2878\n",
      "Epoch 144/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0399 - mse: 0.0399 - mae: 0.1562 - mape: 1.1920 - val_loss: 0.0448 - val_mse: 0.0448 - val_mae: 0.1615 - val_mape: 1.2622\n",
      "Epoch 145/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0358 - mse: 0.0358 - mae: 0.1473 - mape: 1.1291 - val_loss: 0.0461 - val_mse: 0.0461 - val_mae: 0.1646 - val_mape: 1.2897\n",
      "Epoch 146/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0348 - mse: 0.0348 - mae: 0.1472 - mape: 1.1370 - val_loss: 0.0440 - val_mse: 0.0440 - val_mae: 0.1595 - val_mape: 1.2491\n",
      "Epoch 147/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1766 - mape: 1.3477 - val_loss: 0.0441 - val_mse: 0.0441 - val_mae: 0.1613 - val_mape: 1.2629\n",
      "Epoch 148/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0396 - mse: 0.0396 - mae: 0.1594 - mape: 1.2247 - val_loss: 0.0447 - val_mse: 0.0447 - val_mae: 0.1639 - val_mape: 1.2797\n",
      "Epoch 149/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0367 - mse: 0.0367 - mae: 0.1476 - mape: 1.1403 - val_loss: 0.0485 - val_mse: 0.0485 - val_mae: 0.1632 - val_mape: 1.2753\n",
      "Epoch 150/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0631 - mse: 0.0631 - mae: 0.2002 - mape: 1.5365 - val_loss: 0.0477 - val_mse: 0.0477 - val_mae: 0.1675 - val_mape: 1.3126\n",
      "Epoch 151/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0370 - mse: 0.0370 - mae: 0.1475 - mape: 1.1247 - val_loss: 0.0913 - val_mse: 0.0913 - val_mae: 0.2529 - val_mape: 1.9552\n",
      "Epoch 152/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1700 - mape: 1.3105 - val_loss: 0.0462 - val_mse: 0.0462 - val_mae: 0.1661 - val_mape: 1.2992\n",
      "Epoch 153/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0391 - mse: 0.0391 - mae: 0.1547 - mape: 1.1868 - val_loss: 0.0506 - val_mse: 0.0506 - val_mae: 0.1682 - val_mape: 1.3141\n",
      "Epoch 154/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0325 - mse: 0.0325 - mae: 0.1405 - mape: 1.0745 - val_loss: 0.0420 - val_mse: 0.0420 - val_mae: 0.1585 - val_mape: 1.2378\n",
      "Epoch 155/250\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0394 - mse: 0.0394 - mae: 0.1553 - mape: 1.1714 - val_loss: 0.0538 - val_mse: 0.0538 - val_mae: 0.1803 - val_mape: 1.4050\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss = \"mse\", optimizer = opt, metrics = [\"mse\", \"mae\", \"mape\"])\n",
    "\n",
    "history_2 = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs = 250, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00100-39921710-a5f9-4e91-9f72-5385a8547e54",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 245,
    "execution_start": 1621689091569,
    "source_hash": "c2ec7681",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squarred error: 0.04819065307509601\n",
      "Root mean squarred error: 0.21952369593074916\n",
      "Mean Absolute Error: 0.17581991990357607\n",
      "MAPE: 0.013687752984619205\n",
      "R squared:0.9776882625638874\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mse_gk_tuned = metrics.mean_squared_error(y_pred, y_test)\n",
    "rmse_gk_tuned = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "mae_gk_tuned = mean_absolute_error(y_test,y_pred)\n",
    "mape_gk_tuned = mean_absolute_percentage_error(y_test,y_pred)\n",
    "r2_score_gk_tuned = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean squarred error: {}\".format(mse_gk_tuned))\n",
    "print(\"Root mean squarred error: {}\".format(rmse_gk_tuned))\n",
    "print(\"Mean Absolute Error: {}\".format(mae_gk_tuned))\n",
    "print(\"MAPE: {}\".format(mape_gk_tuned))\n",
    "print(\"R squared:{}\".format(r2_score_gk_tuned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00051-aebc74e9-2240-49b6-92db-3b63bff7ccf2",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs with Earlystopping 155\n",
      "Epochs without Earlystopping 250\n"
     ]
    }
   ],
   "source": [
    "epochs_earlystop = len(history_2.history['loss']) \n",
    "epochs_no_earlystop = len(history_1.history[\"loss\"])\n",
    "\n",
    "print(\"Epochs with Earlystopping\", epochs_earlystop)\n",
    "print(\"Epochs without Earlystopping\", epochs_no_earlystop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00096-f1633990-a6b9-4808-b074-9d1c25de40c9",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Not by chance the performance of our NN, due to the hyperparameter optimization are noticeably incresead. The MSE is lower!\n",
    "\n",
    "Now we can predicte the market values of the goalkeepers and store them in a a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00053-74c7a0bc-264a-41a8-9188-ab4b0b56f764",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "flatten_y_pred = np.concatenate(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00054-70ebd457-0412-4d3f-a7a6-2f38d52d543c",
    "deepnote_cell_type": "code",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  0.,  2.,  2.,  6., 12., 12., 20., 23., 30., 31., 62., 47.,\n",
       "        61., 64., 64., 54., 41., 44., 37., 20., 23., 13.,  6.,  3.,  0.,\n",
       "         3.,  1.,  1.,  1.]),\n",
       " array([-0.55461531, -0.51016337, -0.46571143, -0.42125949, -0.37680755,\n",
       "        -0.33235561, -0.28790367, -0.24345173, -0.19899979, -0.15454785,\n",
       "        -0.11009592, -0.06564398, -0.02119204,  0.0232599 ,  0.06771184,\n",
       "         0.11216378,  0.15661572,  0.20106766,  0.2455196 ,  0.28997154,\n",
       "         0.33442347,  0.37887541,  0.42332735,  0.46777929,  0.51223123,\n",
       "         0.55668317,  0.60113511,  0.64558705,  0.69003899,  0.73449093,\n",
       "         0.77894287]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 368
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.hist(flatten_y_pred-y_test,bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00055-108a3cbb-61bf-49d6-8e99-664e8376a51f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The residuals of the goalkeepers dataset appear to be normally distributed and slightly skewed on the left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00100-41b42210-fb46-47eb-bfb0-2f77cb8ecd25",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1621689107832,
    "source_hash": "a14fc53c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_real=np.e**y_pred\n",
    "y_test_real=np.e**y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00057-bd44719d-bcc4-4e64-9ae8-5f08e9f15a5e",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "flatten_y_pred = np.concatenate(y_pred_real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00096-03b97bb7-c557-49fd-8575-ec2afd8f63d4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1621689110608,
    "source_hash": "6c8f9d17",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_real= pd.Series(flatten_y_pred).astype(int)\n",
    "y_test_real = pd.Series(y_test_real).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00097-986dba61-4dbd-4217-bff8-70ee0881b885",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1621689112588,
    "source_hash": "99785c08",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"True vlues\": y_test_real,\n",
    "    \"Predicted values\": y_pred_real\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00098-b4cdc80b-02d9-4433-af45-205a4b101365",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 23,
    "execution_start": 1621689113077,
    "source_hash": "f56a542b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series, pandas.core.series.Series)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test_real), type(y_pred_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00100-9b4432f9-14b4-40a3-b553-7006bcccea05",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1621689113643,
    "source_hash": "550d18cc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_gk = pd.concat(data, axis = 1)\n",
    "list_of_indexes = list(y_test_real.index)\n",
    "list_of_predictions = list(y_pred_real)\n",
    "list_total = list(zip(list_of_indexes, list(y_test_real), list_of_predictions))\n",
    "df_gk = pd.DataFrame(list_total, columns = ['index', 'true', 'pred'])\n",
    "df_gk[\"Difference\"] = df_gk.pred-df_gk.true\n",
    "df_gk['Difference %'] = round(100*(df_gk.pred-df_gk.true)/df_gk.true, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00062-7b6eed2c-89de-4207-9fa8-59554a84faf9",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#adding the age column to the new dataframe by matching player indexes\n",
    "\n",
    "age_list = []\n",
    "for index in list(y_test.index):\n",
    "    if index in gk_age_dict:\n",
    "        age_list.append(gk_age_dict[index])\n",
    "    else:\n",
    "        break\n",
    "df_gk['age'] = age_list\n",
    "col = df_gk.pop(\"age\")\n",
    "df_gk.insert(0, col.name, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00097-ddbc74b6-8d48-49a7-9f58-293196a0229d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 79,
    "execution_start": 1621689116260,
    "scrolled": true,
    "source_hash": "12c1fc92",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adding the name column to the new dataframe by matching player indexes\n",
    "\n",
    "name_list = []\n",
    "for index in list(y_test_real.index):\n",
    "    if index in gk_dict:\n",
    "        name_list.append(gk_dict[index])\n",
    "    else:\n",
    "        break\n",
    "df_gk['player'] = name_list\n",
    "col = df_gk.pop(\"player\")\n",
    "df_gk.insert(0, col.name, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00064-bb58ffda-a065-410f-ba78-60fd178917f6",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------+-------+-------+-------+-------+------------+---------+\n",
      "|                  Method for goalkeepers dataset                  |  MSE  |  RMSE |  MAE  |  MAPE | R squared  | Epochs  |\n",
      "+------------------------------------------------------------------+-------+-------+-------+-------+------------+---------+\n",
      "|                          Neural Network                          | 0.066 | 0.256 | 0.203 | 0.016 |    0.97    |   250   |\n",
      "|    Neural Netwotk with Hyperparm. Optimiztion + EarlyStopping    | 0.048 |  0.22 | 0.176 | 0.014 |   0.978    |   155   |\n",
      "| Neural Netwotk with Hyperparm. Optimiztion without EarlyStopping | 0.056 | 0.236 | 0.185 | 0.014 |   0.974    |   250   |\n",
      "+------------------------------------------------------------------+-------+-------+-------+-------+------------+---------+\n"
     ]
    }
   ],
   "source": [
    "gk_mse_all = [mse_gk, mse_gk_tuned, mse_gk_tuned_no_earlystop]\n",
    "gk_mse_all = [round(num, 3) for num in gk_mse_all]\n",
    "\n",
    "gk_rmse_all = [rmse_gk, rmse_gk_tuned, rmse_gk_tuned_no_earlystop]\n",
    "gk_rmse_all = [round(num, 3) for num in gk_rmse_all]\n",
    "\n",
    "gk_mae_all = [mae_gk, mae_gk_tuned, mae_gk_tuned_no_earlystop]\n",
    "gk_mae_all = [round(num, 3) for num in gk_mae_all]\n",
    "\n",
    "gk_mape_all = [mape_gk, mape_gk_tuned, mape_gk_tuned_no_earlystop]\n",
    "gk_mape_all = [round(num, 3) for num in gk_mape_all]\n",
    "\n",
    "r2_score_gk_all = [r2_score_gk, r2_score_gk_tuned, r2_score_gk_tuned_no_earlystop]\n",
    "r2_score_gk_all = [round(num, 3) for num in r2_score_gk_all]\n",
    "\n",
    "epochs_all = [epochs, epochs_earlystop, epochs_no_earlystop]\n",
    "\n",
    "\n",
    "method = [\"Neural Network\", 'Neural Netwotk with Hyperparm. Optimiztion + EarlyStopping', \"Neural Netwotk with Hyperparm. Optimiztion without EarlyStopping\"]\n",
    "overview_gk = PrettyTable()\n",
    "\n",
    "overview_gk.add_column(\"Method for goalkeepers dataset\", method)\n",
    "overview_gk.add_column(\"MSE\", gk_mse_all)\n",
    "overview_gk.add_column(\"RMSE\", gk_rmse_all)\n",
    "overview_gk.add_column(\"MAE\", gk_mae_all)\n",
    "overview_gk.add_column(\"MAPE\", gk_mape_all)\n",
    "overview_gk.add_column(\"R squared \",r2_score_gk_all)\n",
    "overview_gk.add_column(\"Epochs \",epochs_all)\n",
    "\n",
    "print(overview_gk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00102-2f900986-f2b6-4981-abe6-6297001ec39a",
    "deepnote_cell_type": "text-cell-h3",
    "tags": []
   },
   "source": [
    "## Applying NN on NON-goalkeepers dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00103-6b3e683b-c47f-425f-9beb-6afecccf2474",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "The exactly same procedure will be applied to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00104-6a70fad3-191f-4860-84f4-8cccc26706cb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 73,
    "execution_start": 1621692409020,
    "source_hash": "27c1f979",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load relative libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00068-b5710000-65db-4ff6-aacd-51e186c2d001",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "np.random.seed(37)\n",
    "rn.seed(1254)\n",
    "tf.random.set_seed(89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00105-c7f1b678-f518-42c5-be3a-eb7a6b0aa082",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 33,
    "execution_start": 1621692416224,
    "source_hash": "ec490c1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_field= field_df.drop([\"value_eur\"], axis = 1)   #independent features\n",
    "y_field = field_df[\"value_eur\"]                 #dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00106-34d13af8-90a9-40fa-ab5c-11de068bdc01",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15,
    "execution_start": 1621689174081,
    "source_hash": "7b546aa2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_field, y_field, test_size=1/3, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00107-38fe6b05-deb7-4bde-987e-4fa4e75d56ec",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1621689174981,
    "source_hash": "e349cc94",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set field shape: (11102, 43)\n",
      "Test set field shape: (5551, 43)\n",
      "Training features shape: (11102,)\n",
      "Test label set shape: (5551,)\n"
     ]
    }
   ],
   "source": [
    "#checking the shape of our train set and test set\n",
    "\n",
    "print(\"Training set field shape: {}\".format(X_train.shape))\n",
    "print(\"Test set field shape: {}\".format(X_test.shape))\n",
    "print(\"Training features shape: {}\".format(y_train.shape))\n",
    "print(\"Test label set shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00108-39e83bcb-5f4c-4950-a795-5572923a67eb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1621689176017,
    "source_hash": "a7bf9899",
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00073-748d7291-7dd8-4709-9a72-077183375500",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Benchmark model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00111-d8fe8fce-ad29-4885-be02-b3f23995965c",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "A first benchamark model will be built.\n",
    "Because of the good results in the previous models, we decided to mantain, complessively the same amount of neurons and layers. Moreover, as it has been done for the goalkeepers dataset, if necessary the parameters will be furtherly tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00110-8fd5b203-c178-4583-9da1-7b9e12826a0a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 60,
    "execution_start": 1621689178764,
    "source_hash": "6d68d424",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Since now we are predicting a single continuous value, the output layer will only have 1 node.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim = X_field.shape[1], activation = \"relu\"))\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(Dense(32, activation = \"relu\"))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1, activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00113-f43796bd-f049-4047-bbd5-a1c3cdd45167",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 35,
    "execution_start": 1621689179795,
    "source_hash": "c51f67e2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 128)               5632      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 16,001\n",
      "Trainable params: 16,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"mse\", optimizer = \"adam\", metrics = [\"mse\", \"mae\", \"mape\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00114-a8d916e4-8f87-463b-998b-5b7cb6727700",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 206230,
    "execution_start": 1621689181694,
    "source_hash": "cc4d0ba8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 48.8311 - mse: 48.8311 - mae: 4.7740 - mape: 35.2346 - val_loss: 0.5071 - val_mse: 0.5071 - val_mae: 0.5642 - val_mape: 4.1907\n",
      "Epoch 2/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.3954 - mse: 0.3954 - mae: 0.4987 - mape: 3.7039 - val_loss: 0.2401 - val_mse: 0.2401 - val_mae: 0.3871 - val_mape: 2.8711\n",
      "Epoch 3/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.2154 - mse: 0.2154 - mae: 0.3648 - mape: 2.7036 - val_loss: 0.1598 - val_mse: 0.1598 - val_mae: 0.3130 - val_mape: 2.3205\n",
      "Epoch 4/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1487 - mse: 0.1487 - mae: 0.3030 - mape: 2.2501 - val_loss: 0.1296 - val_mse: 0.1296 - val_mae: 0.2787 - val_mape: 2.0661\n",
      "Epoch 5/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1262 - mse: 0.1262 - mae: 0.2802 - mape: 2.0747 - val_loss: 0.1119 - val_mse: 0.1119 - val_mae: 0.2620 - val_mape: 1.9316\n",
      "Epoch 6/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1145 - mse: 0.1145 - mae: 0.2670 - mape: 1.9806 - val_loss: 0.1042 - val_mse: 0.1042 - val_mae: 0.2524 - val_mape: 1.8666\n",
      "Epoch 7/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1049 - mse: 0.1049 - mae: 0.2550 - mape: 1.8870 - val_loss: 0.0943 - val_mse: 0.0943 - val_mae: 0.2389 - val_mape: 1.7688\n",
      "Epoch 8/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0982 - mse: 0.0982 - mae: 0.2465 - mape: 1.8282 - val_loss: 0.0976 - val_mse: 0.0976 - val_mae: 0.2450 - val_mape: 1.8024\n",
      "Epoch 9/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0971 - mse: 0.0971 - mae: 0.2460 - mape: 1.8188 - val_loss: 0.1046 - val_mse: 0.1046 - val_mae: 0.2508 - val_mape: 1.8585\n",
      "Epoch 10/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0939 - mse: 0.0939 - mae: 0.2400 - mape: 1.7749 - val_loss: 0.1384 - val_mse: 0.1384 - val_mae: 0.2946 - val_mape: 2.1894\n",
      "Epoch 11/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0997 - mse: 0.0997 - mae: 0.2478 - mape: 1.8307 - val_loss: 0.1093 - val_mse: 0.1093 - val_mae: 0.2624 - val_mape: 1.9153\n",
      "Epoch 12/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0959 - mse: 0.0959 - mae: 0.2418 - mape: 1.7869 - val_loss: 0.0803 - val_mse: 0.0803 - val_mae: 0.2191 - val_mape: 1.6153\n",
      "Epoch 13/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0897 - mse: 0.0897 - mae: 0.2331 - mape: 1.7232 - val_loss: 0.0812 - val_mse: 0.0812 - val_mae: 0.2216 - val_mape: 1.6339\n",
      "Epoch 14/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0947 - mse: 0.0947 - mae: 0.2410 - mape: 1.7799 - val_loss: 0.0778 - val_mse: 0.0778 - val_mae: 0.2154 - val_mape: 1.5871\n",
      "Epoch 15/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0800 - mse: 0.0800 - mae: 0.2189 - mape: 1.6168 - val_loss: 0.0865 - val_mse: 0.0865 - val_mae: 0.2311 - val_mape: 1.6892\n",
      "Epoch 16/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0815 - mse: 0.0815 - mae: 0.2218 - mape: 1.6384 - val_loss: 0.0737 - val_mse: 0.0737 - val_mae: 0.2101 - val_mape: 1.5386\n",
      "Epoch 17/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0785 - mse: 0.0785 - mae: 0.2199 - mape: 1.6237 - val_loss: 0.1308 - val_mse: 0.1308 - val_mae: 0.3006 - val_mape: 2.1927\n",
      "Epoch 18/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2336 - mape: 1.7220 - val_loss: 0.0726 - val_mse: 0.0726 - val_mae: 0.2094 - val_mape: 1.5374\n",
      "Epoch 19/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0777 - mse: 0.0777 - mae: 0.2172 - mape: 1.6001 - val_loss: 0.0747 - val_mse: 0.0747 - val_mae: 0.2111 - val_mape: 1.5545\n",
      "Epoch 20/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0772 - mse: 0.0772 - mae: 0.2166 - mape: 1.5983 - val_loss: 0.0942 - val_mse: 0.0942 - val_mae: 0.2448 - val_mape: 1.7851\n",
      "Epoch 21/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0762 - mse: 0.0762 - mae: 0.2156 - mape: 1.5893 - val_loss: 0.0678 - val_mse: 0.0678 - val_mae: 0.2015 - val_mape: 1.4758\n",
      "Epoch 22/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0744 - mse: 0.0744 - mae: 0.2126 - mape: 1.5662 - val_loss: 0.1297 - val_mse: 0.1297 - val_mae: 0.2988 - val_mape: 2.1763\n",
      "Epoch 23/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0808 - mse: 0.0808 - mae: 0.2218 - mape: 1.6319 - val_loss: 0.0752 - val_mse: 0.0752 - val_mae: 0.2098 - val_mape: 1.5498\n",
      "Epoch 24/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0769 - mse: 0.0769 - mae: 0.2174 - mape: 1.6027 - val_loss: 0.0713 - val_mse: 0.0713 - val_mae: 0.2086 - val_mape: 1.5228\n",
      "Epoch 25/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0858 - mse: 0.0858 - mae: 0.2297 - mape: 1.6954 - val_loss: 0.0712 - val_mse: 0.0712 - val_mae: 0.2045 - val_mape: 1.5083\n",
      "Epoch 26/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0740 - mse: 0.0740 - mae: 0.2135 - mape: 1.5720 - val_loss: 0.0671 - val_mse: 0.0671 - val_mae: 0.1989 - val_mape: 1.4636\n",
      "Epoch 27/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0693 - mse: 0.0693 - mae: 0.2054 - mape: 1.5159 - val_loss: 0.0643 - val_mse: 0.0643 - val_mae: 0.1941 - val_mape: 1.4252\n",
      "Epoch 28/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0654 - mse: 0.0654 - mae: 0.1993 - mape: 1.4653 - val_loss: 0.0821 - val_mse: 0.0821 - val_mae: 0.2289 - val_mape: 1.6687\n",
      "Epoch 29/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0705 - mse: 0.0705 - mae: 0.2069 - mape: 1.5207 - val_loss: 0.0674 - val_mse: 0.0674 - val_mae: 0.1989 - val_mape: 1.4636\n",
      "Epoch 30/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0677 - mse: 0.0677 - mae: 0.2031 - mape: 1.4953 - val_loss: 0.0654 - val_mse: 0.0654 - val_mae: 0.1943 - val_mape: 1.4297\n",
      "Epoch 31/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0656 - mse: 0.0656 - mae: 0.1995 - mape: 1.4697 - val_loss: 0.0718 - val_mse: 0.0718 - val_mae: 0.2073 - val_mape: 1.5108\n",
      "Epoch 32/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0693 - mse: 0.0693 - mae: 0.2053 - mape: 1.5124 - val_loss: 0.0793 - val_mse: 0.0793 - val_mae: 0.2265 - val_mape: 1.6608\n",
      "Epoch 33/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0689 - mse: 0.0689 - mae: 0.2044 - mape: 1.5067 - val_loss: 0.0673 - val_mse: 0.0673 - val_mae: 0.1981 - val_mape: 1.4596\n",
      "Epoch 34/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0640 - mse: 0.0640 - mae: 0.1978 - mape: 1.4516 - val_loss: 0.0648 - val_mse: 0.0648 - val_mae: 0.1962 - val_mape: 1.4332\n",
      "Epoch 35/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0713 - mse: 0.0713 - mae: 0.2076 - mape: 1.5273 - val_loss: 0.0867 - val_mse: 0.0867 - val_mae: 0.2354 - val_mape: 1.7082\n",
      "Epoch 36/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0644 - mse: 0.0644 - mae: 0.1978 - mape: 1.4558 - val_loss: 0.0628 - val_mse: 0.0628 - val_mae: 0.1931 - val_mape: 1.4131\n",
      "Epoch 37/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0665 - mse: 0.0665 - mae: 0.2009 - mape: 1.4771 - val_loss: 0.0626 - val_mse: 0.0626 - val_mae: 0.1935 - val_mape: 1.4168\n",
      "Epoch 38/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0772 - mse: 0.0772 - mae: 0.2165 - mape: 1.5905 - val_loss: 0.0868 - val_mse: 0.0868 - val_mae: 0.2353 - val_mape: 1.7094\n",
      "Epoch 39/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0669 - mse: 0.0669 - mae: 0.2004 - mape: 1.4771 - val_loss: 0.0655 - val_mse: 0.0655 - val_mae: 0.1973 - val_mape: 1.4387\n",
      "Epoch 40/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0695 - mse: 0.0695 - mae: 0.2067 - mape: 1.5217 - val_loss: 0.0931 - val_mse: 0.0931 - val_mae: 0.2487 - val_mape: 1.8109\n",
      "Epoch 41/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0660 - mse: 0.0660 - mae: 0.2001 - mape: 1.4709 - val_loss: 0.0608 - val_mse: 0.0608 - val_mae: 0.1869 - val_mape: 1.3727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0624 - mse: 0.0624 - mae: 0.1939 - mape: 1.4245 - val_loss: 0.0886 - val_mse: 0.0886 - val_mae: 0.2342 - val_mape: 1.6986\n",
      "Epoch 43/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0631 - mse: 0.0631 - mae: 0.1953 - mape: 1.4376 - val_loss: 0.0604 - val_mse: 0.0604 - val_mae: 0.1894 - val_mape: 1.3850\n",
      "Epoch 44/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0608 - mse: 0.0608 - mae: 0.1917 - mape: 1.4124 - val_loss: 0.0724 - val_mse: 0.0724 - val_mae: 0.2107 - val_mape: 1.5376\n",
      "Epoch 45/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0604 - mse: 0.0604 - mae: 0.1924 - mape: 1.4188 - val_loss: 0.0600 - val_mse: 0.0600 - val_mae: 0.1875 - val_mape: 1.3770\n",
      "Epoch 46/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0573 - mse: 0.0573 - mae: 0.1864 - mape: 1.3717 - val_loss: 0.0609 - val_mse: 0.0609 - val_mae: 0.1904 - val_mape: 1.3935\n",
      "Epoch 47/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0609 - mse: 0.0609 - mae: 0.1912 - mape: 1.4046 - val_loss: 0.0791 - val_mse: 0.0791 - val_mae: 0.2175 - val_mape: 1.6089\n",
      "Epoch 48/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0613 - mse: 0.0613 - mae: 0.1940 - mape: 1.4279 - val_loss: 0.1552 - val_mse: 0.1552 - val_mae: 0.3223 - val_mape: 2.3840\n",
      "Epoch 49/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0704 - mse: 0.0704 - mae: 0.2061 - mape: 1.5158 - val_loss: 0.0873 - val_mse: 0.0873 - val_mae: 0.2383 - val_mape: 1.7309\n",
      "Epoch 50/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0629 - mse: 0.0629 - mae: 0.1958 - mape: 1.4419 - val_loss: 0.0629 - val_mse: 0.0629 - val_mae: 0.1959 - val_mape: 1.4365\n",
      "Epoch 51/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0635 - mse: 0.0635 - mae: 0.1970 - mape: 1.4487 - val_loss: 0.0719 - val_mse: 0.0719 - val_mae: 0.2035 - val_mape: 1.5028\n",
      "Epoch 52/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0579 - mse: 0.0579 - mae: 0.1874 - mape: 1.3792 - val_loss: 0.0611 - val_mse: 0.0611 - val_mae: 0.1890 - val_mape: 1.3901\n",
      "Epoch 53/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0626 - mse: 0.0626 - mae: 0.1938 - mape: 1.4271 - val_loss: 0.0888 - val_mse: 0.0888 - val_mae: 0.2425 - val_mape: 1.7636\n",
      "Epoch 54/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0625 - mse: 0.0625 - mae: 0.1936 - mape: 1.4258 - val_loss: 0.0578 - val_mse: 0.0578 - val_mae: 0.1844 - val_mape: 1.3534\n",
      "Epoch 55/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0610 - mse: 0.0610 - mae: 0.1929 - mape: 1.4191 - val_loss: 0.0601 - val_mse: 0.0601 - val_mae: 0.1893 - val_mape: 1.3893\n",
      "Epoch 56/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0584 - mse: 0.0584 - mae: 0.1863 - mape: 1.3710 - val_loss: 0.0622 - val_mse: 0.0622 - val_mae: 0.1897 - val_mape: 1.3977\n",
      "Epoch 57/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0556 - mse: 0.0556 - mae: 0.1826 - mape: 1.3412 - val_loss: 0.0621 - val_mse: 0.0621 - val_mae: 0.1928 - val_mape: 1.4067\n",
      "Epoch 58/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0626 - mse: 0.0626 - mae: 0.1940 - mape: 1.4293 - val_loss: 0.0982 - val_mse: 0.0982 - val_mae: 0.2593 - val_mape: 1.8901\n",
      "Epoch 59/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0624 - mse: 0.0624 - mae: 0.1956 - mape: 1.4427 - val_loss: 0.0586 - val_mse: 0.0586 - val_mae: 0.1862 - val_mape: 1.3581\n",
      "Epoch 60/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0563 - mse: 0.0563 - mae: 0.1844 - mape: 1.3590 - val_loss: 0.0587 - val_mse: 0.0587 - val_mae: 0.1852 - val_mape: 1.3614\n",
      "Epoch 61/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0597 - mse: 0.0597 - mae: 0.1906 - mape: 1.4040 - val_loss: 0.0814 - val_mse: 0.0814 - val_mae: 0.2258 - val_mape: 1.6364\n",
      "Epoch 62/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0556 - mse: 0.0556 - mae: 0.1831 - mape: 1.3478 - val_loss: 0.0626 - val_mse: 0.0626 - val_mae: 0.1941 - val_mape: 1.4171\n",
      "Epoch 63/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0553 - mse: 0.0553 - mae: 0.1820 - mape: 1.3344 - val_loss: 0.0605 - val_mse: 0.0605 - val_mae: 0.1894 - val_mape: 1.3899\n",
      "Epoch 64/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0553 - mse: 0.0553 - mae: 0.1828 - mape: 1.3445 - val_loss: 0.0615 - val_mse: 0.0615 - val_mae: 0.1905 - val_mape: 1.3903\n",
      "Epoch 65/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0565 - mse: 0.0565 - mae: 0.1851 - mape: 1.3638 - val_loss: 0.0744 - val_mse: 0.0744 - val_mae: 0.2087 - val_mape: 1.5405\n",
      "Epoch 66/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0624 - mse: 0.0624 - mae: 0.1945 - mape: 1.4304 - val_loss: 0.0594 - val_mse: 0.0594 - val_mae: 0.1891 - val_mape: 1.3835\n",
      "Epoch 67/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0541 - mse: 0.0541 - mae: 0.1803 - mape: 1.3271 - val_loss: 0.0592 - val_mse: 0.0592 - val_mae: 0.1876 - val_mape: 1.3691\n",
      "Epoch 68/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0522 - mse: 0.0522 - mae: 0.1774 - mape: 1.3052 - val_loss: 0.0670 - val_mse: 0.0670 - val_mae: 0.2015 - val_mape: 1.4679\n",
      "Epoch 69/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0624 - mse: 0.0624 - mae: 0.1946 - mape: 1.4364 - val_loss: 0.0577 - val_mse: 0.0577 - val_mae: 0.1850 - val_mape: 1.3557\n",
      "Epoch 70/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0576 - mse: 0.0576 - mae: 0.1867 - mape: 1.3720 - val_loss: 0.0715 - val_mse: 0.0715 - val_mae: 0.2044 - val_mape: 1.5100\n",
      "Epoch 71/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0608 - mse: 0.0608 - mae: 0.1923 - mape: 1.4141 - val_loss: 0.0823 - val_mse: 0.0823 - val_mae: 0.2291 - val_mape: 1.6603\n",
      "Epoch 72/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0568 - mse: 0.0568 - mae: 0.1873 - mape: 1.3767 - val_loss: 0.0607 - val_mse: 0.0607 - val_mae: 0.1895 - val_mape: 1.3908\n",
      "Epoch 73/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0555 - mse: 0.0555 - mae: 0.1840 - mape: 1.3553 - val_loss: 0.0613 - val_mse: 0.0613 - val_mae: 0.1877 - val_mape: 1.3813\n",
      "Epoch 74/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0627 - mse: 0.0627 - mae: 0.1958 - mape: 1.4386 - val_loss: 0.0568 - val_mse: 0.0568 - val_mae: 0.1828 - val_mape: 1.3406\n",
      "Epoch 75/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0535 - mse: 0.0535 - mae: 0.1808 - mape: 1.3294 - val_loss: 0.0571 - val_mse: 0.0571 - val_mae: 0.1826 - val_mape: 1.3386\n",
      "Epoch 76/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0612 - mse: 0.0612 - mae: 0.1906 - mape: 1.3991 - val_loss: 0.0590 - val_mse: 0.0590 - val_mae: 0.1884 - val_mape: 1.3741\n",
      "Epoch 77/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0544 - mse: 0.0544 - mae: 0.1808 - mape: 1.3336 - val_loss: 0.0922 - val_mse: 0.0922 - val_mae: 0.2490 - val_mape: 1.8129\n",
      "Epoch 78/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0605 - mse: 0.0605 - mae: 0.1891 - mape: 1.3897 - val_loss: 0.0687 - val_mse: 0.0687 - val_mae: 0.2018 - val_mape: 1.4913\n",
      "Epoch 79/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0558 - mae: 0.1838 - mape: 1.3556 - val_loss: 0.0559 - val_mse: 0.0559 - val_mae: 0.1809 - val_mape: 1.3293\n",
      "Epoch 80/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0584 - mse: 0.0584 - mae: 0.1881 - mape: 1.3850 - val_loss: 0.0645 - val_mse: 0.0645 - val_mae: 0.1984 - val_mape: 1.4447\n",
      "Epoch 81/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0524 - mse: 0.0524 - mae: 0.1776 - mape: 1.3083 - val_loss: 0.0642 - val_mse: 0.0642 - val_mae: 0.1940 - val_mape: 1.4329\n",
      "Epoch 82/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0546 - mse: 0.0546 - mae: 0.1813 - mape: 1.3338 - val_loss: 0.0835 - val_mse: 0.0835 - val_mae: 0.2255 - val_mape: 1.6723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.1769 - mape: 1.3011 - val_loss: 0.0966 - val_mse: 0.0966 - val_mae: 0.2549 - val_mape: 1.8545\n",
      "Epoch 84/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0549 - mse: 0.0549 - mae: 0.1811 - mape: 1.3305 - val_loss: 0.0572 - val_mse: 0.0572 - val_mae: 0.1841 - val_mape: 1.3479\n",
      "Epoch 85/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.1759 - mape: 1.2954 - val_loss: 0.0593 - val_mse: 0.0593 - val_mae: 0.1889 - val_mape: 1.3794\n",
      "Epoch 86/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0546 - mse: 0.0546 - mae: 0.1803 - mape: 1.3293 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1778 - val_mape: 1.3052\n",
      "Epoch 87/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.1787 - mape: 1.3132 - val_loss: 0.0674 - val_mse: 0.0674 - val_mae: 0.1981 - val_mape: 1.4622\n",
      "Epoch 88/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0571 - mse: 0.0571 - mae: 0.1847 - mape: 1.3570 - val_loss: 0.0568 - val_mse: 0.0568 - val_mae: 0.1807 - val_mape: 1.3299\n",
      "Epoch 89/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0572 - mse: 0.0572 - mae: 0.1848 - mape: 1.3584 - val_loss: 0.0578 - val_mse: 0.0578 - val_mae: 0.1824 - val_mape: 1.3403\n",
      "Epoch 90/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0528 - mse: 0.0528 - mae: 0.1782 - mape: 1.3126 - val_loss: 0.0582 - val_mse: 0.0582 - val_mae: 0.1849 - val_mape: 1.3584\n",
      "Epoch 91/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1736 - mape: 1.2767 - val_loss: 0.0690 - val_mse: 0.0690 - val_mae: 0.2040 - val_mape: 1.5087\n",
      "Epoch 92/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.1777 - mape: 1.3073 - val_loss: 0.0774 - val_mse: 0.0774 - val_mae: 0.2167 - val_mape: 1.6069\n",
      "Epoch 93/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1725 - mape: 1.2702 - val_loss: 0.0826 - val_mse: 0.0826 - val_mae: 0.2333 - val_mape: 1.7101\n",
      "Epoch 94/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0546 - mse: 0.0546 - mae: 0.1817 - mape: 1.3391 - val_loss: 0.0668 - val_mse: 0.0668 - val_mae: 0.2040 - val_mape: 1.4856\n",
      "Epoch 95/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0555 - mse: 0.0555 - mae: 0.1833 - mape: 1.3485 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2401 - val_mape: 1.7566\n",
      "Epoch 96/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.1797 - mape: 1.3240 - val_loss: 0.0696 - val_mse: 0.0696 - val_mae: 0.2101 - val_mape: 1.5386\n",
      "Epoch 97/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.1804 - mape: 1.3277 - val_loss: 0.0842 - val_mse: 0.0842 - val_mae: 0.2366 - val_mape: 1.7280\n",
      "Epoch 98/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0543 - mse: 0.0543 - mae: 0.1804 - mape: 1.3236 - val_loss: 0.0846 - val_mse: 0.0846 - val_mae: 0.2342 - val_mape: 1.7015\n",
      "Epoch 99/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0546 - mse: 0.0546 - mae: 0.1813 - mape: 1.3304 - val_loss: 0.0583 - val_mse: 0.0583 - val_mae: 0.1830 - val_mape: 1.3484\n",
      "Epoch 100/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0536 - mse: 0.0536 - mae: 0.1797 - mape: 1.3245 - val_loss: 0.0758 - val_mse: 0.0758 - val_mae: 0.2203 - val_mape: 1.6049\n",
      "Epoch 101/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0545 - mse: 0.0545 - mae: 0.1805 - mape: 1.3271 - val_loss: 0.0571 - val_mse: 0.0571 - val_mae: 0.1817 - val_mape: 1.3378\n",
      "Epoch 102/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.1782 - mape: 1.3114 - val_loss: 0.0566 - val_mse: 0.0566 - val_mae: 0.1843 - val_mape: 1.3531\n",
      "Epoch 103/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0543 - mse: 0.0543 - mae: 0.1801 - mape: 1.3263 - val_loss: 0.0574 - val_mse: 0.0574 - val_mae: 0.1860 - val_mape: 1.3607\n",
      "Epoch 104/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0507 - mse: 0.0507 - mae: 0.1763 - mape: 1.3009 - val_loss: 0.0548 - val_mse: 0.0548 - val_mae: 0.1796 - val_mape: 1.3166\n",
      "Epoch 105/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1746 - mape: 1.2832 - val_loss: 0.0568 - val_mse: 0.0568 - val_mae: 0.1821 - val_mape: 1.3403\n",
      "Epoch 106/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0541 - mse: 0.0541 - mae: 0.1803 - mape: 1.3282 - val_loss: 0.0582 - val_mse: 0.0582 - val_mae: 0.1877 - val_mape: 1.3722\n",
      "Epoch 107/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0527 - mse: 0.0527 - mae: 0.1780 - mape: 1.3083 - val_loss: 0.0639 - val_mse: 0.0639 - val_mae: 0.1962 - val_mape: 1.4258\n",
      "Epoch 108/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1728 - mape: 1.2711 - val_loss: 0.0582 - val_mse: 0.0582 - val_mae: 0.1847 - val_mape: 1.3572\n",
      "Epoch 109/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.1769 - mape: 1.3005 - val_loss: 0.0728 - val_mse: 0.0728 - val_mae: 0.2089 - val_mape: 1.5457\n",
      "Epoch 110/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0556 - mse: 0.0556 - mae: 0.1801 - mape: 1.3254 - val_loss: 0.0618 - val_mse: 0.0618 - val_mae: 0.1896 - val_mape: 1.3986\n",
      "Epoch 111/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.1758 - mape: 1.2949 - val_loss: 0.0556 - val_mse: 0.0556 - val_mae: 0.1805 - val_mape: 1.3248\n",
      "Epoch 112/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0499 - mse: 0.0499 - mae: 0.1725 - mape: 1.2703 - val_loss: 0.0664 - val_mse: 0.0664 - val_mae: 0.2005 - val_mape: 1.4842\n",
      "Epoch 113/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1742 - mape: 1.2855 - val_loss: 0.0564 - val_mse: 0.0564 - val_mae: 0.1831 - val_mape: 1.3464\n",
      "Epoch 114/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1703 - mape: 1.2551 - val_loss: 0.0553 - val_mse: 0.0553 - val_mae: 0.1803 - val_mape: 1.3238\n",
      "Epoch 115/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0482 - mse: 0.0482 - mae: 0.1698 - mape: 1.2516 - val_loss: 0.0544 - val_mse: 0.0544 - val_mae: 0.1783 - val_mape: 1.3083\n",
      "Epoch 116/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0492 - mse: 0.0492 - mae: 0.1717 - mape: 1.2659 - val_loss: 0.0663 - val_mse: 0.0663 - val_mae: 0.1959 - val_mape: 1.4486\n",
      "Epoch 117/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.1789 - mape: 1.3188 - val_loss: 0.0579 - val_mse: 0.0579 - val_mae: 0.1876 - val_mape: 1.3760\n",
      "Epoch 118/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1718 - mape: 1.2688 - val_loss: 0.0559 - val_mse: 0.0559 - val_mae: 0.1806 - val_mape: 1.3297\n",
      "Epoch 119/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1730 - mape: 1.2746 - val_loss: 0.0580 - val_mse: 0.0580 - val_mae: 0.1861 - val_mape: 1.3623\n",
      "Epoch 120/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0510 - mse: 0.0510 - mae: 0.1761 - mape: 1.2944 - val_loss: 0.0579 - val_mse: 0.0579 - val_mae: 0.1873 - val_mape: 1.3709\n",
      "Epoch 121/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1758 - mape: 1.2945 - val_loss: 0.0578 - val_mse: 0.0578 - val_mae: 0.1854 - val_mape: 1.3640\n",
      "Epoch 122/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1717 - mape: 1.2624 - val_loss: 0.0634 - val_mse: 0.0634 - val_mae: 0.1935 - val_mape: 1.4316\n",
      "Epoch 123/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0552 - mse: 0.0552 - mae: 0.1829 - mape: 1.3432 - val_loss: 0.0683 - val_mse: 0.0683 - val_mae: 0.2007 - val_mape: 1.4842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.1764 - mape: 1.2998 - val_loss: 0.0574 - val_mse: 0.0574 - val_mae: 0.1825 - val_mape: 1.3418\n",
      "Epoch 125/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1717 - mape: 1.2605 - val_loss: 0.0579 - val_mse: 0.0579 - val_mae: 0.1865 - val_mape: 1.3698\n",
      "Epoch 126/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1713 - mape: 1.2602 - val_loss: 0.0564 - val_mse: 0.0564 - val_mae: 0.1820 - val_mape: 1.3376\n",
      "Epoch 127/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1688 - mape: 1.2422 - val_loss: 0.0905 - val_mse: 0.0905 - val_mae: 0.2442 - val_mape: 1.7749\n",
      "Epoch 128/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.1786 - mape: 1.3141 - val_loss: 0.0537 - val_mse: 0.0537 - val_mae: 0.1777 - val_mape: 1.3030\n",
      "Epoch 129/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1713 - mape: 1.2600 - val_loss: 0.0626 - val_mse: 0.0626 - val_mae: 0.1958 - val_mape: 1.4306\n",
      "Epoch 130/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.1765 - mape: 1.2971 - val_loss: 0.0558 - val_mse: 0.0558 - val_mae: 0.1823 - val_mape: 1.3305\n",
      "Epoch 131/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1708 - mape: 1.2573 - val_loss: 0.0581 - val_mse: 0.0581 - val_mae: 0.1841 - val_mape: 1.3559\n",
      "Epoch 132/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1726 - mape: 1.2697 - val_loss: 0.0699 - val_mse: 0.0699 - val_mae: 0.2048 - val_mape: 1.5144\n",
      "Epoch 133/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.1770 - mape: 1.3020 - val_loss: 0.0813 - val_mse: 0.0813 - val_mae: 0.2195 - val_mape: 1.6259\n",
      "Epoch 134/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.1780 - mape: 1.3103 - val_loss: 0.0564 - val_mse: 0.0564 - val_mae: 0.1851 - val_mape: 1.3550\n",
      "Epoch 135/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1685 - mape: 1.2401 - val_loss: 0.0582 - val_mse: 0.0582 - val_mae: 0.1838 - val_mape: 1.3549\n",
      "Epoch 136/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1733 - mape: 1.2771 - val_loss: 0.0610 - val_mse: 0.0610 - val_mae: 0.1946 - val_mape: 1.4237\n",
      "Epoch 137/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1720 - mape: 1.2678 - val_loss: 0.0544 - val_mse: 0.0544 - val_mae: 0.1801 - val_mape: 1.3212\n",
      "Epoch 138/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1661 - mape: 1.2228 - val_loss: 0.0777 - val_mse: 0.0777 - val_mae: 0.2156 - val_mape: 1.5968\n",
      "Epoch 139/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1755 - mape: 1.2940 - val_loss: 0.0583 - val_mse: 0.0583 - val_mae: 0.1860 - val_mape: 1.3710\n",
      "Epoch 140/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1706 - mape: 1.2571 - val_loss: 0.0679 - val_mse: 0.0679 - val_mae: 0.2087 - val_mape: 1.5276\n",
      "Epoch 141/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0554 - mse: 0.0554 - mae: 0.1846 - mape: 1.3601 - val_loss: 0.0531 - val_mse: 0.0531 - val_mae: 0.1765 - val_mape: 1.2948\n",
      "Epoch 142/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1743 - mape: 1.2851 - val_loss: 0.0628 - val_mse: 0.0628 - val_mae: 0.1912 - val_mape: 1.4114\n",
      "Epoch 143/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0461 - mse: 0.0461 - mae: 0.1661 - mape: 1.2252 - val_loss: 0.0594 - val_mse: 0.0594 - val_mae: 0.1850 - val_mape: 1.3639\n",
      "Epoch 144/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0459 - mse: 0.0459 - mae: 0.1654 - mape: 1.2192 - val_loss: 0.0634 - val_mse: 0.0634 - val_mae: 0.1971 - val_mape: 1.4417\n",
      "Epoch 145/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1693 - mape: 1.2484 - val_loss: 0.0778 - val_mse: 0.0778 - val_mae: 0.2155 - val_mape: 1.5989\n",
      "Epoch 146/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.1755 - mape: 1.2891 - val_loss: 0.0542 - val_mse: 0.0542 - val_mae: 0.1773 - val_mape: 1.3008\n",
      "Epoch 147/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0579 - mse: 0.0579 - mae: 0.1876 - mape: 1.3839 - val_loss: 0.0571 - val_mse: 0.0571 - val_mae: 0.1821 - val_mape: 1.3401\n",
      "Epoch 148/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.1747 - mape: 1.2880 - val_loss: 0.0548 - val_mse: 0.0548 - val_mae: 0.1790 - val_mape: 1.3131\n",
      "Epoch 149/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0452 - mse: 0.0452 - mae: 0.1651 - mape: 1.2172 - val_loss: 0.0542 - val_mse: 0.0542 - val_mae: 0.1785 - val_mape: 1.3114\n",
      "Epoch 150/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.1772 - mape: 1.3074 - val_loss: 0.0529 - val_mse: 0.0529 - val_mae: 0.1751 - val_mape: 1.2874\n",
      "Epoch 151/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1666 - mape: 1.2292 - val_loss: 0.0576 - val_mse: 0.0576 - val_mae: 0.1813 - val_mape: 1.3369\n",
      "Epoch 152/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1721 - mape: 1.2644 - val_loss: 0.0624 - val_mse: 0.0624 - val_mae: 0.1967 - val_mape: 1.4342\n",
      "Epoch 153/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1694 - mape: 1.2474 - val_loss: 0.0841 - val_mse: 0.0841 - val_mae: 0.2284 - val_mape: 1.6876\n",
      "Epoch 154/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0457 - mse: 0.0457 - mae: 0.1642 - mape: 1.2149 - val_loss: 0.0540 - val_mse: 0.0540 - val_mae: 0.1769 - val_mape: 1.3004\n",
      "Epoch 155/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1657 - mape: 1.2207 - val_loss: 0.0577 - val_mse: 0.0577 - val_mae: 0.1844 - val_mape: 1.3611\n",
      "Epoch 156/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1735 - mape: 1.2805 - val_loss: 0.0610 - val_mse: 0.0610 - val_mae: 0.1930 - val_mape: 1.4060\n",
      "Epoch 157/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1678 - mape: 1.2386 - val_loss: 0.0629 - val_mse: 0.0629 - val_mae: 0.1974 - val_mape: 1.4459\n",
      "Epoch 158/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1752 - mape: 1.2893 - val_loss: 0.0617 - val_mse: 0.0617 - val_mae: 0.1890 - val_mape: 1.3959\n",
      "Epoch 159/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0457 - mse: 0.0457 - mae: 0.1660 - mape: 1.2220 - val_loss: 0.0580 - val_mse: 0.0580 - val_mae: 0.1872 - val_mape: 1.3681\n",
      "Epoch 160/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0453 - mse: 0.0453 - mae: 0.1656 - mape: 1.2198 - val_loss: 0.0567 - val_mse: 0.0567 - val_mae: 0.1842 - val_mape: 1.3499\n",
      "Epoch 161/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0460 - mse: 0.0460 - mae: 0.1659 - mape: 1.2226 - val_loss: 0.0592 - val_mse: 0.0592 - val_mae: 0.1875 - val_mape: 1.3810\n",
      "Epoch 162/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1679 - mape: 1.2418 - val_loss: 0.0546 - val_mse: 0.0546 - val_mae: 0.1801 - val_mape: 1.3203\n",
      "Epoch 163/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0461 - mse: 0.0461 - mae: 0.1652 - mape: 1.2159 - val_loss: 0.0566 - val_mse: 0.0566 - val_mae: 0.1813 - val_mape: 1.3337\n",
      "Epoch 164/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0453 - mse: 0.0453 - mae: 0.1645 - mape: 1.2119 - val_loss: 0.0541 - val_mse: 0.0541 - val_mae: 0.1756 - val_mape: 1.2926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1663 - mape: 1.2249 - val_loss: 0.0677 - val_mse: 0.0677 - val_mae: 0.1986 - val_mape: 1.4717\n",
      "Epoch 166/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0434 - mse: 0.0434 - mae: 0.1623 - mape: 1.1954 - val_loss: 0.0765 - val_mse: 0.0765 - val_mae: 0.2221 - val_mape: 1.6258\n",
      "Epoch 167/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1691 - mape: 1.2462 - val_loss: 0.0526 - val_mse: 0.0526 - val_mae: 0.1759 - val_mape: 1.2914\n",
      "Epoch 168/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0455 - mse: 0.0455 - mae: 0.1633 - mape: 1.2061 - val_loss: 0.0550 - val_mse: 0.0550 - val_mae: 0.1810 - val_mape: 1.3254\n",
      "Epoch 169/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0445 - mse: 0.0445 - mae: 0.1628 - mape: 1.2011 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1793 - val_mape: 1.3150\n",
      "Epoch 170/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0451 - mse: 0.0451 - mae: 0.1644 - mape: 1.2115 - val_loss: 0.0567 - val_mse: 0.0567 - val_mae: 0.1810 - val_mape: 1.3363\n",
      "Epoch 171/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1685 - mape: 1.2427 - val_loss: 0.0532 - val_mse: 0.0532 - val_mae: 0.1755 - val_mape: 1.2894\n",
      "Epoch 172/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0461 - mse: 0.0461 - mae: 0.1664 - mape: 1.2264 - val_loss: 0.0766 - val_mse: 0.0766 - val_mae: 0.2117 - val_mape: 1.5688\n",
      "Epoch 173/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1737 - mape: 1.2830 - val_loss: 0.0665 - val_mse: 0.0665 - val_mae: 0.2025 - val_mape: 1.4737\n",
      "Epoch 174/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0443 - mse: 0.0443 - mae: 0.1627 - mape: 1.1948 - val_loss: 0.0555 - val_mse: 0.0555 - val_mae: 0.1797 - val_mape: 1.3253\n",
      "Epoch 175/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1673 - mape: 1.2306 - val_loss: 0.0854 - val_mse: 0.0854 - val_mae: 0.2380 - val_mape: 1.7386\n",
      "Epoch 176/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1664 - mape: 1.2278 - val_loss: 0.0600 - val_mse: 0.0600 - val_mae: 0.1925 - val_mape: 1.4073\n",
      "Epoch 177/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1717 - mape: 1.2661 - val_loss: 0.0579 - val_mse: 0.0579 - val_mae: 0.1870 - val_mape: 1.3684\n",
      "Epoch 178/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0429 - mse: 0.0429 - mae: 0.1599 - mape: 1.1785 - val_loss: 0.0743 - val_mse: 0.0743 - val_mae: 0.2084 - val_mape: 1.5471\n",
      "Epoch 179/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1680 - mape: 1.2406 - val_loss: 0.0531 - val_mse: 0.0531 - val_mae: 0.1728 - val_mape: 1.2751\n",
      "Epoch 180/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0429 - mse: 0.0429 - mae: 0.1601 - mape: 1.1798 - val_loss: 0.0539 - val_mse: 0.0539 - val_mae: 0.1783 - val_mape: 1.3110\n",
      "Epoch 181/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1678 - mape: 1.2348 - val_loss: 0.0582 - val_mse: 0.0582 - val_mae: 0.1871 - val_mape: 1.3655\n",
      "Epoch 182/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0452 - mse: 0.0452 - mae: 0.1645 - mape: 1.2130 - val_loss: 0.0587 - val_mse: 0.0587 - val_mae: 0.1869 - val_mape: 1.3820\n",
      "Epoch 183/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0444 - mse: 0.0444 - mae: 0.1625 - mape: 1.1995 - val_loss: 0.0545 - val_mse: 0.0545 - val_mae: 0.1799 - val_mape: 1.3202\n",
      "Epoch 184/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1682 - mape: 1.2373 - val_loss: 0.0569 - val_mse: 0.0569 - val_mae: 0.1812 - val_mape: 1.3324\n",
      "Epoch 185/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1677 - mape: 1.2358 - val_loss: 0.0542 - val_mse: 0.0542 - val_mae: 0.1768 - val_mape: 1.3053\n",
      "Epoch 186/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0456 - mse: 0.0456 - mae: 0.1650 - mape: 1.2158 - val_loss: 0.0530 - val_mse: 0.0530 - val_mae: 0.1734 - val_mape: 1.2769\n",
      "Epoch 187/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0446 - mse: 0.0446 - mae: 0.1637 - mape: 1.2087 - val_loss: 0.0529 - val_mse: 0.0529 - val_mae: 0.1757 - val_mape: 1.2900\n",
      "Epoch 188/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0443 - mse: 0.0443 - mae: 0.1636 - mape: 1.2094 - val_loss: 0.0742 - val_mse: 0.0742 - val_mae: 0.2214 - val_mape: 1.6319\n",
      "Epoch 189/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0444 - mse: 0.0444 - mae: 0.1642 - mape: 1.2134 - val_loss: 0.0563 - val_mse: 0.0563 - val_mae: 0.1788 - val_mape: 1.3175\n",
      "Epoch 190/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1680 - mape: 1.2371 - val_loss: 0.0540 - val_mse: 0.0540 - val_mae: 0.1757 - val_mape: 1.2920\n",
      "Epoch 191/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1671 - mape: 1.2291 - val_loss: 0.0533 - val_mse: 0.0533 - val_mae: 0.1768 - val_mape: 1.2988\n",
      "Epoch 192/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0430 - mse: 0.0430 - mae: 0.1611 - mape: 1.1895 - val_loss: 0.0641 - val_mse: 0.0641 - val_mae: 0.1922 - val_mape: 1.4173\n",
      "Epoch 193/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1658 - mape: 1.2212 - val_loss: 0.0581 - val_mse: 0.0581 - val_mae: 0.1824 - val_mape: 1.3494\n",
      "Epoch 194/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0416 - mae: 0.1582 - mape: 1.1673 - val_loss: 0.0672 - val_mse: 0.0672 - val_mae: 0.1974 - val_mape: 1.4547\n",
      "Epoch 195/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1578 - mape: 1.1631 - val_loss: 0.0543 - val_mse: 0.0543 - val_mae: 0.1788 - val_mape: 1.3145\n",
      "Epoch 196/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0438 - mse: 0.0438 - mae: 0.1610 - mape: 1.1863 - val_loss: 0.0528 - val_mse: 0.0528 - val_mae: 0.1754 - val_mape: 1.2908\n",
      "Epoch 197/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0431 - mse: 0.0431 - mae: 0.1606 - mape: 1.1828 - val_loss: 0.0629 - val_mse: 0.0629 - val_mae: 0.1904 - val_mape: 1.4038\n",
      "Epoch 198/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0433 - mse: 0.0433 - mae: 0.1608 - mape: 1.1843 - val_loss: 0.0583 - val_mse: 0.0583 - val_mae: 0.1874 - val_mape: 1.3817\n",
      "Epoch 199/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0452 - mse: 0.0452 - mae: 0.1639 - mape: 1.2064 - val_loss: 0.0548 - val_mse: 0.0548 - val_mae: 0.1788 - val_mape: 1.3197\n",
      "Epoch 200/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0424 - mse: 0.0424 - mae: 0.1575 - mape: 1.1649 - val_loss: 0.0565 - val_mse: 0.0565 - val_mae: 0.1814 - val_mape: 1.3322\n",
      "Epoch 201/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0432 - mse: 0.0432 - mae: 0.1610 - mape: 1.1843 - val_loss: 0.0706 - val_mse: 0.0706 - val_mae: 0.2121 - val_mape: 1.5492\n",
      "Epoch 202/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0451 - mse: 0.0451 - mae: 0.1645 - mape: 1.2135 - val_loss: 0.0586 - val_mse: 0.0586 - val_mae: 0.1834 - val_mape: 1.3535\n",
      "Epoch 203/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1662 - mape: 1.2242 - val_loss: 0.0626 - val_mse: 0.0626 - val_mae: 0.1915 - val_mape: 1.4192\n",
      "Epoch 204/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1676 - mape: 1.2362 - val_loss: 0.0550 - val_mse: 0.0550 - val_mae: 0.1806 - val_mape: 1.3316\n",
      "Epoch 205/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0416 - mse: 0.0416 - mae: 0.1580 - mape: 1.1681 - val_loss: 0.0669 - val_mse: 0.0669 - val_mae: 0.2037 - val_mape: 1.4825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0442 - mse: 0.0442 - mae: 0.1618 - mape: 1.1949 - val_loss: 0.0532 - val_mse: 0.0532 - val_mae: 0.1770 - val_mape: 1.3011\n",
      "Epoch 207/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0447 - mse: 0.0447 - mae: 0.1636 - mape: 1.2061 - val_loss: 0.0553 - val_mse: 0.0553 - val_mae: 0.1808 - val_mape: 1.3227\n",
      "Epoch 208/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0423 - mse: 0.0423 - mae: 0.1581 - mape: 1.1614 - val_loss: 0.0540 - val_mse: 0.0540 - val_mae: 0.1803 - val_mape: 1.3241\n",
      "Epoch 209/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0426 - mse: 0.0426 - mae: 0.1602 - mape: 1.1816 - val_loss: 0.0527 - val_mse: 0.0527 - val_mae: 0.1770 - val_mape: 1.2985\n",
      "Epoch 210/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0446 - mse: 0.0446 - mae: 0.1624 - mape: 1.1972 - val_loss: 0.0621 - val_mse: 0.0621 - val_mae: 0.1951 - val_mape: 1.4247\n",
      "Epoch 211/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0441 - mse: 0.0441 - mae: 0.1617 - mape: 1.1943 - val_loss: 0.0655 - val_mse: 0.0655 - val_mae: 0.2006 - val_mape: 1.4534\n",
      "Epoch 212/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0439 - mse: 0.0439 - mae: 0.1622 - mape: 1.1967 - val_loss: 0.0531 - val_mse: 0.0531 - val_mae: 0.1748 - val_mape: 1.2871\n",
      "Epoch 213/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0415 - mse: 0.0415 - mae: 0.1572 - mape: 1.1606 - val_loss: 0.0666 - val_mse: 0.0666 - val_mae: 0.2010 - val_mape: 1.4870\n",
      "Epoch 214/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0456 - mse: 0.0456 - mae: 0.1655 - mape: 1.2262 - val_loss: 0.0617 - val_mse: 0.0617 - val_mae: 0.1880 - val_mape: 1.3860\n",
      "Epoch 215/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1709 - mape: 1.2623 - val_loss: 0.0527 - val_mse: 0.0527 - val_mae: 0.1753 - val_mape: 1.2915\n",
      "Epoch 216/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1591 - mape: 1.1731 - val_loss: 0.0519 - val_mse: 0.0519 - val_mae: 0.1722 - val_mape: 1.2646\n",
      "Epoch 217/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1580 - mape: 1.1631 - val_loss: 0.0512 - val_mse: 0.0512 - val_mae: 0.1702 - val_mape: 1.2543\n",
      "Epoch 218/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1599 - mape: 1.1818 - val_loss: 0.0514 - val_mse: 0.0514 - val_mae: 0.1728 - val_mape: 1.2701\n",
      "Epoch 219/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0449 - mse: 0.0449 - mae: 0.1637 - mape: 1.2075 - val_loss: 0.0555 - val_mse: 0.0555 - val_mae: 0.1781 - val_mape: 1.3110\n",
      "Epoch 220/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0403 - mse: 0.0403 - mae: 0.1543 - mape: 1.1379 - val_loss: 0.0989 - val_mse: 0.0989 - val_mae: 0.2589 - val_mape: 1.8738\n",
      "Epoch 221/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0438 - mse: 0.0438 - mae: 0.1623 - mape: 1.1974 - val_loss: 0.0546 - val_mse: 0.0546 - val_mae: 0.1780 - val_mape: 1.3140\n",
      "Epoch 222/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0413 - mse: 0.0413 - mae: 0.1553 - mape: 1.1450 - val_loss: 0.0561 - val_mse: 0.0561 - val_mae: 0.1838 - val_mape: 1.3476\n",
      "Epoch 223/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0456 - mse: 0.0456 - mae: 0.1645 - mape: 1.2148 - val_loss: 0.0558 - val_mse: 0.0558 - val_mae: 0.1829 - val_mape: 1.3530\n",
      "Epoch 224/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1691 - mape: 1.2477 - val_loss: 0.0586 - val_mse: 0.0586 - val_mae: 0.1858 - val_mape: 1.3759\n",
      "Epoch 225/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0437 - mse: 0.0437 - mae: 0.1618 - mape: 1.1943 - val_loss: 0.0572 - val_mse: 0.0572 - val_mae: 0.1803 - val_mape: 1.3336\n",
      "Epoch 226/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0428 - mse: 0.0428 - mae: 0.1605 - mape: 1.1841 - val_loss: 0.0556 - val_mse: 0.0556 - val_mae: 0.1813 - val_mape: 1.3383\n",
      "Epoch 227/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0439 - mse: 0.0439 - mae: 0.1615 - mape: 1.1897 - val_loss: 0.0642 - val_mse: 0.0642 - val_mae: 0.2011 - val_mape: 1.4714\n",
      "Epoch 228/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0432 - mse: 0.0432 - mae: 0.1619 - mape: 1.1953 - val_loss: 0.0531 - val_mse: 0.0531 - val_mae: 0.1754 - val_mape: 1.2950\n",
      "Epoch 229/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0406 - mse: 0.0406 - mae: 0.1550 - mape: 1.1440 - val_loss: 0.0607 - val_mse: 0.0607 - val_mae: 0.1935 - val_mape: 1.4171\n",
      "Epoch 230/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0436 - mse: 0.0436 - mae: 0.1618 - mape: 1.1944 - val_loss: 0.0653 - val_mse: 0.0653 - val_mae: 0.2016 - val_mape: 1.4698\n",
      "Epoch 231/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1697 - mape: 1.2512 - val_loss: 0.0596 - val_mse: 0.0596 - val_mae: 0.1852 - val_mape: 1.3726\n",
      "Epoch 232/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0424 - mse: 0.0424 - mae: 0.1605 - mape: 1.1840 - val_loss: 0.0543 - val_mse: 0.0543 - val_mae: 0.1795 - val_mape: 1.3152\n",
      "Epoch 233/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0417 - mse: 0.0417 - mae: 0.1594 - mape: 1.1757 - val_loss: 0.0632 - val_mse: 0.0632 - val_mae: 0.1977 - val_mape: 1.4461\n",
      "Epoch 234/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0446 - mse: 0.0446 - mae: 0.1638 - mape: 1.2051 - val_loss: 0.0524 - val_mse: 0.0524 - val_mae: 0.1742 - val_mape: 1.2855\n",
      "Epoch 235/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0421 - mse: 0.0421 - mae: 0.1576 - mape: 1.1633 - val_loss: 0.0523 - val_mse: 0.0523 - val_mae: 0.1752 - val_mape: 1.2849\n",
      "Epoch 236/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0449 - mse: 0.0449 - mae: 0.1630 - mape: 1.2013 - val_loss: 0.0651 - val_mse: 0.0651 - val_mae: 0.2023 - val_mape: 1.4792\n",
      "Epoch 237/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0426 - mse: 0.0426 - mae: 0.1598 - mape: 1.1752 - val_loss: 0.0540 - val_mse: 0.0540 - val_mae: 0.1789 - val_mape: 1.3184\n",
      "Epoch 238/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0381 - mse: 0.0381 - mae: 0.1491 - mape: 1.1004 - val_loss: 0.0577 - val_mse: 0.0577 - val_mae: 0.1889 - val_mape: 1.3912\n",
      "Epoch 239/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1682 - mape: 1.2414 - val_loss: 0.0621 - val_mse: 0.0621 - val_mae: 0.1888 - val_mape: 1.4015\n",
      "Epoch 240/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0441 - mse: 0.0441 - mae: 0.1625 - mape: 1.1981 - val_loss: 0.0528 - val_mse: 0.0528 - val_mae: 0.1765 - val_mape: 1.2966\n",
      "Epoch 241/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0410 - mse: 0.0410 - mae: 0.1566 - mape: 1.1555 - val_loss: 0.0520 - val_mse: 0.0520 - val_mae: 0.1752 - val_mape: 1.2893\n",
      "Epoch 242/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0412 - mse: 0.0412 - mae: 0.1559 - mape: 1.1495 - val_loss: 0.0536 - val_mse: 0.0536 - val_mae: 0.1770 - val_mape: 1.3020\n",
      "Epoch 243/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0409 - mse: 0.0409 - mae: 0.1570 - mape: 1.1583 - val_loss: 0.0624 - val_mse: 0.0624 - val_mae: 0.1951 - val_mape: 1.4290\n",
      "Epoch 244/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0442 - mse: 0.0442 - mae: 0.1627 - mape: 1.2013 - val_loss: 0.0710 - val_mse: 0.0710 - val_mae: 0.2045 - val_mape: 1.5183\n",
      "Epoch 245/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0431 - mse: 0.0431 - mae: 0.1617 - mape: 1.1937 - val_loss: 0.0855 - val_mse: 0.0855 - val_mae: 0.2297 - val_mape: 1.7070\n",
      "Epoch 246/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0446 - mse: 0.0446 - mae: 0.1637 - mape: 1.2060 - val_loss: 0.0541 - val_mse: 0.0541 - val_mae: 0.1783 - val_mape: 1.3096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0412 - mse: 0.0412 - mae: 0.1582 - mape: 1.1670 - val_loss: 0.0539 - val_mse: 0.0539 - val_mae: 0.1756 - val_mape: 1.2993\n",
      "Epoch 248/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0408 - mse: 0.0408 - mae: 0.1570 - mape: 1.1599 - val_loss: 0.0532 - val_mse: 0.0532 - val_mae: 0.1749 - val_mape: 1.2909\n",
      "Epoch 249/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0388 - mse: 0.0388 - mae: 0.1517 - mape: 1.1208 - val_loss: 0.0568 - val_mse: 0.0568 - val_mae: 0.1841 - val_mape: 1.3581\n",
      "Epoch 250/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0454 - mse: 0.0454 - mae: 0.1650 - mape: 1.2192 - val_loss: 0.0620 - val_mse: 0.0620 - val_mae: 0.1890 - val_mape: 1.4007\n"
     ]
    }
   ],
   "source": [
    "history_field = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00115-22cc5132-ab6f-4acd-906c-c04d87c93b22",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 809,
    "execution_start": 1621689387965,
    "source_hash": "67fb9612",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.049, Test: 0.060\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 264,
       "width": 368
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_mse = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse[0], test_mse[0]))\n",
    "\n",
    "# plot loss during training\n",
    "plt.title('Loss / MSE (Mean Squared Error)')\n",
    "plt.plot(history_field.history['loss'], label='train')\n",
    "plt.plot(history_field.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00116-ef8d6161-5bbb-4b23-87e9-3dcf0874ef7c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 254,
    "execution_start": 1621689388785,
    "source_hash": "1920decf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squarred error (field): 0.0599018247340535\n",
      "Root mean squarred error (field): 0.24474849281262898\n",
      "Mean Absolute Error: 0.18758275235240393\n",
      "MAPE: 0.013931792322561807\n",
      "R squared:0.9679076212681311\n"
     ]
    }
   ],
   "source": [
    "y_pred_field = model.predict(X_test)\n",
    "mse_field = metrics.mean_squared_error(y_test, y_pred_field)\n",
    "rmse_field= np.sqrt(mean_squared_error(y_test, y_pred_field))\n",
    "mae_field = mean_absolute_error(y_test,y_pred_field)\n",
    "mape_field = mean_absolute_percentage_error(y_test,y_pred_field)\n",
    "r2_score_field = r2_score(y_test, y_pred_field)\n",
    "\n",
    "print(\"Mean squarred error (field): {}\".format(mse_field))\n",
    "print(\"Root mean squarred error (field): {}\".format(rmse_field))\n",
    "print(\"Mean Absolute Error: {}\".format(mae_field))\n",
    "print(\"MAPE: {}\".format(mape_field))\n",
    "print(\"R squared:{}\".format(r2_score_field))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00080-dab82bd4-d5b2-47f6-ad35-c808d9baa1d2",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 250\n"
     ]
    }
   ],
   "source": [
    "epochs_field = len(history_field.history[\"loss\"])\n",
    "print(\"Epochs\", epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00081-c45541fb-3945-4589-8c2a-5a1cb7269ea2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Hyperparameter optimization with RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00116-e3304350-6d8a-4729-87e1-b083c0a98454",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "As it can be noticed in the cell above, the model learns quickly how to tuned and adjust all the parameters in the NN. it's evident that there are not signs of underfitting or overfitting. The only insight we might have is that 250 epochs are more than enough.\n",
    "\n",
    "However, we decided to pursue our analysis by increasing the efficency of the NN by performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00118-97d4ce1d-daa3-4d43-abc3-824456e4fa37",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1621689478161,
    "source_hash": "d9c01bdb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_field(hp):\n",
    "    first_layers_neuron = hp.Choice(\"Number of neurons Input layer\", [128, 100, 80, 60, 40, 30, 10])\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.Dense(first_layers_neuron, input_dim = X_field.shape[1], activation = \"relu\"))\n",
    "    for i in range(hp.Int('num_layers', 1, 7)):                      #number of hidden layers\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=5,       #min number of neurons\n",
    "                                            max_value=128,     #max number of neurons\n",
    "                                            step=22),\n",
    "                               activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [0.01, 1e-3, 1e-4])),  #what should be the learning rate\n",
    "        loss='mse',\n",
    "        metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00120-8cdab654-1cae-4c59-b278-d5ca33f99417",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 324,
    "execution_start": 1621689479077,
    "source_hash": "c5b57f2f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project temp_2\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from temp_2\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_field = RandomSearch(\n",
    "    model_field,\n",
    "    objective='val_mse',\n",
    "    max_trials=3,\n",
    "    executions_per_trial=3,\n",
    "    directory='temp_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00121-0e4dadd1-af0b-4cd9-9c74-ec79a96df0d1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2664020,
    "execution_start": 1621689480402,
    "source_hash": "860a5264",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_field.search(X_train, y_train, epochs = 250, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00122-297dcd41-0e8c-4e62-9210-c2282d0230aa",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 11,
    "execution_start": 1621672596140,
    "source_hash": "b68d4cf1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of neurons Input layer': 40,\n",
       " 'num_layers': 5,\n",
       " 'units_0': 37,\n",
       " 'learning_rate': 0.001,\n",
       " 'units_1': 49,\n",
       " 'units_2': 115,\n",
       " 'units_3': 49,\n",
       " 'units_4': 5}"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner_field.get_best_hyperparameters()[0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00123-e25a01ed-afcc-41c9-86fb-080741995ef7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 467,
    "execution_start": 1621672608985,
    "source_hash": "246448eb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 37)                1517      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 49)                1862      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 115)               5750      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 49)                5684      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 250       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 16,829\n",
      "Trainable params: 16,829\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "tuner_field.get_best_models()[0].summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00088-282d1dfd-c9c5-4ed4-b47d-43c278dc5a88",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### NN without EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00089-010f43b3-3929-4733-bd84-c12d8e7843d8",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#Since now we are predicting a single continuous value, the output layer will only have 1 node.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim = X_field.shape[1], activation = \"relu\"))\n",
    "model.add(Dense(37, activation = \"relu\"))         #first hidden layer\n",
    "model.add(Dense(49, activation = \"relu\"))        #second hidden layer\n",
    "model.add(Dense(115, activation = \"relu\"))        \n",
    "model.add(Dense(49, activation = \"relu\"))        \n",
    "model.add(Dense(5, activation = \"relu\"))        \n",
    "\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1, activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00090-642f7391-45c0-411e-812f-52eab43d58a9",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 40.0968 - mse: 40.0968 - mae: 4.0480 - mape: 29.8689 - val_loss: 0.3745 - val_mse: 0.3745 - val_mae: 0.4887 - val_mape: 3.6126\n",
      "Epoch 2/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.3233 - mse: 0.3233 - mae: 0.4479 - mape: 3.3290 - val_loss: 0.2528 - val_mse: 0.2528 - val_mae: 0.3996 - val_mape: 2.9765\n",
      "Epoch 3/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.2089 - mse: 0.2089 - mae: 0.3624 - mape: 2.6908 - val_loss: 0.2511 - val_mse: 0.2511 - val_mae: 0.3983 - val_mape: 2.9690\n",
      "Epoch 4/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1793 - mse: 0.1793 - mae: 0.3347 - mape: 2.4833 - val_loss: 0.1553 - val_mse: 0.1553 - val_mae: 0.3125 - val_mape: 2.3145\n",
      "Epoch 5/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1524 - mse: 0.1524 - mae: 0.3102 - mape: 2.2910 - val_loss: 0.2153 - val_mse: 0.2153 - val_mae: 0.3783 - val_mape: 2.7478\n",
      "Epoch 6/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1450 - mse: 0.1450 - mae: 0.3000 - mape: 2.2191 - val_loss: 0.1221 - val_mse: 0.1221 - val_mae: 0.2768 - val_mape: 2.0392\n",
      "Epoch 7/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1239 - mse: 0.1239 - mae: 0.2770 - mape: 2.0460 - val_loss: 0.1606 - val_mse: 0.1606 - val_mae: 0.3185 - val_mape: 2.3722\n",
      "Epoch 8/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1120 - mse: 0.1120 - mae: 0.2637 - mape: 1.9496 - val_loss: 0.1013 - val_mse: 0.1013 - val_mae: 0.2488 - val_mape: 1.8369\n",
      "Epoch 9/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1088 - mse: 0.1088 - mae: 0.2594 - mape: 1.9145 - val_loss: 0.0968 - val_mse: 0.0968 - val_mae: 0.2412 - val_mape: 1.7772\n",
      "Epoch 10/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1063 - mse: 0.1063 - mae: 0.2554 - mape: 1.8819 - val_loss: 0.1296 - val_mse: 0.1296 - val_mae: 0.2819 - val_mape: 2.0942\n",
      "Epoch 11/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1094 - mse: 0.1094 - mae: 0.2609 - mape: 1.9249 - val_loss: 0.1162 - val_mse: 0.1162 - val_mae: 0.2673 - val_mape: 1.9396\n",
      "Epoch 12/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1084 - mse: 0.1084 - mae: 0.2589 - mape: 1.9095 - val_loss: 0.0888 - val_mse: 0.0888 - val_mae: 0.2315 - val_mape: 1.7073\n",
      "Epoch 13/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1037 - mse: 0.1037 - mae: 0.2533 - mape: 1.8686 - val_loss: 0.0927 - val_mse: 0.0927 - val_mae: 0.2377 - val_mape: 1.7615\n",
      "Epoch 14/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0953 - mse: 0.0953 - mae: 0.2397 - mape: 1.7655 - val_loss: 0.0890 - val_mse: 0.0890 - val_mae: 0.2323 - val_mape: 1.7155\n",
      "Epoch 15/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0886 - mse: 0.0886 - mae: 0.2315 - mape: 1.7080 - val_loss: 0.0842 - val_mse: 0.0842 - val_mae: 0.2277 - val_mape: 1.6677\n",
      "Epoch 16/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0960 - mse: 0.0960 - mae: 0.2438 - mape: 1.7976 - val_loss: 0.0799 - val_mse: 0.0799 - val_mae: 0.2205 - val_mape: 1.6131\n",
      "Epoch 17/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0831 - mse: 0.0831 - mae: 0.2260 - mape: 1.6656 - val_loss: 0.0896 - val_mse: 0.0896 - val_mae: 0.2383 - val_mape: 1.7428\n",
      "Epoch 18/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0854 - mse: 0.0854 - mae: 0.2286 - mape: 1.6847 - val_loss: 0.1412 - val_mse: 0.1412 - val_mae: 0.3086 - val_mape: 2.2390\n",
      "Epoch 19/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.1030 - mse: 0.1030 - mae: 0.2526 - mape: 1.8589 - val_loss: 0.0933 - val_mse: 0.0933 - val_mae: 0.2398 - val_mape: 1.7777\n",
      "Epoch 20/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0959 - mse: 0.0959 - mae: 0.2415 - mape: 1.7827 - val_loss: 0.0745 - val_mse: 0.0745 - val_mae: 0.2107 - val_mape: 1.5519\n",
      "Epoch 21/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0816 - mse: 0.0816 - mae: 0.2209 - mape: 1.6261 - val_loss: 0.0794 - val_mse: 0.0794 - val_mae: 0.2189 - val_mape: 1.6171\n",
      "Epoch 22/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0775 - mse: 0.0775 - mae: 0.2158 - mape: 1.5910 - val_loss: 0.0846 - val_mse: 0.0846 - val_mae: 0.2285 - val_mape: 1.6670\n",
      "Epoch 23/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0818 - mse: 0.0818 - mae: 0.2239 - mape: 1.6469 - val_loss: 0.0686 - val_mse: 0.0686 - val_mae: 0.2022 - val_mape: 1.4855\n",
      "Epoch 24/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0853 - mse: 0.0853 - mae: 0.2280 - mape: 1.6795 - val_loss: 0.1209 - val_mse: 0.1209 - val_mae: 0.2880 - val_mape: 2.0926\n",
      "Epoch 25/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0903 - mse: 0.0903 - mae: 0.2367 - mape: 1.7439 - val_loss: 0.0841 - val_mse: 0.0841 - val_mae: 0.2277 - val_mape: 1.6540\n",
      "Epoch 26/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0987 - mse: 0.0987 - mae: 0.2487 - mape: 1.8306 - val_loss: 0.0962 - val_mse: 0.0962 - val_mae: 0.2413 - val_mape: 1.7842\n",
      "Epoch 27/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0724 - mse: 0.0724 - mae: 0.2095 - mape: 1.5479 - val_loss: 0.0863 - val_mse: 0.0863 - val_mae: 0.2280 - val_mape: 1.6876\n",
      "Epoch 28/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0746 - mse: 0.0746 - mae: 0.2122 - mape: 1.5609 - val_loss: 0.0968 - val_mse: 0.0968 - val_mae: 0.2533 - val_mape: 1.8492\n",
      "Epoch 29/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0860 - mse: 0.0860 - mae: 0.2297 - mape: 1.6890 - val_loss: 0.0676 - val_mse: 0.0676 - val_mae: 0.1997 - val_mape: 1.4680\n",
      "Epoch 30/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0743 - mse: 0.0743 - mae: 0.2127 - mape: 1.5678 - val_loss: 0.0675 - val_mse: 0.0675 - val_mae: 0.2008 - val_mape: 1.4764\n",
      "Epoch 31/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0781 - mse: 0.0781 - mae: 0.2184 - mape: 1.6108 - val_loss: 0.0811 - val_mse: 0.0811 - val_mae: 0.2211 - val_mape: 1.6315\n",
      "Epoch 32/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0760 - mse: 0.0760 - mae: 0.2145 - mape: 1.5811 - val_loss: 0.0885 - val_mse: 0.0885 - val_mae: 0.2278 - val_mape: 1.6821\n",
      "Epoch 33/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0734 - mse: 0.0734 - mae: 0.2116 - mape: 1.5599 - val_loss: 0.0776 - val_mse: 0.0776 - val_mae: 0.2127 - val_mape: 1.5714\n",
      "Epoch 34/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0782 - mse: 0.0782 - mae: 0.2192 - mape: 1.6104 - val_loss: 0.0856 - val_mse: 0.0856 - val_mae: 0.2320 - val_mape: 1.6853\n",
      "Epoch 35/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0749 - mse: 0.0749 - mae: 0.2142 - mape: 1.5780 - val_loss: 0.0820 - val_mse: 0.0820 - val_mae: 0.2284 - val_mape: 1.6580\n",
      "Epoch 36/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0711 - mse: 0.0711 - mae: 0.2070 - mape: 1.5271 - val_loss: 0.0736 - val_mse: 0.0736 - val_mae: 0.2127 - val_mape: 1.5687\n",
      "Epoch 37/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0688 - mse: 0.0688 - mae: 0.2051 - mape: 1.5073 - val_loss: 0.0707 - val_mse: 0.0707 - val_mae: 0.2096 - val_mape: 1.5339\n",
      "Epoch 38/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0698 - mse: 0.0698 - mae: 0.2040 - mape: 1.5017 - val_loss: 0.0696 - val_mse: 0.0696 - val_mae: 0.2053 - val_mape: 1.4988\n",
      "Epoch 39/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0729 - mse: 0.0729 - mae: 0.2087 - mape: 1.5396 - val_loss: 0.1166 - val_mse: 0.1166 - val_mae: 0.2731 - val_mape: 2.0240\n",
      "Epoch 40/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0816 - mse: 0.0816 - mae: 0.2217 - mape: 1.6302 - val_loss: 0.0779 - val_mse: 0.0779 - val_mae: 0.2225 - val_mape: 1.6235\n",
      "Epoch 41/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0677 - mse: 0.0677 - mae: 0.2010 - mape: 1.4793 - val_loss: 0.0759 - val_mse: 0.0759 - val_mae: 0.2106 - val_mape: 1.5569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0702 - mse: 0.0702 - mae: 0.2075 - mape: 1.5269 - val_loss: 0.0641 - val_mse: 0.0641 - val_mae: 0.1962 - val_mape: 1.4376\n",
      "Epoch 43/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0700 - mse: 0.0700 - mae: 0.2067 - mape: 1.5212 - val_loss: 0.0606 - val_mse: 0.0606 - val_mae: 0.1895 - val_mape: 1.3894\n",
      "Epoch 44/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0662 - mse: 0.0662 - mae: 0.2002 - mape: 1.4757 - val_loss: 0.0662 - val_mse: 0.0662 - val_mae: 0.1985 - val_mape: 1.4599\n",
      "Epoch 45/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0694 - mse: 0.0694 - mae: 0.2057 - mape: 1.5158 - val_loss: 0.0649 - val_mse: 0.0649 - val_mae: 0.1974 - val_mape: 1.4491\n",
      "Epoch 46/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0620 - mse: 0.0620 - mae: 0.1936 - mape: 1.4251 - val_loss: 0.0712 - val_mse: 0.0712 - val_mae: 0.2115 - val_mape: 1.5466\n",
      "Epoch 47/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0763 - mse: 0.0763 - mae: 0.2175 - mape: 1.5975 - val_loss: 0.0688 - val_mse: 0.0688 - val_mae: 0.2038 - val_mape: 1.4890\n",
      "Epoch 48/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0630 - mse: 0.0630 - mae: 0.1970 - mape: 1.4473 - val_loss: 0.1664 - val_mse: 0.1664 - val_mae: 0.3375 - val_mape: 2.5000\n",
      "Epoch 49/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0739 - mse: 0.0739 - mae: 0.2120 - mape: 1.5580 - val_loss: 0.0841 - val_mse: 0.0841 - val_mae: 0.2231 - val_mape: 1.6513\n",
      "Epoch 50/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0666 - mse: 0.0666 - mae: 0.2004 - mape: 1.4769 - val_loss: 0.0802 - val_mse: 0.0802 - val_mae: 0.2156 - val_mape: 1.5896\n",
      "Epoch 51/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0727 - mse: 0.0727 - mae: 0.2116 - mape: 1.5562 - val_loss: 0.0613 - val_mse: 0.0613 - val_mae: 0.1897 - val_mape: 1.3927\n",
      "Epoch 52/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0726 - mse: 0.0726 - mae: 0.2112 - mape: 1.5549 - val_loss: 0.1071 - val_mse: 0.1071 - val_mae: 0.2700 - val_mape: 1.9629\n",
      "Epoch 53/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0664 - mse: 0.0664 - mae: 0.1995 - mape: 1.4702 - val_loss: 0.0672 - val_mse: 0.0672 - val_mae: 0.2011 - val_mape: 1.4692\n",
      "Epoch 54/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0645 - mse: 0.0645 - mae: 0.1961 - mape: 1.4426 - val_loss: 0.0783 - val_mse: 0.0783 - val_mae: 0.2236 - val_mape: 1.6280\n",
      "Epoch 55/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0694 - mse: 0.0694 - mae: 0.2056 - mape: 1.5152 - val_loss: 0.0637 - val_mse: 0.0637 - val_mae: 0.1957 - val_mape: 1.4329\n",
      "Epoch 56/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0647 - mse: 0.0647 - mae: 0.1965 - mape: 1.4469 - val_loss: 0.0895 - val_mse: 0.0895 - val_mae: 0.2413 - val_mape: 1.7515\n",
      "Epoch 57/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0664 - mse: 0.0664 - mae: 0.1998 - mape: 1.4660 - val_loss: 0.0753 - val_mse: 0.0753 - val_mae: 0.2154 - val_mape: 1.5702\n",
      "Epoch 58/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0640 - mse: 0.0640 - mae: 0.1963 - mape: 1.4473 - val_loss: 0.0771 - val_mse: 0.0771 - val_mae: 0.2216 - val_mape: 1.6131\n",
      "Epoch 59/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0728 - mse: 0.0728 - mae: 0.2133 - mape: 1.5713 - val_loss: 0.0624 - val_mse: 0.0624 - val_mae: 0.1922 - val_mape: 1.4153\n",
      "Epoch 60/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0598 - mse: 0.0598 - mae: 0.1916 - mape: 1.4115 - val_loss: 0.0777 - val_mse: 0.0777 - val_mae: 0.2261 - val_mape: 1.6555\n",
      "Epoch 61/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0701 - mse: 0.0701 - mae: 0.2060 - mape: 1.5162 - val_loss: 0.0614 - val_mse: 0.0614 - val_mae: 0.1915 - val_mape: 1.4070\n",
      "Epoch 62/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0590 - mse: 0.0590 - mae: 0.1885 - mape: 1.3878 - val_loss: 0.0754 - val_mse: 0.0754 - val_mae: 0.2122 - val_mape: 1.5692\n",
      "Epoch 63/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0628 - mse: 0.0628 - mae: 0.1941 - mape: 1.4256 - val_loss: 0.0725 - val_mse: 0.0725 - val_mae: 0.2129 - val_mape: 1.5597\n",
      "Epoch 64/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0591 - mse: 0.0591 - mae: 0.1883 - mape: 1.3844 - val_loss: 0.0726 - val_mse: 0.0726 - val_mae: 0.2110 - val_mape: 1.5383\n",
      "Epoch 65/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0657 - mse: 0.0657 - mae: 0.1984 - mape: 1.4633 - val_loss: 0.0580 - val_mse: 0.0580 - val_mae: 0.1839 - val_mape: 1.3512\n",
      "Epoch 66/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0683 - mse: 0.0683 - mae: 0.2034 - mape: 1.4953 - val_loss: 0.0594 - val_mse: 0.0594 - val_mae: 0.1873 - val_mape: 1.3706\n",
      "Epoch 67/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0607 - mse: 0.0607 - mae: 0.1901 - mape: 1.4001 - val_loss: 0.0978 - val_mse: 0.0978 - val_mae: 0.2561 - val_mape: 1.8643\n",
      "Epoch 68/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0579 - mse: 0.0579 - mae: 0.1871 - mape: 1.3762 - val_loss: 0.0735 - val_mse: 0.0735 - val_mae: 0.2084 - val_mape: 1.5311\n",
      "Epoch 69/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0648 - mse: 0.0648 - mae: 0.1975 - mape: 1.4566 - val_loss: 0.0724 - val_mse: 0.0724 - val_mae: 0.2045 - val_mape: 1.5083\n",
      "Epoch 70/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0659 - mse: 0.0659 - mae: 0.1996 - mape: 1.4679 - val_loss: 0.0697 - val_mse: 0.0697 - val_mae: 0.2006 - val_mape: 1.4817\n",
      "Epoch 71/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0660 - mse: 0.0660 - mae: 0.2003 - mape: 1.4741 - val_loss: 0.0728 - val_mse: 0.0728 - val_mae: 0.2133 - val_mape: 1.5514\n",
      "Epoch 72/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0647 - mse: 0.0647 - mae: 0.2001 - mape: 1.4677 - val_loss: 0.0736 - val_mse: 0.0736 - val_mae: 0.2143 - val_mape: 1.5689\n",
      "Epoch 73/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0662 - mse: 0.0662 - mae: 0.2002 - mape: 1.4745 - val_loss: 0.0618 - val_mse: 0.0618 - val_mae: 0.1924 - val_mape: 1.4092\n",
      "Epoch 74/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0609 - mse: 0.0609 - mae: 0.1926 - mape: 1.4160 - val_loss: 0.0611 - val_mse: 0.0611 - val_mae: 0.1872 - val_mape: 1.3761\n",
      "Epoch 75/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0616 - mse: 0.0616 - mae: 0.1947 - mape: 1.4330 - val_loss: 0.1415 - val_mse: 0.1415 - val_mae: 0.3226 - val_mape: 2.3457\n",
      "Epoch 76/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0762 - mse: 0.0762 - mae: 0.2177 - mape: 1.5999 - val_loss: 0.0639 - val_mse: 0.0639 - val_mae: 0.1967 - val_mape: 1.4323\n",
      "Epoch 77/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0577 - mse: 0.0577 - mae: 0.1873 - mape: 1.3810 - val_loss: 0.0565 - val_mse: 0.0565 - val_mae: 0.1805 - val_mape: 1.3246\n",
      "Epoch 78/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0628 - mse: 0.0628 - mae: 0.1953 - mape: 1.4382 - val_loss: 0.0721 - val_mse: 0.0721 - val_mae: 0.2055 - val_mape: 1.5174\n",
      "Epoch 79/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0615 - mse: 0.0615 - mae: 0.1924 - mape: 1.4173 - val_loss: 0.0637 - val_mse: 0.0637 - val_mae: 0.1978 - val_mape: 1.4405\n",
      "Epoch 80/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0663 - mse: 0.0663 - mae: 0.1997 - mape: 1.4696 - val_loss: 0.0692 - val_mse: 0.0692 - val_mae: 0.2055 - val_mape: 1.4923\n",
      "Epoch 81/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0596 - mse: 0.0596 - mae: 0.1900 - mape: 1.4002 - val_loss: 0.0604 - val_mse: 0.0604 - val_mae: 0.1874 - val_mape: 1.3798\n",
      "Epoch 82/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0622 - mse: 0.0622 - mae: 0.1939 - mape: 1.4275 - val_loss: 0.0971 - val_mse: 0.0971 - val_mae: 0.2452 - val_mape: 1.8245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0558 - mae: 0.1846 - mape: 1.3585 - val_loss: 0.1064 - val_mse: 0.1064 - val_mae: 0.2696 - val_mape: 1.9610\n",
      "Epoch 84/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0590 - mse: 0.0590 - mae: 0.1879 - mape: 1.3791 - val_loss: 0.0575 - val_mse: 0.0575 - val_mae: 0.1840 - val_mape: 1.3503\n",
      "Epoch 85/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0569 - mse: 0.0569 - mae: 0.1857 - mape: 1.3676 - val_loss: 0.0575 - val_mse: 0.0575 - val_mae: 0.1837 - val_mape: 1.3495\n",
      "Epoch 86/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0578 - mse: 0.0578 - mae: 0.1864 - mape: 1.3723 - val_loss: 0.0802 - val_mse: 0.0802 - val_mae: 0.2189 - val_mape: 1.6218\n",
      "Epoch 87/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0583 - mse: 0.0583 - mae: 0.1872 - mape: 1.3752 - val_loss: 0.0627 - val_mse: 0.0627 - val_mae: 0.1909 - val_mape: 1.4066\n",
      "Epoch 88/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0569 - mse: 0.0569 - mae: 0.1842 - mape: 1.3532 - val_loss: 0.0593 - val_mse: 0.0593 - val_mae: 0.1882 - val_mape: 1.3800\n",
      "Epoch 89/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0670 - mse: 0.0670 - mae: 0.2030 - mape: 1.4940 - val_loss: 0.0590 - val_mse: 0.0590 - val_mae: 0.1869 - val_mape: 1.3625\n",
      "Epoch 90/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0616 - mse: 0.0616 - mae: 0.1936 - mape: 1.4249 - val_loss: 0.0825 - val_mse: 0.0825 - val_mae: 0.2337 - val_mape: 1.7081\n",
      "Epoch 91/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0572 - mse: 0.0572 - mae: 0.1862 - mape: 1.3688 - val_loss: 0.0587 - val_mse: 0.0587 - val_mae: 0.1854 - val_mape: 1.3644\n",
      "Epoch 92/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0553 - mse: 0.0553 - mae: 0.1835 - mape: 1.3496 - val_loss: 0.0805 - val_mse: 0.0805 - val_mae: 0.2202 - val_mape: 1.6373\n",
      "Epoch 93/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0535 - mse: 0.0535 - mae: 0.1799 - mape: 1.3265 - val_loss: 0.0729 - val_mse: 0.0729 - val_mae: 0.2062 - val_mape: 1.5236\n",
      "Epoch 94/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0595 - mse: 0.0595 - mae: 0.1888 - mape: 1.3895 - val_loss: 0.0609 - val_mse: 0.0609 - val_mae: 0.1912 - val_mape: 1.3973\n",
      "Epoch 95/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0595 - mse: 0.0595 - mae: 0.1905 - mape: 1.4034 - val_loss: 0.0709 - val_mse: 0.0709 - val_mae: 0.2137 - val_mape: 1.5608\n",
      "Epoch 96/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0553 - mse: 0.0553 - mae: 0.1833 - mape: 1.3484 - val_loss: 0.0627 - val_mse: 0.0627 - val_mae: 0.1965 - val_mape: 1.4345\n",
      "Epoch 97/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0553 - mse: 0.0553 - mae: 0.1826 - mape: 1.3426 - val_loss: 0.0581 - val_mse: 0.0581 - val_mae: 0.1848 - val_mape: 1.3538\n",
      "Epoch 98/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0558 - mse: 0.0558 - mae: 0.1829 - mape: 1.3415 - val_loss: 0.0835 - val_mse: 0.0835 - val_mae: 0.2317 - val_mape: 1.6793\n",
      "Epoch 99/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0623 - mse: 0.0623 - mae: 0.1918 - mape: 1.4099 - val_loss: 0.0577 - val_mse: 0.0577 - val_mae: 0.1829 - val_mape: 1.3428\n",
      "Epoch 100/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0589 - mse: 0.0589 - mae: 0.1905 - mape: 1.4025 - val_loss: 0.0887 - val_mse: 0.0887 - val_mae: 0.2404 - val_mape: 1.7460\n",
      "Epoch 101/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0571 - mse: 0.0571 - mae: 0.1846 - mape: 1.3550 - val_loss: 0.0720 - val_mse: 0.0720 - val_mae: 0.2042 - val_mape: 1.5074\n",
      "Epoch 102/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0610 - mse: 0.0610 - mae: 0.1936 - mape: 1.4233 - val_loss: 0.0556 - val_mse: 0.0556 - val_mae: 0.1796 - val_mape: 1.3183\n",
      "Epoch 103/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0593 - mse: 0.0593 - mae: 0.1880 - mape: 1.3830 - val_loss: 0.0584 - val_mse: 0.0584 - val_mae: 0.1843 - val_mape: 1.3538\n",
      "Epoch 104/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.1771 - mape: 1.3056 - val_loss: 0.0614 - val_mse: 0.0614 - val_mae: 0.1929 - val_mape: 1.4123\n",
      "Epoch 105/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0556 - mse: 0.0556 - mae: 0.1833 - mape: 1.3455 - val_loss: 0.0591 - val_mse: 0.0591 - val_mae: 0.1853 - val_mape: 1.3641\n",
      "Epoch 106/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0569 - mse: 0.0569 - mae: 0.1839 - mape: 1.3541 - val_loss: 0.0597 - val_mse: 0.0597 - val_mae: 0.1894 - val_mape: 1.3846\n",
      "Epoch 107/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0562 - mse: 0.0562 - mae: 0.1843 - mape: 1.3532 - val_loss: 0.0582 - val_mse: 0.0582 - val_mae: 0.1833 - val_mape: 1.3495\n",
      "Epoch 108/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.1758 - mape: 1.2939 - val_loss: 0.0830 - val_mse: 0.0830 - val_mae: 0.2331 - val_mape: 1.7002\n",
      "Epoch 109/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0579 - mse: 0.0579 - mae: 0.1878 - mape: 1.3819 - val_loss: 0.0897 - val_mse: 0.0897 - val_mae: 0.2329 - val_mape: 1.7230\n",
      "Epoch 110/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0640 - mse: 0.0640 - mae: 0.1947 - mape: 1.4293 - val_loss: 0.0661 - val_mse: 0.0661 - val_mae: 0.1945 - val_mape: 1.4365\n",
      "Epoch 111/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0586 - mse: 0.0586 - mae: 0.1882 - mape: 1.3863 - val_loss: 0.0577 - val_mse: 0.0577 - val_mae: 0.1850 - val_mape: 1.3561\n",
      "Epoch 112/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0539 - mse: 0.0539 - mae: 0.1808 - mape: 1.3319 - val_loss: 0.0686 - val_mse: 0.0686 - val_mae: 0.1998 - val_mape: 1.4803\n",
      "Epoch 113/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0550 - mse: 0.0550 - mae: 0.1820 - mape: 1.3420 - val_loss: 0.0627 - val_mse: 0.0627 - val_mae: 0.1962 - val_mape: 1.4326\n",
      "Epoch 114/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0587 - mse: 0.0587 - mae: 0.1882 - mape: 1.3847 - val_loss: 0.0576 - val_mse: 0.0576 - val_mae: 0.1849 - val_mape: 1.3547\n",
      "Epoch 115/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1744 - mape: 1.2838 - val_loss: 0.0817 - val_mse: 0.0817 - val_mae: 0.2194 - val_mape: 1.6252\n",
      "Epoch 116/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0567 - mse: 0.0567 - mae: 0.1859 - mape: 1.3701 - val_loss: 0.0558 - val_mse: 0.0558 - val_mae: 0.1791 - val_mape: 1.3175\n",
      "Epoch 117/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0557 - mse: 0.0557 - mae: 0.1835 - mape: 1.3525 - val_loss: 0.1014 - val_mse: 0.1014 - val_mae: 0.2506 - val_mape: 1.8553\n",
      "Epoch 118/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0584 - mse: 0.0584 - mae: 0.1891 - mape: 1.3958 - val_loss: 0.0559 - val_mse: 0.0559 - val_mae: 0.1820 - val_mape: 1.3350\n",
      "Epoch 119/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.1787 - mape: 1.3152 - val_loss: 0.0608 - val_mse: 0.0608 - val_mae: 0.1887 - val_mape: 1.3909\n",
      "Epoch 120/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1764 - mape: 1.2959 - val_loss: 0.0747 - val_mse: 0.0747 - val_mae: 0.2183 - val_mape: 1.5938\n",
      "Epoch 121/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.1776 - mape: 1.3066 - val_loss: 0.0638 - val_mse: 0.0638 - val_mae: 0.1915 - val_mape: 1.4115\n",
      "Epoch 122/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0527 - mse: 0.0527 - mae: 0.1789 - mape: 1.3126 - val_loss: 0.0695 - val_mse: 0.0695 - val_mae: 0.2082 - val_mape: 1.5176\n",
      "Epoch 123/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0570 - mse: 0.0570 - mae: 0.1861 - mape: 1.3654 - val_loss: 0.0661 - val_mse: 0.0661 - val_mae: 0.1935 - val_mape: 1.4285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0574 - mse: 0.0574 - mae: 0.1863 - mape: 1.3679 - val_loss: 0.0558 - val_mse: 0.0558 - val_mae: 0.1813 - val_mape: 1.3302\n",
      "Epoch 125/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0525 - mse: 0.0525 - mae: 0.1779 - mape: 1.3065 - val_loss: 0.0593 - val_mse: 0.0593 - val_mae: 0.1855 - val_mape: 1.3664\n",
      "Epoch 126/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0507 - mse: 0.0507 - mae: 0.1754 - mape: 1.2905 - val_loss: 0.0720 - val_mse: 0.0720 - val_mae: 0.2130 - val_mape: 1.5531\n",
      "Epoch 127/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0537 - mse: 0.0537 - mae: 0.1805 - mape: 1.3267 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2384 - val_mape: 1.7359\n",
      "Epoch 128/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0528 - mse: 0.0528 - mae: 0.1788 - mape: 1.3146 - val_loss: 0.0612 - val_mse: 0.0612 - val_mae: 0.1880 - val_mape: 1.3887\n",
      "Epoch 129/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0522 - mse: 0.0522 - mae: 0.1774 - mape: 1.3050 - val_loss: 0.0581 - val_mse: 0.0581 - val_mae: 0.1875 - val_mape: 1.3707\n",
      "Epoch 130/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0554 - mse: 0.0554 - mae: 0.1817 - mape: 1.3362 - val_loss: 0.0626 - val_mse: 0.0626 - val_mae: 0.1935 - val_mape: 1.4161\n",
      "Epoch 131/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1718 - mape: 1.2649 - val_loss: 0.0616 - val_mse: 0.0616 - val_mae: 0.1890 - val_mape: 1.3938\n",
      "Epoch 132/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0531 - mse: 0.0531 - mae: 0.1797 - mape: 1.3224 - val_loss: 0.0564 - val_mse: 0.0564 - val_mae: 0.1823 - val_mape: 1.3385\n",
      "Epoch 133/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0589 - mse: 0.0589 - mae: 0.1882 - mape: 1.3827 - val_loss: 0.0714 - val_mse: 0.0714 - val_mae: 0.2016 - val_mape: 1.4918\n",
      "Epoch 134/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.1771 - mape: 1.3014 - val_loss: 0.0609 - val_mse: 0.0609 - val_mae: 0.1883 - val_mape: 1.3916\n",
      "Epoch 135/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1704 - mape: 1.2545 - val_loss: 0.0537 - val_mse: 0.0537 - val_mae: 0.1761 - val_mape: 1.2918\n",
      "Epoch 136/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1723 - mape: 1.2683 - val_loss: 0.0910 - val_mse: 0.0910 - val_mae: 0.2486 - val_mape: 1.8100\n",
      "Epoch 137/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0562 - mse: 0.0562 - mae: 0.1848 - mape: 1.3598 - val_loss: 0.0695 - val_mse: 0.0695 - val_mae: 0.1983 - val_mape: 1.4625\n",
      "Epoch 138/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.1774 - mape: 1.3043 - val_loss: 0.0696 - val_mse: 0.0696 - val_mae: 0.1985 - val_mape: 1.4660\n",
      "Epoch 139/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0539 - mse: 0.0539 - mae: 0.1799 - mape: 1.3230 - val_loss: 0.0585 - val_mse: 0.0585 - val_mae: 0.1866 - val_mape: 1.3625\n",
      "Epoch 140/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1702 - mape: 1.2518 - val_loss: 0.0625 - val_mse: 0.0625 - val_mae: 0.1978 - val_mape: 1.4459\n",
      "Epoch 141/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0529 - mse: 0.0529 - mae: 0.1794 - mape: 1.3204 - val_loss: 0.0559 - val_mse: 0.0559 - val_mae: 0.1794 - val_mape: 1.3183\n",
      "Epoch 142/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0504 - mse: 0.0504 - mae: 0.1737 - mape: 1.2798 - val_loss: 0.0673 - val_mse: 0.0673 - val_mae: 0.1957 - val_mape: 1.4459\n",
      "Epoch 143/250\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.0536 - mse: 0.0536 - mae: 0.1796 - mape: 1.3227 - val_loss: 0.0674 - val_mse: 0.0674 - val_mae: 0.1959 - val_mape: 1.4442\n",
      "Epoch 144/250\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.1769 - mape: 1.3027 - val_loss: 0.0559 - val_mse: 0.0559 - val_mae: 0.1821 - val_mape: 1.3357\n",
      "Epoch 145/250\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.1763 - mape: 1.2989 - val_loss: 0.0949 - val_mse: 0.0949 - val_mae: 0.2385 - val_mape: 1.7641\n",
      "Epoch 146/250\n",
      "278/278 [==============================] - 1s 4ms/step - loss: 0.0541 - mse: 0.0541 - mae: 0.1818 - mape: 1.3322 - val_loss: 0.0698 - val_mse: 0.0698 - val_mae: 0.2005 - val_mape: 1.4813\n",
      "Epoch 147/250\n",
      "278/278 [==============================] - 1s 5ms/step - loss: 0.0542 - mse: 0.0542 - mae: 0.1823 - mape: 1.3426 - val_loss: 0.0950 - val_mse: 0.0950 - val_mae: 0.2390 - val_mape: 1.7679\n",
      "Epoch 148/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0600 - mse: 0.0600 - mae: 0.1897 - mape: 1.3952 - val_loss: 0.0742 - val_mse: 0.0742 - val_mae: 0.2174 - val_mape: 1.5902\n",
      "Epoch 149/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0553 - mse: 0.0553 - mae: 0.1846 - mape: 1.3591 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1786 - val_mape: 1.3127\n",
      "Epoch 150/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0543 - mse: 0.0543 - mae: 0.1801 - mape: 1.3273 - val_loss: 0.0613 - val_mse: 0.0613 - val_mae: 0.1875 - val_mape: 1.3859\n",
      "Epoch 151/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1715 - mape: 1.2610 - val_loss: 0.0604 - val_mse: 0.0604 - val_mae: 0.1839 - val_mape: 1.3564\n",
      "Epoch 152/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0531 - mse: 0.0531 - mae: 0.1793 - mape: 1.3153 - val_loss: 0.0727 - val_mse: 0.0727 - val_mae: 0.2148 - val_mape: 1.5607\n",
      "Epoch 153/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1755 - mape: 1.2903 - val_loss: 0.0974 - val_mse: 0.0974 - val_mae: 0.2444 - val_mape: 1.8054\n",
      "Epoch 154/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1696 - mape: 1.2507 - val_loss: 0.0579 - val_mse: 0.0579 - val_mae: 0.1867 - val_mape: 1.3672\n",
      "Epoch 155/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1720 - mape: 1.2652 - val_loss: 0.0771 - val_mse: 0.0771 - val_mae: 0.2163 - val_mape: 1.6085\n",
      "Epoch 156/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0524 - mse: 0.0524 - mae: 0.1786 - mape: 1.3144 - val_loss: 0.0596 - val_mse: 0.0596 - val_mae: 0.1859 - val_mape: 1.3712\n",
      "Epoch 157/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0492 - mse: 0.0492 - mae: 0.1732 - mape: 1.2766 - val_loss: 0.0569 - val_mse: 0.0569 - val_mae: 0.1807 - val_mape: 1.3274\n",
      "Epoch 158/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0507 - mse: 0.0507 - mae: 0.1760 - mape: 1.2938 - val_loss: 0.0621 - val_mse: 0.0621 - val_mae: 0.1872 - val_mape: 1.3804\n",
      "Epoch 159/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1687 - mape: 1.2391 - val_loss: 0.0743 - val_mse: 0.0743 - val_mae: 0.2183 - val_mape: 1.5874\n",
      "Epoch 160/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0520 - mse: 0.0520 - mae: 0.1787 - mape: 1.3154 - val_loss: 0.0579 - val_mse: 0.0579 - val_mae: 0.1836 - val_mape: 1.3421\n",
      "Epoch 161/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0513 - mse: 0.0513 - mae: 0.1757 - mape: 1.2936 - val_loss: 0.0619 - val_mse: 0.0619 - val_mae: 0.1945 - val_mape: 1.4235\n",
      "Epoch 162/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.1774 - mape: 1.3094 - val_loss: 0.0577 - val_mse: 0.0577 - val_mae: 0.1826 - val_mape: 1.3439\n",
      "Epoch 163/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1743 - mape: 1.2791 - val_loss: 0.0597 - val_mse: 0.0597 - val_mae: 0.1835 - val_mape: 1.3510\n",
      "Epoch 164/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1682 - mape: 1.2368 - val_loss: 0.0737 - val_mse: 0.0737 - val_mae: 0.2080 - val_mape: 1.5395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1673 - mape: 1.2313 - val_loss: 0.0566 - val_mse: 0.0566 - val_mae: 0.1825 - val_mape: 1.3337\n",
      "Epoch 166/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1672 - mape: 1.2296 - val_loss: 0.0649 - val_mse: 0.0649 - val_mae: 0.1917 - val_mape: 1.4125\n",
      "Epoch 167/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.1810 - mape: 1.3325 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1771 - val_mape: 1.3005\n",
      "Epoch 168/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1726 - mape: 1.2731 - val_loss: 0.0593 - val_mse: 0.0593 - val_mae: 0.1862 - val_mape: 1.3662\n",
      "Epoch 169/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1729 - mape: 1.2714 - val_loss: 0.0568 - val_mse: 0.0568 - val_mae: 0.1808 - val_mape: 1.3252\n",
      "Epoch 170/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1719 - mape: 1.2636 - val_loss: 0.0620 - val_mse: 0.0620 - val_mae: 0.1884 - val_mape: 1.3886\n",
      "Epoch 171/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1687 - mape: 1.2417 - val_loss: 0.0552 - val_mse: 0.0552 - val_mae: 0.1799 - val_mape: 1.3205\n",
      "Epoch 172/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1689 - mape: 1.2421 - val_loss: 0.0859 - val_mse: 0.0859 - val_mae: 0.2235 - val_mape: 1.6514\n",
      "Epoch 173/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.1787 - mape: 1.3158 - val_loss: 0.0703 - val_mse: 0.0703 - val_mae: 0.2024 - val_mape: 1.4909\n",
      "Epoch 174/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0545 - mse: 0.0545 - mae: 0.1831 - mape: 1.3424 - val_loss: 0.0542 - val_mse: 0.0542 - val_mae: 0.1780 - val_mape: 1.3079\n",
      "Epoch 175/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0522 - mse: 0.0522 - mae: 0.1767 - mape: 1.2961 - val_loss: 0.0662 - val_mse: 0.0662 - val_mae: 0.2037 - val_mape: 1.4872\n",
      "Epoch 176/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0453 - mse: 0.0453 - mae: 0.1633 - mape: 1.2041 - val_loss: 0.0658 - val_mse: 0.0658 - val_mae: 0.2017 - val_mape: 1.4662\n",
      "Epoch 177/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0607 - mse: 0.0607 - mae: 0.1904 - mape: 1.3999 - val_loss: 0.0872 - val_mse: 0.0872 - val_mae: 0.2422 - val_mape: 1.7707\n",
      "Epoch 178/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0491 - mse: 0.0491 - mae: 0.1725 - mape: 1.2689 - val_loss: 0.0602 - val_mse: 0.0602 - val_mae: 0.1839 - val_mape: 1.3562\n",
      "Epoch 179/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0499 - mse: 0.0499 - mae: 0.1713 - mape: 1.2618 - val_loss: 0.0536 - val_mse: 0.0536 - val_mae: 0.1758 - val_mape: 1.2900\n",
      "Epoch 180/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1740 - mape: 1.2782 - val_loss: 0.0634 - val_mse: 0.0634 - val_mae: 0.1904 - val_mape: 1.4055\n",
      "Epoch 181/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1673 - mape: 1.2301 - val_loss: 0.0567 - val_mse: 0.0567 - val_mae: 0.1812 - val_mape: 1.3333\n",
      "Epoch 182/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1738 - mape: 1.2781 - val_loss: 0.0829 - val_mse: 0.0829 - val_mae: 0.2231 - val_mape: 1.6512\n",
      "Epoch 183/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1649 - mape: 1.2142 - val_loss: 0.0567 - val_mse: 0.0567 - val_mae: 0.1819 - val_mape: 1.3339\n",
      "Epoch 184/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0540 - mse: 0.0540 - mae: 0.1802 - mape: 1.3215 - val_loss: 0.0566 - val_mse: 0.0566 - val_mae: 0.1798 - val_mape: 1.3215\n",
      "Epoch 185/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0499 - mse: 0.0499 - mae: 0.1733 - mape: 1.2739 - val_loss: 0.0670 - val_mse: 0.0670 - val_mae: 0.2032 - val_mape: 1.4837\n",
      "Epoch 186/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1743 - mape: 1.2815 - val_loss: 0.0536 - val_mse: 0.0536 - val_mae: 0.1774 - val_mape: 1.3007\n",
      "Epoch 187/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1677 - mape: 1.2333 - val_loss: 0.0652 - val_mse: 0.0652 - val_mae: 0.1959 - val_mape: 1.4479\n",
      "Epoch 188/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1686 - mape: 1.2430 - val_loss: 0.0570 - val_mse: 0.0570 - val_mae: 0.1850 - val_mape: 1.3545\n",
      "Epoch 189/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1683 - mape: 1.2397 - val_loss: 0.0652 - val_mse: 0.0652 - val_mae: 0.1944 - val_mape: 1.4331\n",
      "Epoch 190/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1743 - mape: 1.2804 - val_loss: 0.0587 - val_mse: 0.0587 - val_mae: 0.1877 - val_mape: 1.3748\n",
      "Epoch 191/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1672 - mape: 1.2277 - val_loss: 0.0582 - val_mse: 0.0582 - val_mae: 0.1873 - val_mape: 1.3679\n",
      "Epoch 192/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1704 - mape: 1.2540 - val_loss: 0.0559 - val_mse: 0.0559 - val_mae: 0.1803 - val_mape: 1.3222\n",
      "Epoch 193/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1694 - mape: 1.2452 - val_loss: 0.0594 - val_mse: 0.0594 - val_mae: 0.1876 - val_mape: 1.3705\n",
      "Epoch 194/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0439 - mse: 0.0439 - mae: 0.1619 - mape: 1.1936 - val_loss: 0.0825 - val_mse: 0.0825 - val_mae: 0.2198 - val_mape: 1.6188\n",
      "Epoch 195/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1667 - mape: 1.2252 - val_loss: 0.0556 - val_mse: 0.0556 - val_mae: 0.1807 - val_mape: 1.3211\n",
      "Epoch 196/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0455 - mse: 0.0455 - mae: 0.1643 - mape: 1.2072 - val_loss: 0.0634 - val_mse: 0.0634 - val_mae: 0.1966 - val_mape: 1.4366\n",
      "Epoch 197/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1664 - mape: 1.2215 - val_loss: 0.0582 - val_mse: 0.0582 - val_mae: 0.1828 - val_mape: 1.3398\n",
      "Epoch 198/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1679 - mape: 1.2328 - val_loss: 0.0675 - val_mse: 0.0675 - val_mae: 0.1986 - val_mape: 1.4623\n",
      "Epoch 199/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.1785 - mape: 1.3127 - val_loss: 0.0554 - val_mse: 0.0554 - val_mae: 0.1805 - val_mape: 1.3243\n",
      "Epoch 200/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0449 - mse: 0.0449 - mae: 0.1616 - mape: 1.1906 - val_loss: 0.0690 - val_mse: 0.0690 - val_mae: 0.1979 - val_mape: 1.4575\n",
      "Epoch 201/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1750 - mape: 1.2840 - val_loss: 0.0660 - val_mse: 0.0660 - val_mae: 0.2021 - val_mape: 1.4760\n",
      "Epoch 202/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0458 - mse: 0.0458 - mae: 0.1653 - mape: 1.2170 - val_loss: 0.0590 - val_mse: 0.0590 - val_mae: 0.1834 - val_mape: 1.3537\n",
      "Epoch 203/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1676 - mape: 1.2315 - val_loss: 0.0661 - val_mse: 0.0661 - val_mae: 0.1969 - val_mape: 1.4553\n",
      "Epoch 204/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1675 - mape: 1.2329 - val_loss: 0.0528 - val_mse: 0.0528 - val_mae: 0.1743 - val_mape: 1.2786\n",
      "Epoch 205/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0451 - mse: 0.0451 - mae: 0.1642 - mape: 1.2105 - val_loss: 0.0552 - val_mse: 0.0552 - val_mae: 0.1801 - val_mape: 1.3183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1645 - mape: 1.2115 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1765 - val_mape: 1.2938\n",
      "Epoch 207/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0461 - mse: 0.0461 - mae: 0.1671 - mape: 1.2282 - val_loss: 0.0552 - val_mse: 0.0552 - val_mae: 0.1802 - val_mape: 1.3194\n",
      "Epoch 208/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0442 - mse: 0.0442 - mae: 0.1624 - mape: 1.1910 - val_loss: 0.0562 - val_mse: 0.0562 - val_mae: 0.1815 - val_mape: 1.3303\n",
      "Epoch 209/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0445 - mse: 0.0445 - mae: 0.1644 - mape: 1.2101 - val_loss: 0.0692 - val_mse: 0.0692 - val_mae: 0.2036 - val_mape: 1.5057\n",
      "Epoch 210/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1683 - mape: 1.2399 - val_loss: 0.0637 - val_mse: 0.0637 - val_mae: 0.1949 - val_mape: 1.4155\n",
      "Epoch 211/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1684 - mape: 1.2404 - val_loss: 0.0530 - val_mse: 0.0530 - val_mae: 0.1744 - val_mape: 1.2829\n",
      "Epoch 212/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1722 - mape: 1.2646 - val_loss: 0.0553 - val_mse: 0.0553 - val_mae: 0.1777 - val_mape: 1.3086\n",
      "Epoch 213/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0434 - mse: 0.0434 - mae: 0.1596 - mape: 1.1743 - val_loss: 0.0620 - val_mse: 0.0620 - val_mae: 0.1921 - val_mape: 1.4196\n",
      "Epoch 214/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0467 - mse: 0.0467 - mae: 0.1675 - mape: 1.2363 - val_loss: 0.0704 - val_mse: 0.0704 - val_mae: 0.1968 - val_mape: 1.4456\n",
      "Epoch 215/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.1788 - mape: 1.3156 - val_loss: 0.0598 - val_mse: 0.0598 - val_mae: 0.1878 - val_mape: 1.3903\n",
      "Epoch 216/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0446 - mse: 0.0446 - mae: 0.1643 - mape: 1.2100 - val_loss: 0.0528 - val_mse: 0.0528 - val_mae: 0.1734 - val_mape: 1.2750\n",
      "Epoch 217/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1663 - mape: 1.2203 - val_loss: 0.0534 - val_mse: 0.0534 - val_mae: 0.1752 - val_mape: 1.2872\n",
      "Epoch 218/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1690 - mape: 1.2450 - val_loss: 0.0564 - val_mse: 0.0564 - val_mae: 0.1825 - val_mape: 1.3324\n",
      "Epoch 219/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0456 - mse: 0.0456 - mae: 0.1649 - mape: 1.2144 - val_loss: 0.0555 - val_mse: 0.0555 - val_mae: 0.1776 - val_mape: 1.3073\n",
      "Epoch 220/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0408 - mse: 0.0408 - mae: 0.1557 - mape: 1.1439 - val_loss: 0.0564 - val_mse: 0.0564 - val_mae: 0.1824 - val_mape: 1.3331\n",
      "Epoch 221/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0454 - mse: 0.0454 - mae: 0.1655 - mape: 1.2181 - val_loss: 0.0590 - val_mse: 0.0590 - val_mae: 0.1833 - val_mape: 1.3530\n",
      "Epoch 222/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0442 - mse: 0.0442 - mae: 0.1612 - mape: 1.1860 - val_loss: 0.0681 - val_mse: 0.0681 - val_mae: 0.2064 - val_mape: 1.5066\n",
      "Epoch 223/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0457 - mse: 0.0457 - mae: 0.1645 - mape: 1.2129 - val_loss: 0.0661 - val_mse: 0.0661 - val_mae: 0.1979 - val_mape: 1.4674\n",
      "Epoch 224/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0452 - mse: 0.0452 - mae: 0.1638 - mape: 1.2068 - val_loss: 0.0798 - val_mse: 0.0798 - val_mae: 0.2180 - val_mape: 1.6186\n",
      "Epoch 225/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0460 - mse: 0.0460 - mae: 0.1652 - mape: 1.2166 - val_loss: 0.0542 - val_mse: 0.0542 - val_mae: 0.1779 - val_mape: 1.3057\n",
      "Epoch 226/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0435 - mse: 0.0435 - mae: 0.1610 - mape: 1.1849 - val_loss: 0.0609 - val_mse: 0.0609 - val_mae: 0.1907 - val_mape: 1.3915\n",
      "Epoch 227/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0455 - mse: 0.0455 - mae: 0.1639 - mape: 1.2066 - val_loss: 0.0641 - val_mse: 0.0641 - val_mae: 0.1901 - val_mape: 1.3995\n",
      "Epoch 228/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0517 - mse: 0.0517 - mae: 0.1777 - mape: 1.3078 - val_loss: 0.0588 - val_mse: 0.0588 - val_mae: 0.1825 - val_mape: 1.3478\n",
      "Epoch 229/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0425 - mse: 0.0425 - mae: 0.1579 - mape: 1.1619 - val_loss: 0.0752 - val_mse: 0.0752 - val_mae: 0.2226 - val_mape: 1.6318\n",
      "Epoch 230/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0448 - mse: 0.0448 - mae: 0.1644 - mape: 1.2124 - val_loss: 0.0630 - val_mse: 0.0630 - val_mae: 0.1974 - val_mape: 1.4413\n",
      "Epoch 231/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1724 - mape: 1.2684 - val_loss: 0.0545 - val_mse: 0.0545 - val_mae: 0.1755 - val_mape: 1.2911\n",
      "Epoch 232/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1700 - mape: 1.2503 - val_loss: 0.0526 - val_mse: 0.0526 - val_mae: 0.1740 - val_mape: 1.2744\n",
      "Epoch 233/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0479 - mse: 0.0479 - mae: 0.1704 - mape: 1.2535 - val_loss: 0.0738 - val_mse: 0.0738 - val_mae: 0.2163 - val_mape: 1.5765\n",
      "Epoch 234/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.1775 - mape: 1.3029 - val_loss: 0.0553 - val_mse: 0.0553 - val_mae: 0.1809 - val_mape: 1.3371\n",
      "Epoch 235/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1648 - mape: 1.2134 - val_loss: 0.0583 - val_mse: 0.0583 - val_mae: 0.1867 - val_mape: 1.3670\n",
      "Epoch 236/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0444 - mse: 0.0444 - mae: 0.1622 - mape: 1.1938 - val_loss: 0.0522 - val_mse: 0.0522 - val_mae: 0.1730 - val_mape: 1.2696\n",
      "Epoch 237/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0433 - mse: 0.0433 - mae: 0.1604 - mape: 1.1779 - val_loss: 0.0588 - val_mse: 0.0588 - val_mae: 0.1854 - val_mape: 1.3644\n",
      "Epoch 238/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0403 - mse: 0.0403 - mae: 0.1547 - mape: 1.1399 - val_loss: 0.0660 - val_mse: 0.0660 - val_mae: 0.2032 - val_mape: 1.4859\n",
      "Epoch 239/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0509 - mse: 0.0509 - mae: 0.1737 - mape: 1.2798 - val_loss: 0.0537 - val_mse: 0.0537 - val_mae: 0.1764 - val_mape: 1.2937\n",
      "Epoch 240/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0458 - mse: 0.0458 - mae: 0.1657 - mape: 1.2183 - val_loss: 0.0588 - val_mse: 0.0588 - val_mae: 0.1883 - val_mape: 1.3755\n",
      "Epoch 241/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0421 - mse: 0.0421 - mae: 0.1575 - mape: 1.1594 - val_loss: 0.0525 - val_mse: 0.0525 - val_mae: 0.1753 - val_mape: 1.2837\n",
      "Epoch 242/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0422 - mae: 0.1574 - mape: 1.1602 - val_loss: 0.0558 - val_mse: 0.0558 - val_mae: 0.1812 - val_mape: 1.3216\n",
      "Epoch 243/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0445 - mse: 0.0445 - mae: 0.1634 - mape: 1.2031 - val_loss: 0.0522 - val_mse: 0.0522 - val_mae: 0.1743 - val_mape: 1.2796\n",
      "Epoch 244/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1649 - mape: 1.2158 - val_loss: 0.0616 - val_mse: 0.0616 - val_mae: 0.1902 - val_mape: 1.3982\n",
      "Epoch 245/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0421 - mse: 0.0421 - mae: 0.1579 - mape: 1.1635 - val_loss: 0.0593 - val_mse: 0.0593 - val_mae: 0.1841 - val_mape: 1.3643\n",
      "Epoch 246/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0556 - mse: 0.0556 - mae: 0.1844 - mape: 1.3523 - val_loss: 0.0515 - val_mse: 0.0515 - val_mae: 0.1731 - val_mape: 1.2727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0438 - mse: 0.0438 - mae: 0.1626 - mape: 1.1980 - val_loss: 0.0750 - val_mse: 0.0750 - val_mae: 0.2122 - val_mape: 1.5683\n",
      "Epoch 248/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0452 - mse: 0.0452 - mae: 0.1650 - mape: 1.2143 - val_loss: 0.0532 - val_mse: 0.0532 - val_mae: 0.1768 - val_mape: 1.2948\n",
      "Epoch 249/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0409 - mse: 0.0409 - mae: 0.1565 - mape: 1.1544 - val_loss: 0.0550 - val_mse: 0.0550 - val_mae: 0.1795 - val_mape: 1.3166\n",
      "Epoch 250/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1697 - mape: 1.2516 - val_loss: 0.0565 - val_mse: 0.0565 - val_mae: 0.1782 - val_mape: 1.3137\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss = \"mse\", optimizer = opt, metrics = [\"mse\", \"mae\", \"mape\"])\n",
    "\n",
    "history_1_field = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00091-0196c862-954e-4eb0-a30d-1c2daca84fc0",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.045, Test: 0.054\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 264,
       "width": 368
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_mse = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse[0], test_mse[0]))\n",
    "\n",
    "# plot loss during training\n",
    "plt.title('Loss / MSE (Mean Squared Error)')\n",
    "plt.plot(history_1_field.history['loss'], label='train')\n",
    "plt.plot(history_1_field.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00092-066f2e33-cd1b-47de-b62e-5ea86652b6f3",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squarred error (field_tuner): 0.05419532922506465\n",
      "Root mean squarred error (field_tuner): 0.23279890297221043\n",
      "Mean absolute error (field_tuner): 0.17757174251127272\n",
      "MAPE (field_tuner): 0.013106454387074822\n",
      "R squared (field_tuner): 0.9709648739631742\n"
     ]
    }
   ],
   "source": [
    "y_pred_field_no_earlystopping = model.predict(X_test)\n",
    "mse_field_tuner_no_earlystopping = metrics.mean_squared_error(y_test, y_pred_field_no_earlystopping)\n",
    "rmse_field_tuner_no_earlystopping= np.sqrt(mean_squared_error(y_test, y_pred_field_no_earlystopping))\n",
    "mae_field_tuner_no_earlystopping = mean_absolute_error(y_test,y_pred_field_no_earlystopping)\n",
    "mape_field_tuner_no_earlystopping = mean_absolute_percentage_error(y_test,y_pred_field_no_earlystopping)\n",
    "r2_score_field_tuner_no_earlystopping = r2_score(y_test, y_pred_field_no_earlystopping)\n",
    "\n",
    "print(\"Mean squarred error (field_tuner): {}\".format(mse_field_tuner_no_earlystopping))\n",
    "print(\"Root mean squarred error (field_tuner): {}\".format(rmse_field_tuner_no_earlystopping))\n",
    "print(\"Mean absolute error (field_tuner): {}\".format(mae_field_tuner_no_earlystopping))\n",
    "print(\"MAPE (field_tuner): {}\".format(mape_field_tuner_no_earlystopping))\n",
    "print(\"R squared (field_tuner): {}\".format(r2_score_field_tuner_no_earlystopping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00093-2f050f60-91ce-4b68-a81e-caa1cf4e4429",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "epochs_field_no_earlystopping = len(history_1_field.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00094-f1a093aa-4435-4b29-8c31-09307054fa59",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### NN with EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00124-141b298f-ff0c-405c-a1cf-c966802f3272",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Now we implement the model with the parameters obtained from the Keras tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00125-c4c1f35e-33b8-42a2-8200-2eca1889d726",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 572,
    "execution_start": 1621692356253,
    "source_hash": "8bbbf050",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Since now we are predicting a single continuous value, the output layer will only have 1 node.\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=40, min_delta = 0.0)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim = X_field.shape[1], activation = \"relu\"))\n",
    "model.add(Dense(37, activation = \"relu\"))         #first hidden layer\n",
    "model.add(Dense(49, activation = \"relu\"))        #second hidden layer\n",
    "model.add(Dense(115, activation = \"relu\"))        \n",
    "model.add(Dense(49, activation = \"relu\"))        \n",
    "model.add(Dense(5, activation = \"relu\"))        \n",
    "\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1, activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00126-fe0ea0a3-7f0a-402b-9a2f-842384f8f9dc",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 146493,
    "execution_start": 1621673389572,
    "scrolled": true,
    "source_hash": "e420584b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "278/278 [==============================] - 2s 3ms/step - loss: 80.8280 - mse: 80.8280 - mae: 6.7821 - mape: 49.9719 - val_loss: 0.9023 - val_mse: 0.9023 - val_mae: 0.7727 - val_mape: 5.7325\n",
      "Epoch 2/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.6688 - mse: 0.6688 - mae: 0.6539 - mape: 4.8702 - val_loss: 0.3149 - val_mse: 0.3149 - val_mae: 0.4451 - val_mape: 3.3088\n",
      "Epoch 3/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.2904 - mse: 0.2904 - mae: 0.4232 - mape: 3.1465 - val_loss: 0.2233 - val_mse: 0.2233 - val_mae: 0.3766 - val_mape: 2.8017\n",
      "Epoch 4/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.2069 - mse: 0.2069 - mae: 0.3604 - mape: 2.6773 - val_loss: 0.1817 - val_mse: 0.1817 - val_mae: 0.3384 - val_mape: 2.5086\n",
      "Epoch 5/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.1726 - mse: 0.1726 - mae: 0.3283 - mape: 2.4288 - val_loss: 0.2098 - val_mse: 0.2098 - val_mae: 0.3693 - val_mape: 2.6972\n",
      "Epoch 6/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.1548 - mse: 0.1548 - mae: 0.3107 - mape: 2.3017 - val_loss: 0.1335 - val_mse: 0.1335 - val_mae: 0.2890 - val_mape: 2.1389\n",
      "Epoch 7/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.1314 - mse: 0.1314 - mae: 0.2864 - mape: 2.1173 - val_loss: 0.1201 - val_mse: 0.1201 - val_mae: 0.2730 - val_mape: 2.0153\n",
      "Epoch 8/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.1257 - mse: 0.1257 - mae: 0.2806 - mape: 2.0781 - val_loss: 0.1337 - val_mse: 0.1337 - val_mae: 0.2895 - val_mape: 2.1148\n",
      "Epoch 9/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.1187 - mse: 0.1187 - mae: 0.2717 - mape: 2.0060 - val_loss: 0.1094 - val_mse: 0.1094 - val_mae: 0.2597 - val_mape: 1.9098\n",
      "Epoch 10/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.1087 - mse: 0.1087 - mae: 0.2615 - mape: 1.9334 - val_loss: 0.2215 - val_mse: 0.2215 - val_mae: 0.3853 - val_mape: 2.8720\n",
      "Epoch 11/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.1250 - mse: 0.1250 - mae: 0.2774 - mape: 2.0486 - val_loss: 0.1035 - val_mse: 0.1035 - val_mae: 0.2506 - val_mape: 1.8488\n",
      "Epoch 12/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.1079 - mse: 0.1079 - mae: 0.2580 - mape: 1.9074 - val_loss: 0.1236 - val_mse: 0.1236 - val_mae: 0.2798 - val_mape: 2.0392\n",
      "Epoch 13/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.1184 - mse: 0.1184 - mae: 0.2718 - mape: 2.0099 - val_loss: 0.1172 - val_mse: 0.1172 - val_mae: 0.2672 - val_mape: 1.9882\n",
      "Epoch 14/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.1050 - mse: 0.1050 - mae: 0.2544 - mape: 1.8797 - val_loss: 0.1003 - val_mse: 0.1003 - val_mae: 0.2493 - val_mape: 1.8304\n",
      "Epoch 15/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0967 - mse: 0.0967 - mae: 0.2430 - mape: 1.7958 - val_loss: 0.1014 - val_mse: 0.1014 - val_mae: 0.2505 - val_mape: 1.8339\n",
      "Epoch 16/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0966 - mse: 0.0966 - mae: 0.2444 - mape: 1.8100 - val_loss: 0.1134 - val_mse: 0.1134 - val_mae: 0.2689 - val_mape: 1.9607\n",
      "Epoch 17/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0966 - mse: 0.0966 - mae: 0.2446 - mape: 1.8073 - val_loss: 0.1103 - val_mse: 0.1103 - val_mae: 0.2660 - val_mape: 1.9423\n",
      "Epoch 18/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0961 - mse: 0.0961 - mae: 0.2437 - mape: 1.7998 - val_loss: 0.0858 - val_mse: 0.0858 - val_mae: 0.2296 - val_mape: 1.6892\n",
      "Epoch 19/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0949 - mse: 0.0949 - mae: 0.2424 - mape: 1.7876 - val_loss: 0.0839 - val_mse: 0.0839 - val_mae: 0.2253 - val_mape: 1.6647\n",
      "Epoch 20/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0929 - mse: 0.0929 - mae: 0.2399 - mape: 1.7756 - val_loss: 0.0981 - val_mse: 0.0981 - val_mae: 0.2491 - val_mape: 1.8178\n",
      "Epoch 21/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0956 - mse: 0.0956 - mae: 0.2410 - mape: 1.7793 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2296 - val_mape: 1.6865\n",
      "Epoch 22/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2315 - mape: 1.7111 - val_loss: 0.1178 - val_mse: 0.1178 - val_mae: 0.2783 - val_mape: 2.0285\n",
      "Epoch 23/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0949 - mse: 0.0949 - mae: 0.2427 - mape: 1.7902 - val_loss: 0.0999 - val_mse: 0.0999 - val_mae: 0.2452 - val_mape: 1.8187\n",
      "Epoch 24/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0925 - mse: 0.0925 - mae: 0.2392 - mape: 1.7677 - val_loss: 0.0871 - val_mse: 0.0871 - val_mae: 0.2327 - val_mape: 1.7021\n",
      "Epoch 25/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0998 - mse: 0.0998 - mae: 0.2474 - mape: 1.8300 - val_loss: 0.0858 - val_mse: 0.0858 - val_mae: 0.2274 - val_mape: 1.6841\n",
      "Epoch 26/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0879 - mse: 0.0879 - mae: 0.2334 - mape: 1.7222 - val_loss: 0.0775 - val_mse: 0.0775 - val_mae: 0.2180 - val_mape: 1.6036\n",
      "Epoch 27/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0851 - mse: 0.0851 - mae: 0.2296 - mape: 1.6978 - val_loss: 0.0758 - val_mse: 0.0758 - val_mae: 0.2146 - val_mape: 1.5800\n",
      "Epoch 28/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0779 - mse: 0.0779 - mae: 0.2173 - mape: 1.6026 - val_loss: 0.0898 - val_mse: 0.0898 - val_mae: 0.2386 - val_mape: 1.7423\n",
      "Epoch 29/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0824 - mse: 0.0824 - mae: 0.2250 - mape: 1.6582 - val_loss: 0.0765 - val_mse: 0.0765 - val_mae: 0.2171 - val_mape: 1.5908\n",
      "Epoch 30/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0839 - mse: 0.0839 - mae: 0.2260 - mape: 1.6664 - val_loss: 0.0756 - val_mse: 0.0756 - val_mae: 0.2144 - val_mape: 1.5788\n",
      "Epoch 31/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0801 - mse: 0.0801 - mae: 0.2216 - mape: 1.6370 - val_loss: 0.0733 - val_mse: 0.0733 - val_mae: 0.2099 - val_mape: 1.5455\n",
      "Epoch 32/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0796 - mse: 0.0796 - mae: 0.2197 - mape: 1.6234 - val_loss: 0.0751 - val_mse: 0.0751 - val_mae: 0.2152 - val_mape: 1.5830\n",
      "Epoch 33/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0803 - mse: 0.0803 - mae: 0.2216 - mape: 1.6365 - val_loss: 0.0751 - val_mse: 0.0751 - val_mae: 0.2114 - val_mape: 1.5595\n",
      "Epoch 34/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0819 - mse: 0.0819 - mae: 0.2255 - mape: 1.6575 - val_loss: 0.0928 - val_mse: 0.0928 - val_mae: 0.2421 - val_mape: 1.7620\n",
      "Epoch 35/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0887 - mse: 0.0887 - mae: 0.2322 - mape: 1.7107 - val_loss: 0.1051 - val_mse: 0.1051 - val_mae: 0.2630 - val_mape: 1.9131\n",
      "Epoch 36/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0757 - mse: 0.0757 - mae: 0.2149 - mape: 1.5860 - val_loss: 0.0730 - val_mse: 0.0730 - val_mae: 0.2110 - val_mape: 1.5524\n",
      "Epoch 37/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0797 - mse: 0.0797 - mae: 0.2201 - mape: 1.6212 - val_loss: 0.0691 - val_mse: 0.0691 - val_mae: 0.2041 - val_mape: 1.4973\n",
      "Epoch 38/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0866 - mse: 0.0866 - mae: 0.2295 - mape: 1.6883 - val_loss: 0.0949 - val_mse: 0.0949 - val_mae: 0.2469 - val_mape: 1.7973\n",
      "Epoch 39/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0744 - mse: 0.0744 - mae: 0.2121 - mape: 1.5666 - val_loss: 0.0739 - val_mse: 0.0739 - val_mae: 0.2110 - val_mape: 1.5487\n",
      "Epoch 40/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0829 - mse: 0.0829 - mae: 0.2253 - mape: 1.6618 - val_loss: 0.0927 - val_mse: 0.0927 - val_mae: 0.2465 - val_mape: 1.7991\n",
      "Epoch 41/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0731 - mse: 0.0731 - mae: 0.2102 - mape: 1.5485 - val_loss: 0.0681 - val_mse: 0.0681 - val_mae: 0.2017 - val_mape: 1.4847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0712 - mse: 0.0712 - mae: 0.2078 - mape: 1.5281 - val_loss: 0.0713 - val_mse: 0.0713 - val_mae: 0.2078 - val_mape: 1.5282\n",
      "Epoch 43/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0701 - mse: 0.0701 - mae: 0.2070 - mape: 1.5290 - val_loss: 0.0884 - val_mse: 0.0884 - val_mae: 0.2368 - val_mape: 1.7208\n",
      "Epoch 44/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0746 - mse: 0.0746 - mae: 0.2130 - mape: 1.5724 - val_loss: 0.0721 - val_mse: 0.0721 - val_mae: 0.2104 - val_mape: 1.5414\n",
      "Epoch 45/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0688 - mse: 0.0688 - mae: 0.2054 - mape: 1.5173 - val_loss: 0.0669 - val_mse: 0.0669 - val_mae: 0.2014 - val_mape: 1.4814\n",
      "Epoch 46/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0657 - mse: 0.0657 - mae: 0.2005 - mape: 1.4788 - val_loss: 0.0679 - val_mse: 0.0679 - val_mae: 0.2042 - val_mape: 1.4982\n",
      "Epoch 47/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0689 - mse: 0.0689 - mae: 0.2047 - mape: 1.5053 - val_loss: 0.0772 - val_mse: 0.0772 - val_mae: 0.2153 - val_mape: 1.5956\n",
      "Epoch 48/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0663 - mse: 0.0663 - mae: 0.2022 - mape: 1.4887 - val_loss: 0.1498 - val_mse: 0.1498 - val_mae: 0.3093 - val_mape: 2.2917\n",
      "Epoch 49/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0748 - mse: 0.0748 - mae: 0.2128 - mape: 1.5654 - val_loss: 0.0700 - val_mse: 0.0700 - val_mae: 0.2073 - val_mape: 1.5149\n",
      "Epoch 50/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0696 - mse: 0.0696 - mae: 0.2062 - mape: 1.5205 - val_loss: 0.0717 - val_mse: 0.0717 - val_mae: 0.2063 - val_mape: 1.5231\n",
      "Epoch 51/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0700 - mse: 0.0700 - mae: 0.2078 - mape: 1.5296 - val_loss: 0.0739 - val_mse: 0.0739 - val_mae: 0.2082 - val_mape: 1.5430\n",
      "Epoch 52/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0662 - mse: 0.0662 - mae: 0.2008 - mape: 1.4805 - val_loss: 0.0754 - val_mse: 0.0754 - val_mae: 0.2174 - val_mape: 1.5867\n",
      "Epoch 53/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0680 - mse: 0.0680 - mae: 0.2033 - mape: 1.5004 - val_loss: 0.0868 - val_mse: 0.0868 - val_mae: 0.2377 - val_mape: 1.7292\n",
      "Epoch 54/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0691 - mse: 0.0691 - mae: 0.2043 - mape: 1.5053 - val_loss: 0.0751 - val_mse: 0.0751 - val_mae: 0.2155 - val_mape: 1.5704\n",
      "Epoch 55/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0696 - mse: 0.0696 - mae: 0.2068 - mape: 1.5226 - val_loss: 0.0640 - val_mse: 0.0640 - val_mae: 0.1963 - val_mape: 1.4431\n",
      "Epoch 56/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0677 - mse: 0.0677 - mae: 0.2021 - mape: 1.4882 - val_loss: 0.0624 - val_mse: 0.0624 - val_mae: 0.1938 - val_mape: 1.4232\n",
      "Epoch 57/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0641 - mse: 0.0641 - mae: 0.1969 - mape: 1.4466 - val_loss: 0.0674 - val_mse: 0.0674 - val_mae: 0.2033 - val_mape: 1.4892\n",
      "Epoch 58/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0677 - mse: 0.0677 - mae: 0.2031 - mape: 1.4981 - val_loss: 0.0979 - val_mse: 0.0979 - val_mae: 0.2546 - val_mape: 1.8525\n",
      "Epoch 59/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0777 - mse: 0.0777 - mae: 0.2200 - mape: 1.6235 - val_loss: 0.0623 - val_mse: 0.0623 - val_mae: 0.1931 - val_mape: 1.4147\n",
      "Epoch 60/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0624 - mse: 0.0624 - mae: 0.1958 - mape: 1.4424 - val_loss: 0.0640 - val_mse: 0.0640 - val_mae: 0.1980 - val_mape: 1.4553\n",
      "Epoch 61/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0656 - mse: 0.0656 - mae: 0.2000 - mape: 1.4737 - val_loss: 0.0793 - val_mse: 0.0793 - val_mae: 0.2226 - val_mape: 1.6194\n",
      "Epoch 62/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0618 - mse: 0.0618 - mae: 0.1931 - mape: 1.4234 - val_loss: 0.0676 - val_mse: 0.0676 - val_mae: 0.2032 - val_mape: 1.4814\n",
      "Epoch 63/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0628 - mse: 0.0628 - mae: 0.1935 - mape: 1.4214 - val_loss: 0.0623 - val_mse: 0.0623 - val_mae: 0.1923 - val_mape: 1.4148\n",
      "Epoch 64/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0606 - mse: 0.0606 - mae: 0.1915 - mape: 1.4099 - val_loss: 0.0786 - val_mse: 0.0786 - val_mae: 0.2188 - val_mape: 1.5956\n",
      "Epoch 65/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0633 - mse: 0.0633 - mae: 0.1956 - mape: 1.4423 - val_loss: 0.0597 - val_mse: 0.0597 - val_mae: 0.1874 - val_mape: 1.3772\n",
      "Epoch 66/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0741 - mse: 0.0741 - mae: 0.2127 - mape: 1.5662 - val_loss: 0.0891 - val_mse: 0.0891 - val_mae: 0.2382 - val_mape: 1.7309\n",
      "Epoch 67/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0634 - mse: 0.0634 - mae: 0.1962 - mape: 1.4448 - val_loss: 0.0641 - val_mse: 0.0641 - val_mae: 0.1980 - val_mape: 1.4482\n",
      "Epoch 68/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0562 - mse: 0.0562 - mae: 0.1860 - mape: 1.3707 - val_loss: 0.0618 - val_mse: 0.0618 - val_mae: 0.1909 - val_mape: 1.4035\n",
      "Epoch 69/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0643 - mse: 0.0643 - mae: 0.1975 - mape: 1.4572 - val_loss: 0.0714 - val_mse: 0.0714 - val_mae: 0.2019 - val_mape: 1.4905\n",
      "Epoch 70/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0661 - mse: 0.0661 - mae: 0.1995 - mape: 1.4682 - val_loss: 0.0669 - val_mse: 0.0669 - val_mae: 0.1963 - val_mape: 1.4480\n",
      "Epoch 71/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0640 - mse: 0.0640 - mae: 0.1979 - mape: 1.4579 - val_loss: 0.0882 - val_mse: 0.0882 - val_mae: 0.2374 - val_mape: 1.7168\n",
      "Epoch 72/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0602 - mse: 0.0602 - mae: 0.1933 - mape: 1.4211 - val_loss: 0.0746 - val_mse: 0.0746 - val_mae: 0.2165 - val_mape: 1.5851\n",
      "Epoch 73/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0633 - mse: 0.0633 - mae: 0.1949 - mape: 1.4368 - val_loss: 0.0596 - val_mse: 0.0596 - val_mae: 0.1862 - val_mape: 1.3714\n",
      "Epoch 74/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0666 - mse: 0.0666 - mae: 0.2018 - mape: 1.4831 - val_loss: 0.0643 - val_mse: 0.0643 - val_mae: 0.1924 - val_mape: 1.4187\n",
      "Epoch 75/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0598 - mse: 0.0598 - mae: 0.1902 - mape: 1.4000 - val_loss: 0.0819 - val_mse: 0.0819 - val_mae: 0.2308 - val_mape: 1.6813\n",
      "Epoch 76/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0748 - mse: 0.0748 - mae: 0.2115 - mape: 1.5528 - val_loss: 0.0657 - val_mse: 0.0657 - val_mae: 0.1994 - val_mape: 1.4498\n",
      "Epoch 77/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0564 - mse: 0.0564 - mae: 0.1835 - mape: 1.3551 - val_loss: 0.0636 - val_mse: 0.0636 - val_mae: 0.1948 - val_mape: 1.4190\n",
      "Epoch 78/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0642 - mse: 0.0642 - mae: 0.1972 - mape: 1.4518 - val_loss: 0.0813 - val_mse: 0.0813 - val_mae: 0.2174 - val_mape: 1.6082\n",
      "Epoch 79/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0579 - mse: 0.0579 - mae: 0.1865 - mape: 1.3754 - val_loss: 0.0599 - val_mse: 0.0599 - val_mae: 0.1910 - val_mape: 1.3960\n",
      "Epoch 80/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0600 - mse: 0.0600 - mae: 0.1906 - mape: 1.4039 - val_loss: 0.0643 - val_mse: 0.0643 - val_mae: 0.1959 - val_mape: 1.4275\n",
      "Epoch 81/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0536 - mse: 0.0536 - mae: 0.1785 - mape: 1.3189 - val_loss: 0.0653 - val_mse: 0.0653 - val_mae: 0.1959 - val_mape: 1.4450\n",
      "Epoch 82/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0570 - mse: 0.0570 - mae: 0.1854 - mape: 1.3654 - val_loss: 0.0801 - val_mse: 0.0801 - val_mae: 0.2198 - val_mape: 1.6310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0556 - mse: 0.0556 - mae: 0.1833 - mape: 1.3500 - val_loss: 0.1050 - val_mse: 0.1050 - val_mae: 0.2695 - val_mape: 1.9572\n",
      "Epoch 84/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0553 - mse: 0.0553 - mae: 0.1822 - mape: 1.3396 - val_loss: 0.0583 - val_mse: 0.0583 - val_mae: 0.1877 - val_mape: 1.3729\n",
      "Epoch 85/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.1783 - mape: 1.3142 - val_loss: 0.0558 - val_mse: 0.0558 - val_mae: 0.1820 - val_mape: 1.3355\n",
      "Epoch 86/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0544 - mse: 0.0544 - mae: 0.1786 - mape: 1.3173 - val_loss: 0.0647 - val_mse: 0.0647 - val_mae: 0.1924 - val_mape: 1.4208\n",
      "Epoch 87/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0561 - mse: 0.0561 - mae: 0.1828 - mape: 1.3438 - val_loss: 0.0672 - val_mse: 0.0672 - val_mae: 0.1960 - val_mape: 1.4485\n",
      "Epoch 88/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0583 - mse: 0.0583 - mae: 0.1860 - mape: 1.3695 - val_loss: 0.0593 - val_mse: 0.0593 - val_mae: 0.1838 - val_mape: 1.3560\n",
      "Epoch 89/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0620 - mse: 0.0620 - mae: 0.1930 - mape: 1.4202 - val_loss: 0.0644 - val_mse: 0.0644 - val_mae: 0.1997 - val_mape: 1.4533\n",
      "Epoch 90/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0547 - mse: 0.0547 - mae: 0.1815 - mape: 1.3383 - val_loss: 0.0671 - val_mse: 0.0671 - val_mae: 0.2065 - val_mape: 1.5066\n",
      "Epoch 91/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.1757 - mape: 1.2958 - val_loss: 0.0692 - val_mse: 0.0692 - val_mae: 0.2039 - val_mape: 1.5119\n",
      "Epoch 92/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.1788 - mape: 1.3177 - val_loss: 0.0751 - val_mse: 0.0751 - val_mae: 0.2120 - val_mape: 1.5732\n",
      "Epoch 93/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.1752 - mape: 1.2939 - val_loss: 0.0547 - val_mse: 0.0547 - val_mae: 0.1762 - val_mape: 1.2998\n",
      "Epoch 94/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0540 - mse: 0.0540 - mae: 0.1787 - mape: 1.3186 - val_loss: 0.0593 - val_mse: 0.0593 - val_mae: 0.1891 - val_mape: 1.3817\n",
      "Epoch 95/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0541 - mse: 0.0541 - mae: 0.1797 - mape: 1.3280 - val_loss: 0.0691 - val_mse: 0.0691 - val_mae: 0.2117 - val_mape: 1.5454\n",
      "Epoch 96/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1753 - mape: 1.2946 - val_loss: 0.0678 - val_mse: 0.0678 - val_mae: 0.2094 - val_mape: 1.5394\n",
      "Epoch 97/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0512 - mse: 0.0512 - mae: 0.1758 - mape: 1.2978 - val_loss: 0.0682 - val_mse: 0.0682 - val_mae: 0.2083 - val_mape: 1.5208\n",
      "Epoch 98/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0527 - mse: 0.0527 - mae: 0.1769 - mape: 1.3016 - val_loss: 0.0666 - val_mse: 0.0666 - val_mae: 0.2075 - val_mape: 1.5188\n",
      "Epoch 99/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0539 - mse: 0.0539 - mae: 0.1770 - mape: 1.3035 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1754 - val_mape: 1.2965\n",
      "Epoch 100/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0571 - mse: 0.0571 - mae: 0.1870 - mape: 1.3821 - val_loss: 0.0986 - val_mse: 0.0986 - val_mae: 0.2584 - val_mape: 1.8813\n",
      "Epoch 101/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0520 - mse: 0.0520 - mae: 0.1745 - mape: 1.2870 - val_loss: 0.0735 - val_mse: 0.0735 - val_mae: 0.2048 - val_mape: 1.5174\n",
      "Epoch 102/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0524 - mse: 0.0524 - mae: 0.1764 - mape: 1.3015 - val_loss: 0.0616 - val_mse: 0.0616 - val_mae: 0.1913 - val_mape: 1.4011\n",
      "Epoch 103/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0560 - mse: 0.0560 - mae: 0.1812 - mape: 1.3372 - val_loss: 0.0543 - val_mse: 0.0543 - val_mae: 0.1800 - val_mape: 1.3195\n",
      "Epoch 104/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1711 - mape: 1.2673 - val_loss: 0.0555 - val_mse: 0.0555 - val_mae: 0.1841 - val_mape: 1.3529\n",
      "Epoch 105/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1732 - mape: 1.2778 - val_loss: 0.0508 - val_mse: 0.0508 - val_mae: 0.1697 - val_mape: 1.2512\n",
      "Epoch 106/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0516 - mse: 0.0516 - mae: 0.1744 - mape: 1.2896 - val_loss: 0.0511 - val_mse: 0.0511 - val_mae: 0.1686 - val_mape: 1.2441\n",
      "Epoch 107/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0511 - mse: 0.0511 - mae: 0.1746 - mape: 1.2868 - val_loss: 0.0533 - val_mse: 0.0533 - val_mae: 0.1752 - val_mape: 1.2862\n",
      "Epoch 108/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0493 - mse: 0.0493 - mae: 0.1700 - mape: 1.2560 - val_loss: 0.0643 - val_mse: 0.0643 - val_mae: 0.2007 - val_mape: 1.4740\n",
      "Epoch 109/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0542 - mse: 0.0542 - mae: 0.1806 - mape: 1.3331 - val_loss: 0.1006 - val_mse: 0.1006 - val_mae: 0.2523 - val_mape: 1.8719\n",
      "Epoch 110/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0592 - mse: 0.0592 - mae: 0.1860 - mape: 1.3730 - val_loss: 0.0911 - val_mse: 0.0911 - val_mae: 0.2324 - val_mape: 1.7176\n",
      "Epoch 111/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0537 - mse: 0.0537 - mae: 0.1784 - mape: 1.3184 - val_loss: 0.0509 - val_mse: 0.0509 - val_mae: 0.1703 - val_mape: 1.2556\n",
      "Epoch 112/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.1747 - mape: 1.2917 - val_loss: 0.0581 - val_mse: 0.0581 - val_mae: 0.1821 - val_mape: 1.3432\n",
      "Epoch 113/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1720 - mape: 1.2732 - val_loss: 0.0512 - val_mse: 0.0512 - val_mae: 0.1679 - val_mape: 1.2432\n",
      "Epoch 114/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1684 - mape: 1.2475 - val_loss: 0.0520 - val_mse: 0.0520 - val_mae: 0.1699 - val_mape: 1.2563\n",
      "Epoch 115/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1741 - mape: 1.2863 - val_loss: 0.0517 - val_mse: 0.0517 - val_mae: 0.1680 - val_mape: 1.2420\n",
      "Epoch 116/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1707 - mape: 1.2628 - val_loss: 0.0546 - val_mse: 0.0546 - val_mae: 0.1740 - val_mape: 1.2911\n",
      "Epoch 117/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1708 - mape: 1.2651 - val_loss: 0.0610 - val_mse: 0.0610 - val_mae: 0.1869 - val_mape: 1.3841\n",
      "Epoch 118/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1726 - mape: 1.2793 - val_loss: 0.0520 - val_mse: 0.0520 - val_mae: 0.1710 - val_mape: 1.2630\n",
      "Epoch 119/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0454 - mse: 0.0454 - mae: 0.1644 - mape: 1.2153 - val_loss: 0.0596 - val_mse: 0.0596 - val_mae: 0.1841 - val_mape: 1.3587\n",
      "Epoch 120/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1731 - mape: 1.2782 - val_loss: 0.0570 - val_mse: 0.0570 - val_mae: 0.1895 - val_mape: 1.3910\n",
      "Epoch 121/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1682 - mape: 1.2421 - val_loss: 0.0501 - val_mse: 0.0501 - val_mae: 0.1681 - val_mape: 1.2370\n",
      "Epoch 122/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1656 - mape: 1.2251 - val_loss: 0.0580 - val_mse: 0.0580 - val_mae: 0.1924 - val_mape: 1.4147\n",
      "Epoch 123/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0531 - mse: 0.0531 - mae: 0.1777 - mape: 1.3124 - val_loss: 0.0518 - val_mse: 0.0518 - val_mae: 0.1705 - val_mape: 1.2615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0515 - mse: 0.0515 - mae: 0.1737 - mape: 1.2813 - val_loss: 0.0475 - val_mse: 0.0475 - val_mae: 0.1616 - val_mape: 1.1935\n",
      "Epoch 125/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1671 - mape: 1.2315 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1774 - val_mape: 1.3136\n",
      "Epoch 126/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1683 - mape: 1.2450 - val_loss: 0.0568 - val_mse: 0.0568 - val_mae: 0.1814 - val_mape: 1.3340\n",
      "Epoch 127/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1656 - mape: 1.2253 - val_loss: 0.0580 - val_mse: 0.0580 - val_mae: 0.1867 - val_mape: 1.3631\n",
      "Epoch 128/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0455 - mse: 0.0455 - mae: 0.1625 - mape: 1.2009 - val_loss: 0.0584 - val_mse: 0.0584 - val_mae: 0.1837 - val_mape: 1.3533\n",
      "Epoch 129/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1673 - mape: 1.2359 - val_loss: 0.0535 - val_mse: 0.0535 - val_mae: 0.1799 - val_mape: 1.3196\n",
      "Epoch 130/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1678 - mape: 1.2399 - val_loss: 0.0493 - val_mse: 0.0493 - val_mae: 0.1676 - val_mape: 1.2308\n",
      "Epoch 131/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1649 - mape: 1.2202 - val_loss: 0.0491 - val_mse: 0.0491 - val_mae: 0.1638 - val_mape: 1.2108\n",
      "Epoch 132/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1665 - mape: 1.2299 - val_loss: 0.0524 - val_mse: 0.0524 - val_mae: 0.1710 - val_mape: 1.2644\n",
      "Epoch 133/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0514 - mse: 0.0514 - mae: 0.1742 - mape: 1.2877 - val_loss: 0.0515 - val_mse: 0.0515 - val_mae: 0.1664 - val_mape: 1.2328\n",
      "Epoch 134/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1650 - mape: 1.2190 - val_loss: 0.0484 - val_mse: 0.0484 - val_mae: 0.1659 - val_mape: 1.2194\n",
      "Epoch 135/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1571 - mape: 1.1645 - val_loss: 0.0488 - val_mse: 0.0488 - val_mae: 0.1681 - val_mape: 1.2427\n",
      "Epoch 136/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0480 - mse: 0.0480 - mae: 0.1666 - mape: 1.2339 - val_loss: 0.0543 - val_mse: 0.0543 - val_mae: 0.1818 - val_mape: 1.3319\n",
      "Epoch 137/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1685 - mape: 1.2468 - val_loss: 0.0496 - val_mse: 0.0496 - val_mae: 0.1651 - val_mape: 1.2209\n",
      "Epoch 138/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1636 - mape: 1.2100 - val_loss: 0.0468 - val_mse: 0.0468 - val_mae: 0.1595 - val_mape: 1.1778\n",
      "Epoch 139/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1656 - mape: 1.2262 - val_loss: 0.0550 - val_mse: 0.0550 - val_mae: 0.1805 - val_mape: 1.3228\n",
      "Epoch 140/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1654 - mape: 1.2242 - val_loss: 0.0503 - val_mse: 0.0503 - val_mae: 0.1735 - val_mape: 1.2795\n",
      "Epoch 141/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0460 - mse: 0.0460 - mae: 0.1645 - mape: 1.2176 - val_loss: 0.0469 - val_mse: 0.0469 - val_mae: 0.1590 - val_mape: 1.1764\n",
      "Epoch 142/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1647 - mape: 1.2200 - val_loss: 0.0651 - val_mse: 0.0651 - val_mae: 0.1881 - val_mape: 1.3920\n",
      "Epoch 143/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0513 - mse: 0.0513 - mae: 0.1742 - mape: 1.2892 - val_loss: 0.0571 - val_mse: 0.0571 - val_mae: 0.1723 - val_mape: 1.2780\n",
      "Epoch 144/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0461 - mse: 0.0461 - mae: 0.1647 - mape: 1.2189 - val_loss: 0.0487 - val_mse: 0.0487 - val_mae: 0.1615 - val_mape: 1.1988\n",
      "Epoch 145/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1649 - mape: 1.2220 - val_loss: 0.1168 - val_mse: 0.1168 - val_mae: 0.2804 - val_mape: 2.0811\n",
      "Epoch 146/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0489 - mse: 0.0489 - mae: 0.1683 - mape: 1.2418 - val_loss: 0.0501 - val_mse: 0.0501 - val_mae: 0.1647 - val_mape: 1.2188\n",
      "Epoch 147/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0498 - mse: 0.0498 - mae: 0.1727 - mape: 1.2789 - val_loss: 0.0880 - val_mse: 0.0880 - val_mae: 0.2243 - val_mape: 1.6506\n",
      "Epoch 148/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0563 - mse: 0.0563 - mae: 0.1825 - mape: 1.3491 - val_loss: 0.0507 - val_mse: 0.0507 - val_mae: 0.1713 - val_mape: 1.2565\n",
      "Epoch 149/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0427 - mse: 0.0427 - mae: 0.1590 - mape: 1.1781 - val_loss: 0.0506 - val_mse: 0.0506 - val_mae: 0.1705 - val_mape: 1.2501\n",
      "Epoch 150/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0536 - mse: 0.0536 - mae: 0.1782 - mape: 1.3188 - val_loss: 0.0465 - val_mse: 0.0465 - val_mae: 0.1600 - val_mape: 1.1827\n",
      "Epoch 151/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0422 - mse: 0.0422 - mae: 0.1573 - mape: 1.1649 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1680 - val_mape: 1.2437\n",
      "Epoch 152/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1666 - mape: 1.2293 - val_loss: 0.0476 - val_mse: 0.0476 - val_mae: 0.1614 - val_mape: 1.1864\n",
      "Epoch 153/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0427 - mse: 0.0427 - mae: 0.1583 - mape: 1.1721 - val_loss: 0.0722 - val_mse: 0.0722 - val_mae: 0.2039 - val_mape: 1.5094\n",
      "Epoch 154/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0449 - mse: 0.0449 - mae: 0.1608 - mape: 1.1952 - val_loss: 0.0513 - val_mse: 0.0513 - val_mae: 0.1738 - val_mape: 1.2759\n",
      "Epoch 155/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0438 - mse: 0.0438 - mae: 0.1594 - mape: 1.1798 - val_loss: 0.0553 - val_mse: 0.0553 - val_mae: 0.1734 - val_mape: 1.2896\n",
      "Epoch 156/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0454 - mse: 0.0454 - mae: 0.1635 - mape: 1.2091 - val_loss: 0.0519 - val_mse: 0.0519 - val_mae: 0.1773 - val_mape: 1.2987\n",
      "Epoch 157/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0444 - mse: 0.0444 - mae: 0.1630 - mape: 1.2083 - val_loss: 0.0630 - val_mse: 0.0630 - val_mae: 0.1981 - val_mape: 1.4508\n",
      "Epoch 158/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1671 - mape: 1.2346 - val_loss: 0.0898 - val_mse: 0.0898 - val_mae: 0.2390 - val_mape: 1.7704\n",
      "Epoch 159/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0449 - mse: 0.0449 - mae: 0.1631 - mape: 1.2062 - val_loss: 0.0747 - val_mse: 0.0747 - val_mae: 0.2222 - val_mape: 1.6210\n",
      "Epoch 160/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0529 - mse: 0.0529 - mae: 0.1808 - mape: 1.3354 - val_loss: 0.0619 - val_mse: 0.0619 - val_mae: 0.1925 - val_mape: 1.4044\n",
      "Epoch 161/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0455 - mse: 0.0455 - mae: 0.1637 - mape: 1.2122 - val_loss: 0.0488 - val_mse: 0.0488 - val_mae: 0.1637 - val_mape: 1.2101\n",
      "Epoch 162/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0430 - mse: 0.0430 - mae: 0.1576 - mape: 1.1721 - val_loss: 0.0503 - val_mse: 0.0503 - val_mae: 0.1646 - val_mape: 1.2180\n",
      "Epoch 163/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0453 - mse: 0.0453 - mae: 0.1634 - mape: 1.2071 - val_loss: 0.0493 - val_mse: 0.0493 - val_mae: 0.1636 - val_mape: 1.2092\n",
      "Epoch 164/250\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0428 - mse: 0.0428 - mae: 0.1586 - mape: 1.17 - 1s 2ms/step - loss: 0.0431 - mse: 0.0431 - mae: 0.1591 - mape: 1.1766 - val_loss: 0.0517 - val_mse: 0.0517 - val_mae: 0.1637 - val_mape: 1.2114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0430 - mse: 0.0430 - mae: 0.1583 - mape: 1.1731 - val_loss: 0.0543 - val_mse: 0.0543 - val_mae: 0.1729 - val_mape: 1.2798\n",
      "Epoch 166/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0406 - mse: 0.0406 - mae: 0.1559 - mape: 1.1546 - val_loss: 0.0491 - val_mse: 0.0491 - val_mae: 0.1604 - val_mape: 1.1878\n",
      "Epoch 167/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0447 - mse: 0.0447 - mae: 0.1625 - mape: 1.2024 - val_loss: 0.0486 - val_mse: 0.0486 - val_mae: 0.1617 - val_mape: 1.1963\n",
      "Epoch 168/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0438 - mse: 0.0438 - mae: 0.1580 - mape: 1.1734 - val_loss: 0.0472 - val_mse: 0.0472 - val_mae: 0.1636 - val_mape: 1.2075\n",
      "Epoch 169/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0447 - mse: 0.0447 - mae: 0.1610 - mape: 1.1939 - val_loss: 0.0491 - val_mse: 0.0491 - val_mae: 0.1652 - val_mape: 1.2155\n",
      "Epoch 170/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0439 - mse: 0.0439 - mae: 0.1597 - mape: 1.1820 - val_loss: 0.0452 - val_mse: 0.0452 - val_mae: 0.1573 - val_mape: 1.1632\n",
      "Epoch 171/250\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.0413 - mse: 0.0413 - mae: 0.1559 - mape: 1.1550 - val_loss: 0.0473 - val_mse: 0.0473 - val_mae: 0.1600 - val_mape: 1.1808\n",
      "Epoch 172/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0436 - mse: 0.0436 - mae: 0.1603 - mape: 1.1862 - val_loss: 0.0838 - val_mse: 0.0838 - val_mae: 0.2271 - val_mape: 1.6879\n",
      "Epoch 173/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0500 - mse: 0.0500 - mae: 0.1724 - mape: 1.2762 - val_loss: 0.0566 - val_mse: 0.0566 - val_mae: 0.1813 - val_mape: 1.3362\n",
      "Epoch 174/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0460 - mse: 0.0460 - mae: 0.1665 - mape: 1.2286 - val_loss: 0.0454 - val_mse: 0.0454 - val_mae: 0.1593 - val_mape: 1.1752\n",
      "Epoch 175/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0433 - mse: 0.0433 - mae: 0.1582 - mape: 1.1715 - val_loss: 0.0554 - val_mse: 0.0554 - val_mae: 0.1843 - val_mape: 1.3541\n",
      "Epoch 176/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1565 - mape: 1.1633 - val_loss: 0.0510 - val_mse: 0.0510 - val_mae: 0.1747 - val_mape: 1.2773\n",
      "Epoch 177/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0433 - mse: 0.0433 - mae: 0.1575 - mape: 1.1659 - val_loss: 0.0492 - val_mse: 0.0492 - val_mae: 0.1709 - val_mape: 1.2537\n",
      "Epoch 178/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0443 - mse: 0.0443 - mae: 0.1616 - mape: 1.1962 - val_loss: 0.0517 - val_mse: 0.0517 - val_mae: 0.1649 - val_mape: 1.2223\n",
      "Epoch 179/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0474 - mse: 0.0474 - mae: 0.1645 - mape: 1.2198 - val_loss: 0.0460 - val_mse: 0.0460 - val_mae: 0.1569 - val_mape: 1.1589\n",
      "Epoch 180/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0410 - mse: 0.0410 - mae: 0.1558 - mape: 1.1527 - val_loss: 0.0462 - val_mse: 0.0462 - val_mae: 0.1587 - val_mape: 1.1755\n",
      "Epoch 181/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0430 - mse: 0.0430 - mae: 0.1569 - mape: 1.1611 - val_loss: 0.0454 - val_mse: 0.0454 - val_mae: 0.1585 - val_mape: 1.1709\n",
      "Epoch 182/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0476 - mse: 0.0476 - mae: 0.1672 - mape: 1.2352 - val_loss: 0.0654 - val_mse: 0.0654 - val_mae: 0.1943 - val_mape: 1.4387\n",
      "Epoch 183/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0439 - mse: 0.0439 - mae: 0.1594 - mape: 1.1814 - val_loss: 0.0529 - val_mse: 0.0529 - val_mae: 0.1790 - val_mape: 1.3181\n",
      "Epoch 184/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0506 - mse: 0.0506 - mae: 0.1731 - mape: 1.2761 - val_loss: 0.0513 - val_mse: 0.0513 - val_mae: 0.1691 - val_mape: 1.2506\n",
      "Epoch 185/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0472 - mse: 0.0472 - mae: 0.1673 - mape: 1.2363 - val_loss: 0.0562 - val_mse: 0.0562 - val_mae: 0.1883 - val_mape: 1.3842\n",
      "Epoch 186/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0469 - mse: 0.0469 - mae: 0.1657 - mape: 1.2253 - val_loss: 0.0496 - val_mse: 0.0496 - val_mae: 0.1645 - val_mape: 1.2142\n",
      "Epoch 187/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1582 - mape: 1.1719 - val_loss: 0.0473 - val_mse: 0.0473 - val_mae: 0.1608 - val_mape: 1.1881\n",
      "Epoch 188/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0403 - mse: 0.0403 - mae: 0.1529 - mape: 1.1355 - val_loss: 0.0552 - val_mse: 0.0552 - val_mae: 0.1833 - val_mape: 1.3501\n",
      "Epoch 189/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0405 - mse: 0.0405 - mae: 0.1542 - mape: 1.1438 - val_loss: 0.0450 - val_mse: 0.0450 - val_mae: 0.1574 - val_mape: 1.1634\n",
      "Epoch 190/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0434 - mse: 0.0434 - mae: 0.1591 - mape: 1.1761 - val_loss: 0.0517 - val_mse: 0.0517 - val_mae: 0.1746 - val_mape: 1.2818\n",
      "Epoch 191/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0438 - mse: 0.0438 - mae: 0.1606 - mape: 1.1864 - val_loss: 0.0468 - val_mse: 0.0468 - val_mae: 0.1589 - val_mape: 1.1760\n",
      "Epoch 192/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0449 - mse: 0.0449 - mae: 0.1631 - mape: 1.2066 - val_loss: 0.0459 - val_mse: 0.0459 - val_mae: 0.1564 - val_mape: 1.1566\n",
      "Epoch 193/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0443 - mse: 0.0443 - mae: 0.1601 - mape: 1.1839 - val_loss: 0.0495 - val_mse: 0.0495 - val_mae: 0.1714 - val_mape: 1.2658\n",
      "Epoch 194/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0416 - mse: 0.0416 - mae: 0.1565 - mape: 1.1609 - val_loss: 0.0629 - val_mse: 0.0629 - val_mae: 0.1893 - val_mape: 1.4068\n",
      "Epoch 195/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0400 - mse: 0.0400 - mae: 0.1517 - mape: 1.1238 - val_loss: 0.0512 - val_mse: 0.0512 - val_mae: 0.1719 - val_mape: 1.2624\n",
      "Epoch 196/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0427 - mse: 0.0427 - mae: 0.1584 - mape: 1.1711 - val_loss: 0.0568 - val_mse: 0.0568 - val_mae: 0.1859 - val_mape: 1.3605\n",
      "Epoch 197/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0413 - mse: 0.0413 - mae: 0.1555 - mape: 1.1505 - val_loss: 0.0519 - val_mse: 0.0519 - val_mae: 0.1690 - val_mape: 1.2495\n",
      "Epoch 198/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0397 - mse: 0.0397 - mae: 0.1524 - mape: 1.1277 - val_loss: 0.0591 - val_mse: 0.0591 - val_mae: 0.1817 - val_mape: 1.3504\n",
      "Epoch 199/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1652 - mape: 1.2207 - val_loss: 0.0530 - val_mse: 0.0530 - val_mae: 0.1809 - val_mape: 1.3245\n",
      "Epoch 200/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0419 - mse: 0.0419 - mae: 0.1572 - mape: 1.1682 - val_loss: 0.0472 - val_mse: 0.0472 - val_mae: 0.1605 - val_mape: 1.1835\n",
      "Epoch 201/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0392 - mse: 0.0392 - mae: 0.1503 - mape: 1.1114 - val_loss: 0.0496 - val_mse: 0.0496 - val_mae: 0.1658 - val_mape: 1.2280\n",
      "Epoch 202/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0410 - mse: 0.0410 - mae: 0.1544 - mape: 1.1449 - val_loss: 0.0491 - val_mse: 0.0491 - val_mae: 0.1632 - val_mape: 1.2114\n",
      "Epoch 203/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0452 - mse: 0.0452 - mae: 0.1639 - mape: 1.2126 - val_loss: 0.0814 - val_mse: 0.0814 - val_mae: 0.2249 - val_mape: 1.6792\n",
      "Epoch 204/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0429 - mse: 0.0429 - mae: 0.1608 - mape: 1.1887 - val_loss: 0.0495 - val_mse: 0.0495 - val_mae: 0.1642 - val_mape: 1.2150\n",
      "Epoch 205/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0409 - mse: 0.0409 - mae: 0.1545 - mape: 1.1465 - val_loss: 0.0463 - val_mse: 0.0463 - val_mae: 0.1598 - val_mape: 1.1774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0412 - mse: 0.0412 - mae: 0.1532 - mape: 1.1362 - val_loss: 0.0465 - val_mse: 0.0465 - val_mae: 0.1580 - val_mape: 1.1671\n",
      "Epoch 207/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0410 - mse: 0.0410 - mae: 0.1550 - mape: 1.1484 - val_loss: 0.0661 - val_mse: 0.0661 - val_mae: 0.2077 - val_mape: 1.5161\n",
      "Epoch 208/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0432 - mse: 0.0432 - mae: 0.1588 - mape: 1.1709 - val_loss: 0.0487 - val_mse: 0.0487 - val_mae: 0.1633 - val_mape: 1.2057\n",
      "Epoch 209/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0387 - mse: 0.0387 - mae: 0.1498 - mape: 1.1098 - val_loss: 0.0609 - val_mse: 0.0609 - val_mae: 0.1879 - val_mape: 1.3947\n",
      "Epoch 210/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1683 - mape: 1.2450 - val_loss: 0.0481 - val_mse: 0.0481 - val_mae: 0.1632 - val_mape: 1.1969\n",
      "Epoch 211/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0409 - mse: 0.0409 - mae: 0.1539 - mape: 1.1407 - val_loss: 0.0541 - val_mse: 0.0541 - val_mae: 0.1761 - val_mape: 1.2842\n",
      "Epoch 212/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0432 - mse: 0.0432 - mae: 0.1602 - mape: 1.1858 - val_loss: 0.0712 - val_mse: 0.0712 - val_mae: 0.1941 - val_mape: 1.4363\n",
      "Epoch 213/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1554 - mape: 1.1519 - val_loss: 0.0589 - val_mse: 0.0589 - val_mae: 0.1788 - val_mape: 1.3239\n",
      "Epoch 214/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0413 - mse: 0.0413 - mae: 0.1541 - mape: 1.1461 - val_loss: 0.0480 - val_mse: 0.0480 - val_mae: 0.1627 - val_mape: 1.1959\n",
      "Epoch 215/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0444 - mse: 0.0444 - mae: 0.1618 - mape: 1.1985 - val_loss: 0.0508 - val_mse: 0.0508 - val_mae: 0.1673 - val_mape: 1.2450\n",
      "Epoch 216/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0409 - mse: 0.0409 - mae: 0.1558 - mape: 1.1539 - val_loss: 0.0464 - val_mse: 0.0464 - val_mae: 0.1601 - val_mape: 1.1846\n",
      "Epoch 217/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0425 - mse: 0.0425 - mae: 0.1572 - mape: 1.1609 - val_loss: 0.0494 - val_mse: 0.0494 - val_mae: 0.1621 - val_mape: 1.2019\n",
      "Epoch 218/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0433 - mse: 0.0433 - mae: 0.1600 - mape: 1.1872 - val_loss: 0.0473 - val_mse: 0.0473 - val_mae: 0.1622 - val_mape: 1.1999\n",
      "Epoch 219/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0410 - mse: 0.0410 - mae: 0.1555 - mape: 1.1519 - val_loss: 0.0511 - val_mse: 0.0511 - val_mae: 0.1757 - val_mape: 1.2986\n",
      "Epoch 220/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0383 - mse: 0.0383 - mae: 0.1485 - mape: 1.0991 - val_loss: 0.0589 - val_mse: 0.0589 - val_mae: 0.1881 - val_mape: 1.3671\n",
      "Epoch 221/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0418 - mse: 0.0418 - mae: 0.1558 - mape: 1.1522 - val_loss: 0.0574 - val_mse: 0.0574 - val_mae: 0.1759 - val_mape: 1.3079\n",
      "Epoch 222/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0412 - mse: 0.0412 - mae: 0.1541 - mape: 1.1416 - val_loss: 0.0633 - val_mse: 0.0633 - val_mae: 0.2025 - val_mape: 1.4757\n",
      "Epoch 223/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0453 - mse: 0.0453 - mae: 0.1631 - mape: 1.2071 - val_loss: 0.0837 - val_mse: 0.0837 - val_mae: 0.2324 - val_mape: 1.7244\n",
      "Epoch 224/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1663 - mape: 1.2313 - val_loss: 0.0597 - val_mse: 0.0597 - val_mae: 0.1832 - val_mape: 1.3536\n",
      "Epoch 225/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0397 - mse: 0.0397 - mae: 0.1529 - mape: 1.1333 - val_loss: 0.0451 - val_mse: 0.0451 - val_mae: 0.1566 - val_mape: 1.1580\n",
      "Epoch 226/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0391 - mse: 0.0391 - mae: 0.1500 - mape: 1.1138 - val_loss: 0.0463 - val_mse: 0.0463 - val_mae: 0.1590 - val_mape: 1.1755\n",
      "Epoch 227/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0419 - mse: 0.0419 - mae: 0.1554 - mape: 1.1501 - val_loss: 0.0559 - val_mse: 0.0559 - val_mae: 0.1726 - val_mape: 1.2782\n",
      "Epoch 228/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0437 - mse: 0.0437 - mae: 0.1609 - mape: 1.1916 - val_loss: 0.0666 - val_mse: 0.0666 - val_mae: 0.1957 - val_mape: 1.4527\n",
      "Epoch 229/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0406 - mse: 0.0406 - mae: 0.1525 - mape: 1.1310 - val_loss: 0.0748 - val_mse: 0.0748 - val_mae: 0.2219 - val_mape: 1.6141\n",
      "Epoch 230/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1667 - mape: 1.2327 - val_loss: 0.0779 - val_mse: 0.0779 - val_mae: 0.2345 - val_mape: 1.7149\n",
      "Epoch 231/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0542 - mse: 0.0542 - mae: 0.1796 - mape: 1.3244 - val_loss: 0.0455 - val_mse: 0.0455 - val_mae: 0.1590 - val_mape: 1.1740\n",
      "Epoch 232/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0391 - mse: 0.0391 - mae: 0.1516 - mape: 1.1225 - val_loss: 0.0473 - val_mse: 0.0473 - val_mae: 0.1663 - val_mape: 1.2284\n",
      "Epoch 233/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1667 - mape: 1.2323 - val_loss: 0.0623 - val_mse: 0.0623 - val_mae: 0.1924 - val_mape: 1.4031\n",
      "Epoch 234/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0460 - mse: 0.0460 - mae: 0.1652 - mape: 1.2209 - val_loss: 0.0549 - val_mse: 0.0549 - val_mae: 0.1761 - val_mape: 1.3112\n",
      "Epoch 235/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0422 - mse: 0.0422 - mae: 0.1546 - mape: 1.1449 - val_loss: 0.0466 - val_mse: 0.0466 - val_mae: 0.1640 - val_mape: 1.2090\n",
      "Epoch 236/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0411 - mse: 0.0411 - mae: 0.1542 - mape: 1.1420 - val_loss: 0.0468 - val_mse: 0.0468 - val_mae: 0.1645 - val_mape: 1.2073\n",
      "Epoch 237/250\n",
      "278/278 [==============================] - 1s 3ms/step - loss: 0.0394 - mse: 0.0394 - mae: 0.1511 - mape: 1.1167 - val_loss: 0.0621 - val_mse: 0.0621 - val_mae: 0.1929 - val_mape: 1.4295\n",
      "Epoch 238/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0389 - mse: 0.0389 - mae: 0.1495 - mape: 1.1065 - val_loss: 0.0491 - val_mse: 0.0491 - val_mae: 0.1701 - val_mape: 1.2503\n",
      "Epoch 239/250\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0473 - mse: 0.0473 - mae: 0.1658 - mape: 1.22 - 1s 2ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1654 - mape: 1.2240 - val_loss: 0.0476 - val_mse: 0.0476 - val_mae: 0.1590 - val_mape: 1.1774\n",
      "Epoch 240/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0416 - mse: 0.0416 - mae: 0.1553 - mape: 1.1491 - val_loss: 0.0537 - val_mse: 0.0537 - val_mae: 0.1806 - val_mape: 1.3214\n",
      "Epoch 241/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0392 - mse: 0.0392 - mae: 0.1501 - mape: 1.1122 - val_loss: 0.0551 - val_mse: 0.0551 - val_mae: 0.1841 - val_mape: 1.3580\n",
      "Epoch 242/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0397 - mse: 0.0397 - mae: 0.1502 - mape: 1.1121 - val_loss: 0.0448 - val_mse: 0.0448 - val_mae: 0.1555 - val_mape: 1.1487\n",
      "Epoch 243/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0413 - mse: 0.0413 - mae: 0.1558 - mape: 1.1533 - val_loss: 0.0459 - val_mse: 0.0459 - val_mae: 0.1605 - val_mape: 1.1836\n",
      "Epoch 244/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0407 - mse: 0.0407 - mae: 0.1527 - mape: 1.1323 - val_loss: 0.0619 - val_mse: 0.0619 - val_mae: 0.1895 - val_mape: 1.4025\n",
      "Epoch 245/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0412 - mse: 0.0412 - mae: 0.1546 - mape: 1.1445 - val_loss: 0.0529 - val_mse: 0.0529 - val_mae: 0.1709 - val_mape: 1.2669\n",
      "Epoch 246/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1732 - mape: 1.2774 - val_loss: 0.0518 - val_mse: 0.0518 - val_mae: 0.1713 - val_mape: 1.2674\n",
      "Epoch 247/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0382 - mse: 0.0382 - mae: 0.1497 - mape: 1.1099 - val_loss: 0.0614 - val_mse: 0.0614 - val_mae: 0.1860 - val_mape: 1.3795\n",
      "Epoch 248/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0432 - mse: 0.0432 - mae: 0.1603 - mape: 1.1843 - val_loss: 0.0445 - val_mse: 0.0445 - val_mae: 0.1557 - val_mape: 1.1516\n",
      "Epoch 249/250\n",
      "278/278 [==============================] - 0s 2ms/step - loss: 0.0380 - mse: 0.0380 - mae: 0.1478 - mape: 1.0961 - val_loss: 0.0508 - val_mse: 0.0508 - val_mae: 0.1733 - val_mape: 1.2728\n",
      "Epoch 250/250\n",
      "278/278 [==============================] - 1s 2ms/step - loss: 0.0473 - mse: 0.0473 - mae: 0.1677 - mape: 1.2418 - val_loss: 0.0486 - val_mse: 0.0486 - val_mae: 0.1645 - val_mape: 1.2176\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss = \"mse\", optimizer = opt, metrics = [\"mse\", \"mae\", \"mape\"])\n",
    "\n",
    "history_2_field = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs = 250, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00098-2969cb9e-63a8-43f9-9b1c-28ab37c60802",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.040, Test: 0.044\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 264,
       "width": 368
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_mse = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse[0], test_mse[0]))\n",
    "\n",
    "# plot loss during training\n",
    "plt.title('Loss / MSE (Mean Squared Error)')\n",
    "plt.plot(history_2_field.history['loss'], label='train')\n",
    "plt.plot(history_2_field.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00127-50538370-054b-4ce9-a231-f703fead4480",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 154,
    "execution_start": 1621674330916,
    "source_hash": "32454a62",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squarred error (field_tuner): 0.044345353549719614\n",
      "Root mean squarred error (field_tuner): 0.21058336484565826\n",
      "Mean absolute error (field_tuner): 0.15967767742763664\n",
      "MAPE (field_tuner): 0.011864969647050872\n",
      "R squared (field_tuner): 0.9762419945062678\n"
     ]
    }
   ],
   "source": [
    "y_pred_field_tuner = model.predict(X_test)\n",
    "mse_field_tuner = metrics.mean_squared_error(y_test, y_pred_field_tuner)\n",
    "rmse_field_tuner= np.sqrt(mean_squared_error(y_test, y_pred_field_tuner))\n",
    "mae_field_tuner = mean_absolute_error(y_test,y_pred_field_tuner)\n",
    "mape_field_tuner = mean_absolute_percentage_error(y_test,y_pred_field_tuner)\n",
    "r2_score_field_tuner = r2_score(y_test, y_pred_field_tuner)\n",
    "\n",
    "print(\"Mean squarred error (field_tuner): {}\".format(mse_field_tuner))\n",
    "print(\"Root mean squarred error (field_tuner): {}\".format(rmse_field_tuner))\n",
    "print(\"Mean absolute error (field_tuner): {}\".format(mae_field_tuner))\n",
    "print(\"MAPE (field_tuner): {}\".format(mape_field_tuner))\n",
    "print(\"R squared (field_tuner): {}\".format(r2_score_field_tuner))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00100-bf697107-c2bf-41f4-b23a-f0885aec1f75",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "epochs_field_earlystopping = len(history_2_field.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00101-a2350d9e-7108-40a3-b088-ec36030daa5e",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   4.,   7.,  13.,  42.,  99., 168., 299., 456., 772., 878.,\n",
       "        931., 732., 489., 270., 163.,  91.,  60.,  29.,  24.,   7.,   9.,\n",
       "          3.,   0.,   3.,   0.,   0.,   0.,   0.,   1.]),\n",
       " array([-0.78470692, -0.70951215, -0.63431737, -0.55912259, -0.48392781,\n",
       "        -0.40873304, -0.33353826, -0.25834348, -0.1831487 , -0.10795392,\n",
       "        -0.03275915,  0.04243563,  0.11763041,  0.19282519,  0.26801996,\n",
       "         0.34321474,  0.41840952,  0.4936043 ,  0.56879908,  0.64399385,\n",
       "         0.71918863,  0.79438341,  0.86957819,  0.94477296,  1.01996774,\n",
       "         1.09516252,  1.1703573 ,  1.24555207,  1.32074685,  1.39594163,\n",
       "         1.47113641]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANyklEQVR4nO3df6hf913H8efLpOtc51hKbrIsCbsRwjQduI0QOwsy6bRZI6Z/WIgwDaMQlKpTBEkVLAiBCCJOsJPQzUWcK6Fu5rLOuZg51D9sd/tDtzQLDWtMronN3cTOqnSmvv3jnrpv0ntzz+39fu+9+dznA8I553M+3+/3fT89fX0/99zzPd9UFZKktnzPchcgSRo+w12SGmS4S1KDDHdJapDhLkkNWrvcBQCsX7++xsfHl7sMSbqhPPnkk9+sqrHZ9q2IcB8fH2dycnK5y5CkG0qSf55rn6dlJKlBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQSviE6pavcYPPtar37nDe0ZcidQWZ+6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDvLeMRqLvPWMkjYYzd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAb1Cvckv5rkVJKvJfl0kjcmuTXJiSTPdct1A/0fSHI2yZkkd42ufEnSbOYN9ySbgV8GdlbVu4A1wD7gIHCyqrYDJ7ttkuzo9t8G7AYeSrJmNOVLkmbT97TMWuB7k6wF3gRcBPYCR7v9R4F7uvW9wCNV9XJVPQ+cBXYNr2RJ0nzmDfeq+hfgd4HzwCXgxar6IrCxqi51fS4BG7qHbAYuDDzFVNd2lSQHkkwmmZyenl7cTyFJukqf0zLrmJmNbwPeDtyS5EPXe8gsbfWahqojVbWzqnaOjY31rVeS1EOf0zIfAJ6vqumq+h/gM8CPAC8k2QTQLS93/aeArQOP38LMaRxJ0hLpE+7ngduTvClJgDuB08AEsL/rsx843q1PAPuS3JxkG7AdeGK4ZUuSrmfeL8iuqseTPAo8BVwBngaOAG8GjiW5j5k3gHu7/qeSHAOe7frfX1WvjKh+SdIs5g13gKp6EHjwmuaXmZnFz9b/EHBocaVJkl6vXuEuvWr84GPLXYKkHrz9gCQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBfohJN4S+H546d3jPiCuRbgzO3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQb3CPclbkzya5OtJTid5X5Jbk5xI8ly3XDfQ/4EkZ5OcSXLX6MqXJM2m78z9o8AXquoHgB8CTgMHgZNVtR042W2TZAewD7gN2A08lGTNsAuXJM1t3nBP8hbgR4GPA1TVd6rq34G9wNGu21Hgnm59L/BIVb1cVc8DZ4Fdwy5ckjS3PjP37wemgT9O8nSSh5PcAmysqksA3XJD138zcGHg8VNd21WSHEgymWRyenp6UT+EJOlqfcJ9LfBe4GNV9R7gP+lOwcwhs7TVaxqqjlTVzqraOTY21qtYSVI/fcJ9Cpiqqse77UeZCfsXkmwC6JaXB/pvHXj8FuDicMqVJPUxb7hX1b8CF5K8s2u6E3gWmAD2d237gePd+gSwL8nNSbYB24Enhlq1JOm61vbs90vAp5K8AfgG8GFm3hiOJbkPOA/cC1BVp5IcY+YN4Apwf1W9MvTKJUlz6hXuVfUMsHOWXXfO0f8QcGgRdUmSFsFPqEpSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkN6vsF2dINYfzgY737nju8Z4SVSMvLmbskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkJdCCljYJYSSVj5n7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KDe4Z5kTZKnk3yu2741yYkkz3XLdQN9H0hyNsmZJHeNonBJ0twWMnP/CHB6YPsgcLKqtgMnu22S7AD2AbcBu4GHkqwZTrmSpD56hXuSLcAe4OGB5r3A0W79KHDPQPsjVfVyVT0PnAV2DadcSVIffWfuvw/8OvC/A20bq+oSQLfc0LVvBi4M9Jvq2q6S5ECSySST09PTCy5ckjS3ecM9yU8Cl6vqyZ7PmVna6jUNVUeqamdV7RwbG+v51JKkPvrc8vcO4KeS3A28EXhLkj8FXkiyqaouJdkEXO76TwFbBx6/Bbg4zKIlSdc378y9qh6oqi1VNc7MH0q/VFUfAiaA/V23/cDxbn0C2Jfk5iTbgO3AE0OvXJI0p8V8Wcdh4FiS+4DzwL0AVXUqyTHgWeAKcH9VvbLoSiVJvS0o3Kvqy8CXu/VvAXfO0e8QcGiRtUmSXic/oSpJDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatBivolJN4Dxg48tdwmSloEzd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgL4XUqtX3MtFzh/eMuBJp+Jy5S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDZo33JNsTfI3SU4nOZXkI137rUlOJHmuW64beMwDSc4mOZPkrlH+AJKk1+ozc78C/FpV/SBwO3B/kh3AQeBkVW0HTnbbdPv2AbcBu4GHkqwZRfGSpNnNG+5VdamqnurW/wM4DWwG9gJHu25HgXu69b3AI1X1clU9D5wFdg27cEnS3BZ0zj3JOPAe4HFgY1Vdgpk3AGBD120zcGHgYVNd27XPdSDJZJLJ6enphVcuSZpT73BP8mbgz4FfqapvX6/rLG31moaqI1W1s6p2jo2N9S1DktRDr3BPchMzwf6pqvpM1/xCkk3d/k3A5a59Ctg68PAtwMXhlCtJ6qPP1TIBPg6crqrfG9g1Aezv1vcDxwfa9yW5Ock2YDvwxPBKliTNp8/X7N0B/Czw1STPdG2/ARwGjiW5DzgP3AtQVaeSHAOeZeZKm/ur6pWhVy5JmtO84V5Vf8/s59EB7pzjMYeAQ4uoS5K0CH5CVZIa1Oe0jFaY8YOPLXcJklY4Z+6S1CBn7tI8+v6mdO7wnhFXIvXnzF2SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalB3hVyBfE+7ZKGxZm7JDXImbs0JN73XSuJM3dJapDhLkkNMtwlqUGGuyQ1yHCXpAZ5tYy0xLyqRkvBmbskNchwl6QGGe6S1CDPuS8B7xkjaak5c5ekBhnuktQgT8tIK5SXTGoxDHfpBuebgGbjaRlJapDhLkkNGtlpmSS7gY8Ca4CHq+rwqF5ruXiJo6SVaiThnmQN8IfAjwNTwFeSTFTVs6N4vWEztNWiURzXnsdfuUY1c98FnK2qbwAkeQTYCyxruBva0nAN+4+5/nF4eEYV7puBCwPbU8APD3ZIcgA40G2+lOTMiGpZTuuBby53ESuEY3G1VTUe+Z3r7l7wWMzzfDe6hYzHO+baMapwzyxtddVG1RHgyIhef0VIMllVO5e7jpXAsbia4/FdjsXVhjUeo7paZgrYOrC9Bbg4oteSJF1jVOH+FWB7km1J3gDsAyZG9FqSpGuM5LRMVV1J8ovAXzFzKeQnqurUKF5rhWv6tNMCORZXczy+y7G42lDGI1U1fy9J0g3FT6hKUoMMd0lqkOE+REluTXIiyXPdct0c/c4l+WqSZ5JMLnWdo5Rkd5IzSc4mOTjL/iT5g27/PyV573LUuVR6jMf7k7zYHQvPJPmt5ahz1JJ8IsnlJF+bY/9qOy7mG49FHxeG+3AdBE5W1XbgZLc9lx+rqne3dH3vwG0nPgjsAH4myY5run0Q2N79OwB8bEmLXEI9xwPg77pj4d1V9dtLWuTS+SSw+zr7V81x0fkk1x8PWORxYbgP117gaLd+FLhnGWtZDv9/24mq+g7w6m0nBu0F/qRm/APw1iSblrrQJdJnPFaFqvpb4N+u02U1HRd9xmPRDPfh2lhVlwC65YY5+hXwxSRPdrdhaMVst53Y/Dr6tKLvz/q+JP+Y5C+T3LY0pa04q+m46GtRx4XfxLRASf4aeNssu35zAU9zR1VdTLIBOJHk6907+Y1u3ttO9OzTij4/61PAO6rqpSR3A3/BzKmJ1WY1HRd9LPq4cOa+QFX1gap61yz/jgMvvPqrZLe8PMdzXOyWl4HPMvPrewv63HZiNd2aYt6ftaq+XVUvdeufB25Ksn7pSlwxVtNxMa9hHBeG+3BNAPu79f3A8Ws7JLklyfe9ug78BDDrX8xvQH1uOzEB/Fx3dcTtwIuvnspq0LzjkeRtSdKt72Lm/8lvLXmly281HRfzGsZx4WmZ4ToMHEtyH3AeuBcgyduZ+Taqu4GNwGe7/25rgT+rqi8sU71DNddtJ5L8fLf/j4DPA3cDZ4H/Aj68XPWOWs/x+GngF5JcAf4b2FcNfmw8yaeB9wPrk0wBDwI3weo7LqDXeCz6uPD2A5LUIE/LSFKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoP8DkAawe48x4ZAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 375
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "flatten_y_pred = np.concatenate(y_pred_field_tuner)\n",
    "plt.hist(flatten_y_pred-y_test,bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00129-1aaf8ea6-7173-472f-b93c-6af10bb41974",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 1,
    "execution_start": 1621674332475,
    "source_hash": "eba455a4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_real_field=np.e**y_pred_field_tuner\n",
    "y_test_real=np.e**y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00129-611af418-5622-448b-a516-176379221922",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 1,
    "execution_start": 1621674333394,
    "source_hash": "ad34454c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "flatten_y_pred_field = np.concatenate(y_pred_real_field)\n",
    "y_pred_real_field= pd.Series(flatten_y_pred_field).astype(int)\n",
    "y_test_real_field = pd.Series(y_test_real).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00130-77368efe-659f-4004-919e-12f59ec095db",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 9,
    "execution_start": 1621674334524,
    "source_hash": "8074cb4c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"True vlues\": y_test_real_field,\n",
    "    \"Predicted values\": y_pred_real_field\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00131-f40b6af5-9f6d-4d03-9621-443e6ebcb641",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 46,
    "execution_start": 1621674394594,
    "source_hash": "d8ef5fd2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_field = pd.concat(data, axis = 1)\n",
    "list_of_indexes = list(y_test_real_field.index)\n",
    "list_of_predictions = list(y_pred_real_field)\n",
    "list_total = list(zip(list_of_indexes, list(y_test_real_field), list_of_predictions))\n",
    "df_field = pd.DataFrame(list_total, columns = ['index', 'true', 'pred'])\n",
    "df_field[\"Difference\"] = df_field.pred-df_field.true\n",
    "df_field['Difference %'] = round(100*(df_field.pred-df_field.true)/df_field.true, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00132-ca412b2b-68aa-41ef-82ad-94332499136e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 1,
    "execution_start": 1621675267073,
    "source_hash": "1f00d9d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_list = []\n",
    "for index in list(y_test_real_field.index):\n",
    "    if index in field_dict:\n",
    "        name_list.append(field_dict[index])\n",
    "    else:\n",
    "        break\n",
    "df_field['player'] = name_list\n",
    "col = df_field.pop(\"player\")\n",
    "df_field.insert(0, col.name, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00107-d7721878-4425-4c7b-a44d-83ab05a73647",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#adding the age column to the new dataframe by matching player indexes\n",
    "\n",
    "age_list = []\n",
    "for index in list(y_test.index):\n",
    "    if index in field_age_dict:\n",
    "        age_list.append(field_age_dict[index])\n",
    "    else:\n",
    "        break\n",
    "df_field['age'] = age_list\n",
    "col = df_field.pop(\"age\")\n",
    "df_field.insert(0, col.name, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00137-c06d900f-0028-4d6c-a92a-40f2e5cf14e9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------+-------+-------+-------+-------+-----------+--------+\n",
      "|               Method for NON-goalkeepers dataset               |  MSE  |  RMSE |  MAE  |  MAPE | R squared | Epochs |\n",
      "+----------------------------------------------------------------+-------+-------+-------+-------+-----------+--------+\n",
      "|                         Neural Network                         |  0.06 | 0.245 | 0.188 | 0.014 |   0.968   |  250   |\n",
      "|         Neural Netwotk with Hyperparameter Optimiztion         | 0.054 | 0.233 | 0.178 | 0.013 |   0.971   |  250   |\n",
      "| Neural Netwotk with Hyperparameter Optimiztion + EarlyStopping | 0.044 | 0.211 |  0.16 | 0.012 |   0.976   |  250   |\n",
      "+----------------------------------------------------------------+-------+-------+-------+-------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "fields_mse_all = [mse_field, mse_field_tuner_no_earlystopping, mse_field_tuner]\n",
    "fields_mse_all = [round(num, 3) for num in fields_mse_all]\n",
    "\n",
    "fields_rmse_all = [rmse_field, rmse_field_tuner_no_earlystopping, rmse_field_tuner]\n",
    "fields_rmse_all = [round(num, 3) for num in fields_rmse_all]\n",
    "\n",
    "fields_mae_all = [mae_field, mae_field_tuner_no_earlystopping, mae_field_tuner]\n",
    "fields_mae_all = [round(num, 3) for num in fields_mae_all]\n",
    "\n",
    "fields_mape_all = [mape_field, mape_field_tuner_no_earlystopping, mape_field_tuner]\n",
    "fields_mape_all = [round(num, 3) for num in fields_mape_all]\n",
    "\n",
    "r2_score_field_all = [r2_score_field, r2_score_field_tuner_no_earlystopping, r2_score_field_tuner]\n",
    "r2_score_field_all = [round(num, 3) for num in r2_score_field_all]\n",
    "\n",
    "epochs_all = [epochs, epochs_field_no_earlystopping, epochs_field_earlystopping]\n",
    "\n",
    "\n",
    "method = [\"Neural Network\", 'Neural Netwotk with Hyperparameter Optimiztion', 'Neural Netwotk with Hyperparameter Optimiztion + EarlyStopping']\n",
    "overview_fields = PrettyTable()\n",
    "\n",
    "overview_fields.add_column(\"Method for NON-goalkeepers dataset\", method)\n",
    "overview_fields.add_column(\"MSE\", fields_mse_all)\n",
    "overview_fields.add_column(\"RMSE\", fields_rmse_all)\n",
    "overview_fields.add_column(\"MAE\", fields_mae_all)\n",
    "overview_fields.add_column(\"MAPE\", fields_mape_all)\n",
    "overview_fields.add_column(\"R squared\", r2_score_field_all)\n",
    "overview_fields.add_column(\"Epochs\", epochs_all)\n",
    "\n",
    "\n",
    "print(overview_fields)\n",
    "#print(overview_gk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00109-0067a1ed-2cd5-4840-b8bb-630bf87306f6",
    "deepnote_cell_type": "code",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-355-a71529639c30>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_gk_final[\"Position\"] = \"GK\"\n",
      "<ipython-input-355-a71529639c30>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_field_final[\"Position\"] = \"FP\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>age</th>\n",
       "      <th>index</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Difference %</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Onyinye Wilfred Ndidi</td>\n",
       "      <td>23</td>\n",
       "      <td>111</td>\n",
       "      <td>36499999</td>\n",
       "      <td>48034900</td>\n",
       "      <td>11534901</td>\n",
       "      <td>31.602</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Marcus Thuram</td>\n",
       "      <td>22</td>\n",
       "      <td>374</td>\n",
       "      <td>20499999</td>\n",
       "      <td>31873334</td>\n",
       "      <td>11373335</td>\n",
       "      <td>55.480</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>A. Benjamin Chiamuloira Paes</td>\n",
       "      <td>20</td>\n",
       "      <td>866</td>\n",
       "      <td>9999999</td>\n",
       "      <td>16983296</td>\n",
       "      <td>6983297</td>\n",
       "      <td>69.833</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Daniel Ceballos FernÃ¡ndez</td>\n",
       "      <td>23</td>\n",
       "      <td>383</td>\n",
       "      <td>19499999</td>\n",
       "      <td>25868392</td>\n",
       "      <td>6368393</td>\n",
       "      <td>32.658</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Luka JoviÄ‡</td>\n",
       "      <td>22</td>\n",
       "      <td>387</td>\n",
       "      <td>20000000</td>\n",
       "      <td>26139396</td>\n",
       "      <td>6139396</td>\n",
       "      <td>30.697</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Kenneth Paal</td>\n",
       "      <td>23</td>\n",
       "      <td>5440</td>\n",
       "      <td>1299999</td>\n",
       "      <td>1622923</td>\n",
       "      <td>322924</td>\n",
       "      <td>24.840</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>William Togui</td>\n",
       "      <td>23</td>\n",
       "      <td>7596</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1317449</td>\n",
       "      <td>317449</td>\n",
       "      <td>31.745</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Lewis O'Brien</td>\n",
       "      <td>21</td>\n",
       "      <td>6294</td>\n",
       "      <td>1299999</td>\n",
       "      <td>1612912</td>\n",
       "      <td>312913</td>\n",
       "      <td>24.070</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>CÃ©dric KiprÃ©</td>\n",
       "      <td>23</td>\n",
       "      <td>6361</td>\n",
       "      <td>1199999</td>\n",
       "      <td>1502201</td>\n",
       "      <td>302202</td>\n",
       "      <td>25.184</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Danilho Raimundo Doekhi</td>\n",
       "      <td>22</td>\n",
       "      <td>6406</td>\n",
       "      <td>1099999</td>\n",
       "      <td>1391491</td>\n",
       "      <td>291492</td>\n",
       "      <td>26.499</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           player  age  index      true      pred  Difference  \\\n",
       "51          Onyinye Wilfred Ndidi   23    111  36499999  48034900    11534901   \n",
       "52                  Marcus Thuram   22    374  20499999  31873334    11373335   \n",
       "60   A. Benjamin Chiamuloira Paes   20    866   9999999  16983296     6983297   \n",
       "63      Daniel Ceballos FernÃ¡ndez   23    383  19499999  25868392     6368393   \n",
       "65                     Luka JoviÄ‡   22    387  20000000  26139396     6139396   \n",
       "..                            ...  ...    ...       ...       ...         ...   \n",
       "415                  Kenneth Paal   23   5440   1299999   1622923      322924   \n",
       "423                 William Togui   23   7596   1000000   1317449      317449   \n",
       "427                 Lewis O'Brien   21   6294   1299999   1612912      312913   \n",
       "438                  CÃ©dric KiprÃ©   23   6361   1199999   1502201      302202   \n",
       "446       Danilho Raimundo Doekhi   22   6406   1099999   1391491      291492   \n",
       "\n",
       "     Difference % Position  \n",
       "51         31.602       FP  \n",
       "52         55.480       FP  \n",
       "60         69.833       FP  \n",
       "63         32.658       FP  \n",
       "65         30.697       FP  \n",
       "..            ...      ...  \n",
       "415        24.840       FP  \n",
       "423        31.745       FP  \n",
       "427        24.070       FP  \n",
       "438        25.184       FP  \n",
       "446        26.499       FP  \n",
       "\n",
       "[117 rows x 8 columns]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gk_final_perc = df_gk.nlargest(100,'Difference %')\n",
    "df_gk_final_total = df_gk.nlargest(100,\"Difference\")\n",
    "list_gk_topperc = list(df_gk_final_perc.player)\n",
    "df_gk_final = df_gk_final_total[df_gk_final_total.player.isin(list_gk_topperc)]\n",
    "df_gk_final[\"Position\"] = \"GK\"\n",
    "\n",
    "df_field_final_perc = df_field.nlargest(1000,'Difference %')\n",
    "df_field_final_total = df_field.nlargest(1000,\"Difference\")\n",
    "list_field_topperc = list(df_field_final_perc.player)\n",
    "df_field_final = df_field_final_total[df_field_final_total.player.isin(list_field_topperc)]\n",
    "df_field_final[\"Position\"] = \"FP\"\n",
    "\n",
    "final = df_gk_final.append(df_field_final, ignore_index=True)\n",
    "final[(final.age <= 23) & (final.true >= 1000000)].sort_values(by=\"Difference\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d0001f84-164c-454a-9f8a-a2e6174a5f5c' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ddfe774a-efeb-404c-9cf5-fd460a182528",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
